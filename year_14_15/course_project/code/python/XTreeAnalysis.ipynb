{
 "metadata": {
  "name": "",
  "signature": "sha256:b3551e1c4242de8caca3c9ac1e64e1de4e93a813e1f017314f67e38c54ff86ef"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "<center>Studying self-similarity using the crossing tree</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<center>Nazarov Ivan</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<center>Supervisor: DeCrouez GG</center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Crossing times\n",
      "Suppose ${( t_i, x_i)}^N_{k=1}$ is a sample of some continuous process ${( X_t )}_{t\\in T}$ where $X_i = X(t_i)$.<!--, with $T\\subseteq \\mathbb{R}$ an inteval.-->\n",
      "\n",
      "The crossing times are defined as follows: for a given base grid spacing $\\delta>0$ and for $n,k\\geq0$ they are the stopping times $$T^n_{k+1} = \\inf\\Big\\{ t > T^n_k\\,: \\, \\big | X_t - X_{T^n_k} \\big | \\geq \\delta 2^n \\Big\\}$$ with $T^n_0 = 0$. The forcing of the zero-th xcrossing time to $0$ is done to align the grid with the process, so in effect, without losss of generality we may consider processes, which start at the origin.\n",
      "\n",
      "The parameter $\\delta$ is the spacing of the finest grid, with respect to which the leaves of the crossing tree are computed. Parent nodes of these leaves represent crossings of a coraser grid, namely $2\\delta$. The choice of $\\delta$ affects the tree in the following way in the case of a sampled process:\n",
      "**_THIS SECTION MUST BE DISCUSSED_**\n",
      "1. The grid with too low a value of $\\delta$ would be crossed by straight line segments between each pair consecutive sample observations. This could poison the distribution with some unfavouralbe yet unknown mixture and lead to excessive number of seemingly meaningless crossings.\n",
      "2. Too large $\\delta$ lead to a very poor and under sampled crossing tree.\n",
      "\n",
      "By construction, for a binary crossing grid, $N^l_k$, the number of subcrossings in any complete crossing between $T^l_k$ and $T^l_{k+1}$ is always an even number. This is due to the fact, that each crossing is registered as soon as two unidirectional subcrossings are encoutered, as seen by the following.\n",
      "\n",
      "Suppose $T^{n+1}_k$ and $T^n_m$ are aligned in that $T^{n+1}_k=T^n_m$, and $T^{n+1}_{k+1}<+\\infty$, i.e. the $n+1$ grid crossing is complete. First of all $T^n_{m+1},T^n_{m+2}\\leq T^{n+1}_{k+1}$, since otherwise the process would have crossed left the $\\pm\\delta 2^n$ band before it left the $\\pm \\delta 2^{n+1}$ band, which is twice as wide.\n",
      "\n",
      "The process is continuous which means that almost surely for any $\\epsilon>0$ there is $\\eta>0$ such that for any $t$ with $\\big|t-T^n_{m+1}\\big| < \\eta$ it holds that $\\big |X_{T^n_{m+1}}-X_t\\big|<\\epsilon$.\n",
      "Also for every $t\\in\\big[T^n_k, T^n_{k+1}\\big)$ it cannot be otherwise but $\\big | X_t - X_{T^n_k} \\big | < \\delta 2^n$. \n",
      "In particular, for $\\epsilon = \\frac{1}{2}\\delta 2^n$ it means that for a small while after $T^n_{m+1}$ the process is almost surely still within the $\\pm \\delta 2^{n+1}$ band. Therefore $T^n_{m+1} < T^{n+1}_{k+1}$.\n",
      "\n",
      "Thus it is true that $$1\\leq \\bigg | \\frac{1}{\\delta 2^n} \\big(X_{T^n_{m+1}} - X_{T^n_m}\\big)\\bigg | < 2$$. The next crossing of $\\pm\\delta 2^n$ takes palce at $T^n_{m+2}$ and there are two possibilities:\n",
      "1. the process crossed a new $\\pm\\delta 2^{n+1}$ grid line: $\\big|X_{T^n_{m+2}} - X_{T^n_m}\\big|\\geq 2\\cdot\\delta 2^n$. In this case $T^{n+1}_{k+1}\\leq T^n_{m+2}$ and there are _two_ subcrosings.\n",
      "2. the process moved back to the level $X_{T^n_m}$, which does not incurr a crossing of $\\pm\\delta 2^{n+1}$ grid line, yet is registered by the $\\pm\\delta 2^n$ grid. In this case $T^n_{m+2} < T^{n+1}_{k+1}$ and $X_{T^n_{m+2}} = X_{T^{n+1}_{k+1}}$ -- back to the beginning of this argument.\n",
      "\n",
      "Since the crossing is complete, $T^{n+1}_{k+1}<+\\infty$ implies that sooner that later a crossing of $\\pm\\delta 2^{n+1}$ grid occurs, in which case $T^{n+1}_{k+1}=T^n_{m+2p}$, meaning that there were exactly $2p$ subcrossings."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### A model of the offspring distribution\n",
      "\n",
      "Let's test the hypothesis that the number of subcrossings follows a distribution similar to geometric. Recall that $G$ is a geometrically distributed random variable, $G\\sim \\text{Geom}(\\theta)$, if $\\mathbb{P}(G=k) = {(1-\\theta)}^{k-1}\\theta$ for all $k\\geq1$. Other properties of geometrically dsitributed random variables include\n",
      " * Complimentary CDF $\\mathbb{P}(G\\geq k) = {(1-\\theta)}^{k-1}$ for any $k\\geq1$;\n",
      " * Expectation $\\mathbb{E}(G) = \\theta^{-1}$;\n",
      " * memorylessness.\n",
      "\n",
      "The number of offspring of any $\\delta 2^n$-grid crossing is the number of subcrossings of a finer grid with spacing $\\delta 2^{n-1}$ during a typical crossing.\n",
      "\n",
      "Our hypothesis is that $N$, the number of offspring, follows a geometric distribution on the even numbers, i.e. $\\frac{1}{2}N\\sim \\text{Geom}(\\theta)$. To test it we utilize a truncated geometric distribution with a fixed threshold $\\bar{k}$, beacuse this approach  naturally and easily handles unbounded random variables. Truncating the data effectively means that two kinds of observations are registered:\n",
      " * a value less than $\\bar{k}$;\n",
      " * an event $\\big\\{N\\geq \\bar{k}\\big\\}$, indicating that the value has not been less than $\\bar{k}$.\n",
      "Basically such trincated random variable behaves like a typical geometric one on the values $\\big\\{ \\left . 2m\\right \\rvert 2m < \\bar{k}\\big\\}$, but happens ot have an unusual concentration of probability at the upper truncation level $\\bar{k}$.\n",
      "\n",
      "Therefore for even integers $k=2,4,\\ldots\\bar{k}$ the distribution of the number of offspring is given by\n",
      "$$\\mathbb{P}(N=k) = {(1-\\theta)}^{\\frac{k}{2}-1}\\theta\\,1_{k<\\bar{k}} + {(1-\\theta)}^{\\frac{\\bar{k}}{2}-1}\\,1_{k = \\bar{k}}$$\n",
      "where $1_{(\\cdot)}$ -- is the $0-1$ indicator.\n",
      "\n",
      "#### Maximum Likelihhod Estimation\n",
      "\n",
      "Suppose ${(g_i)}_{i=1}^N$ a sample of independent geometric random variables, with distribution truncated by $\\bar{k}$. Due to truncation there is a finite numebr of distinct values that are observed in any given sample. Therefore it is convenient to represent every sample in an equivalent value-frequency form: ${\\Big(j, f_j\\Big)}$ for even $j$ not greater than $\\bar{k}$ and \n",
      "$f_j = \\bigg\\lvert\\big\\{\\big.i\\,\\big\\rvert\\,g_i=j\\big\\}\\bigg\\rvert$ -- the number of observations with the specified value. Without the loss of generality, $f_j$ can be set to zero for those $j$ that were not observed.\n",
      "\n",
      "The log-likelihood function is given by\n",
      "$$\\ln\\mathcal{L} = \\sum_{j\\neq \\bar{k}} f_j {\\Big(\\frac{j}{2}-1\\Big)} \\ln {(1-\\theta)} + \\sum_{j\\neq \\bar{k}} f_j \\ln \\theta + f_{\\bar{k}} {\\Big(\\frac{\\bar{k}}{2} - 1\\Big)} \\ln {(1-\\theta)}$$\n",
      "where the summation is done over the all possible distinct values. The first-order condition on optimal $\\theta$ is given by\n",
      "$$\\frac{d}{d \\theta} \\ln\\mathcal{L}\\,:\\quad-\\sum_j f_j {\\Big(\\frac{j}{2}-1\\Big)} \\frac{1}{1-\\theta} + \\sum_{j\\neq \\bar{k}} f_j \\frac{1}{\\theta} = 0$$\n",
      "This is equivalent to $\\frac{S-N}{1-\\theta} = \\frac{N-f_{\\bar{k}}}{\\theta}$, where $S = \\sum_j \\frac{j}{2} f_j$ and $N = \\sum_j f_j$ becasue the frequencies sum up to the the total number of observations. Therefore the desired ML estimator of the probability parameter $\\theta$ is\n",
      "$$\\hat{\\theta} = \\frac{N-f_{\\bar{k}}}{S-f_{\\bar{k}}}$$\n",
      "\n",
      "I strongly suspec that the MLE of the truncated geometric distribution is biased. If so, this renders it useless for monte-carlo estimation purposes. Clearly the bias should depend on the truncation threshold, and $\\hat{\\theta}_T \\to \\hat{\\theta}$ as $T\\to \\infty$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####The Monte Carlo routine\n",
      "The procedure below is performs the specified $M$ number of MonteCralo simulations of the sample paths of the process specified by the generator object. The paratmeters $K$ and $T$ determine the truncation performed while collecting the crossing tree data.  \n",
      "For example $K=4$ menas that subcrossings of size up to and including 4 are recorded in full detail, while every subcrossing of larger size is agregated and stored in the ``tail''.  \n",
      "\n",
      "Similarly for the parameter $T$, which set the threshold level of the crossing tree starting from the leaf level and up, beyond which the data is strored in aggregate manner."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "from synthfbmcircul import synth_fbm\n",
      "from hsssi_processes import *\n",
      "from Weierstrass import synth_Weier, synth_Weier_2\n",
      "\n",
      "from crossing_tree import *\n",
      "from monte_carlo import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genr = synth_fbm( 2**21, .65 )\n",
      "\n",
      "%lprun -f synth_fgn.__call__ T, X = genr( )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mht, mhp, mhx, mex = xtree_build( T, X, delta = 2**(np.floor(np.log2(np.max(X)-np.min(X)))-8) )\n",
      "# mht, mhp, mhx, mex = xtree_build( T, X, delta = None )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#(/\\, \\/, \u00b11)\n",
      "# inx = ( mex[8][:,2] + 1 ) // 2\n",
      "# print  mex[8]#[:,inx]\n",
      "# wed = np.where(mex[8][:,2]>0, mex[8][:,0], mex[8][:,1])\n",
      "# vee = np.where(mex[8][:,2]<0, mex[8][:,0], mex[8][:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lex= mex[8]\n",
      "lex[ lex[:,2]<0, :2 ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hatvee_cond = np.zeros( (len( mex ), 2, 2 ), dtype = np.int )\n",
      "for i, lex in enumerate( mex, 0 ) :\n",
      "    if lex.shape[0]<1 : continue\n",
      "    hatvee_cond[i,:,0] = lex[ lex[:,2]>0, :2 ].sum( axis = 0 )\n",
      "    hatvee_cond[i,:,1] = lex[ lex[:,2]<0, :2 ].sum( axis = 0 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print hatvee_cond.sum(axis = 2)\n",
      "print [len(t) for t in mhx]\n",
      "print [len(t) for t in mex]\n",
      "lex = mex[4]\n",
      "print lex[ lex[:,2]>0, :2 ].sum( axis = 0 )\n",
      "print lex[ lex[:,2]<0, :2 ].sum( axis = 0 )\n",
      "print hatvee_cond[4,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hatvee_cond[1,0,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Import the complimentary chi squared distribution \n",
      "from scipy.stats import chisqprob as cdchisq\n",
      "\n",
      "## Choose the levels to test the hypothesis on\n",
      "levels = range( -6, -2+1, 1 )\n",
      "\n",
      "## The total number of crossings of \\delta 2^n grid\n",
      "Nn = np.array( [ len( mht[ l ] ) for l in levels ] ).reshape( (len(levels), -1 ) )\n",
      "\n",
      "## The number of subcrossings of size \\delta 2^{n-1} that\n",
      "##  make up the k-th crossing of n-th level.\n",
      "Zn = [ mhx[ l ] for l in levels ]\n",
      "\n",
      "## Compute the empirical distribution of the number of subcrossings in the pooled sample\n",
      "bins, f_pool = np.unique( np.concatenate( tuple( Zn ) ), return_counts = True )\n",
      "p_pool = f_pool / np.sum( f_pool, dtype = np.float64 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p_lvl = np.zeros( ( len( Nn ), len( bins ) ), dtype = np.float )\n",
      "for l, z in enumerate( Zn, 0 ) :\n",
      "    cat, freq = np.unique( z, return_counts = True )\n",
      "    p_lvl[ l, np.searchsorted( bins, cat ) ] = freq / np.sum( freq, dtype = np.float64 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stat = np.sum( Nn * ( ( p_lvl - p_pool )**2 / p_pool ) )\n",
      "pv = cdchisq( stat, ( len( levels ) - 1 ) * ( len( bins ) - 1 ) )\n",
      "print stat, pv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Given the agregated value-count data in X, compute the MLE of \\theta of the geometric distribution.\n",
      "## I think the MLE is biased... This renders averaging across simulations useselss.(\n",
      "def mle_theta( x ) :\n",
      "    N = np.sum( x )\n",
      "    S = np.dot( x, np.arange( 1, len( x ) + 1, dtype = np.float ) )\n",
      "    return ( N+1 - x[ -1 ] ) / ( S+1 - x[ -1 ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "from synthfbmcircul import synth_fbm\n",
      "from hsssi_processes import *\n",
      "from Weierstrass import synth_Weier, synth_Weier_2\n",
      "\n",
      "from crossing_tree import *\n",
      "from monte_carlo import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## The Monte Carlo kernel performs a single experiment and returns its\n",
      "## K'xT slice of the result.\n",
      "def monte_carlo_kernel( generator, K, T, delta = None ) :\n",
      "\tfrom scipy.stats import chisqprob as cdchisq\n",
      "## K is the maximal number of subcrossings beyond which the data\n",
      "##  on subcrossings is agregateed into the tail. (truncation parameter)\n",
      "\tK = 2 * ( K // 2 + 1 )\n",
      "## T is the number of detailed levels of the crossing tree to stored in\n",
      "##  output. Any crossings of grids coarser than the treshold are\n",
      "##  aggregated.\n",
      "\tdistr = np.zeros( ( T+1, K // 2 ), dtype = np.int )\n",
      "## Generate a replication of the process\n",
      "\tt, x = generator( )\n",
      "## G. Decrouez 2015-02-12: the selection of the spacing of the finest grid\n",
      "##  based on the scale of the process is crucial as it allows comparison\n",
      "##  of the crossing tree between different sample paths.\n",
      "\tif delta is None :\n",
      "# \t\tsigma = np.std( np.diff( x ) )\n",
      "## Set the base scale so that the constructed tree is 6 layers deep.\n",
      "# \t\tdelta = 2**( np.floor( np.log2( np.max( x ) - np.min( x ) ) ) - 6 )\n",
      "\t\tdelta = None\n",
      "## 2015-04-08 : I think 6-level deep crossing tree is too poor for any analysis\n",
      "##  which is why it is necessary to take the variance into account\n",
      "## Get the hitting times and points\n",
      "\tht, hp, subx, excur = xtree_build_superfast( t, x, delta )\n",
      "## Pool all the crossing counts together and construct the distribution matrix \n",
      "## ToDo\n",
      "## ChiSquare test for distributional match: choose the levels to test the hypothesis on\n",
      "\tlevels = range( -5, -3+1, 1 )\n",
      "## The total number of crossings of \\delta 2^n grid\n",
      "\tNn = np.array( [ len( ht[ l ] ) for l in levels ] ).reshape( (len(levels), -1 ) )\n",
      "## The number of subcrossings of size \\delta 2^{n-1} that\n",
      "##  make up the k-th crossing of n-th level.\n",
      "\tZn = [ subx[ l ] for l in levels ]\n",
      "## Compute the empirical distribution of the number of subcrossings in the pooled sample\n",
      "\tbins, f_pool = np.unique( np.concatenate( tuple( Zn ) ), return_counts = True )\n",
      "\tp_pool = f_pool / np.sum( f_pool, dtype = np.float64 )\n",
      "## Calculate the empirical probabilites at each level\n",
      "\tp_lvl = np.zeros( ( len( Nn ), len( bins ) ), dtype = np.float )\n",
      "\tfor l, z in enumerate( Zn, 0 ) :\n",
      "\t\tcat, freq = np.unique( z, return_counts = True )\n",
      "\t\tp_lvl[ l, np.searchsorted( bins, cat ) ] = freq / np.sum( freq, dtype = np.float64 )\n",
      "## Run the chi_square test on each level of the tree\n",
      "\tstat = np.sum( Nn * ( ( p_lvl - p_pool )**2 / p_pool ) )\n",
      "\tdof = len( levels ) * ( len( bins ) - 1 )\n",
      "## Now summarize the distribution: Simplify\n",
      "## ToDo\n",
      "\tfor level, xing in enumerate( subx[1:], 0 ) :\n",
      "## Count the absolute frequencies\n",
      "\t\tc, f = np.unique( xing, return_counts = True )\n",
      "## We collect the data on the distribution truncated by K (including).\n",
      "## Thus truncate the number of subcrossings by K -- everything less is\n",
      "##  detailed, otherwise -- agregated into tail\n",
      "\t\tc = np.minimum( c, K )\n",
      "## Similarly truncate the level by T + 1\n",
      "\t\tif level >= T : level = T\n",
      "## Fill the offspring distribution matrix\n",
      "\t\tfor c, f in zip( c, f ) :\n",
      "\t\t\tdistr[ level, c // 2 - 1 ] += f\n",
      "## Use straightforward bivariate regression implementation.\n",
      "## We could also use ML estimators, which is much better!\n",
      "## See the handwritten notes.\n",
      "## Estimate the conditional distribution of excursions\n",
      "## lvl x (++ --) x (+- -+) # (/\\, \\/, +/-1) ==  (u,d,s)\n",
      "\thatvee = np.zeros( (len( excur ), 2, 2 ), dtype = np.int )\n",
      "\tfor i, lex in enumerate( excur, 0 ) :\n",
      "\t\tif lex.shape[0] < 1 : continue\n",
      "\t\thatvee[i,0,:] = lex[ lex[:,2]>0, :2 ].sum( axis = 0 )\n",
      "\t\thatvee[i,1,:] = lex[ lex[:,2]<0, :2 ].sum( axis = 0 )\n",
      "## Estimate the probability distribution of the number of offspring\n",
      "## ToDo\n",
      "\treturn distr, (stat,dof, cdchisq(stat, dof)), hatvee"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Fractional Brownian Motion\n",
      "Let's have a look at the estiate of the parameter of the offspring distribution.\n",
      "We set up the grid with base spacing equal to $2^{-6}$, as has been done in Geoffrey's paper.\n",
      "\n",
      "The continuous processes are confined to the $[0,1]$ interval and their smaple paths are observed at discrete knots of the uniformly spaced lattice ${\\big(t_i\\big)}_{i=0}^{N-1}$ with $t_0=0$ and $t_1=1$. In effect every single Monte Carlo replication deals with a sample discretized path ${\\big(t_k, x_k\\big)}_{k=0}^{N-1}$ where $x_k = X(t_k)$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Set the size of the monte carlo experiment\n",
      "M = 10\n",
      "## Determine how many levels of the crosssing tree to keep\n",
      "T = 5\n",
      "## And set the truncation threshold so that subcrossings of size greater\n",
      "##  than or equal to 34 are put in the tail of the offspring distribution.\n",
      "K = 32\n",
      "## Set the time-precision of the sampled paths\n",
      "N = 2**18\n",
      "## Set the studied Hurst exponent\n",
      "H = .95\n",
      "## The base grid spacing is going to be 2^{-6}\n",
      "# delta = 2**(-6)\n",
      "## Setting \\delta to zero construct the tree for adaptive\n",
      "##  base spacing equal to the standard deviation of the increments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Study the Fractional Brownian motion.\n",
      "%lprun -f xtree_build_superfast res_fbm = monte_carlo_serial( synth_fbm( N, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )\n",
      "# res_fbm = monte_carlo_parallel( synth_fbm( N, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distr  = np.concatenate( [ [d] for d, _, _ in res_fbm[0] ] )\n",
      "chisq  = np.concatenate( [ [c] for _, c, _ in res_fbm[0] ] )\n",
      "hatvee = np.concatenate( [ p for _, _, p in res_fbm[0] ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Import the complimentary chi squared distribution \n",
      "from scipy.stats import chisqprob as cdchisq\n",
      "pv = np.array( [p for s,d,p in chisq], dtype = np.float )\n",
      "print np.sum( pv < 0.05, dtype = np.float ) / len( pv )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chisq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(pv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_probs( res ) :\n",
      "## Compute the empirical distribution function of the number of offspring \n",
      "    return np.apply_along_axis( lambda f : f * 1.0 / np.sum( f ), 2, res )\n",
      "## Compute the probabilities\n",
      "probs = get_probs( distr )\n",
      "## In homage to the original code, call the mean probabilities and errors by PrZ and StZ\n",
      "PrZ = np.mean( probs, axis = 0 )\n",
      "StZ =  np.std( probs, axis = 0 )\n",
      "## Create an appropriate array of offspring values\n",
      "offs = np.arange( 2, 2 * probs.shape[ 2 ] + 1, 2, np.float )\n",
      "## Create a new plot\n",
      "plt.figure( 1, figsize = ( 8, 6 ) )\n",
      "theta = 2**(1.0-1.0/H)\n",
      "offs_prb = (1.0-theta)**(offs//2-1)*theta\n",
      "plt.plot( offs, np.log( offs_prb ), \"k-\", linewidth = 2, markersize = 15 )\n",
      "## Plot the logarithm of the probability of observing a given number of subcrossings \n",
      "for i, c in zip( range( 0, probs.shape[ 2 ] ), [\"r\", \"g\", \"b\", \"y\"] ) :\n",
      "    plt.plot( offs, np.log( PrZ[i,:] ), \"o\" + c )\n",
      "#         plt.errorbar( offs, PrZ[i,:], yerr = StZ[i,:], color = c, linewidth = 0 )\n",
      "plt.show( )\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# P(-+|u) = P(+-|d) = 1/sqrt(\\mu)\n",
      "pu = list( ); pd = list( )\n",
      "for _,_,p in res_fbm[0]:\n",
      "    pp = p[1,:]+p[2,:]+p[3,:]\n",
      "    tt = pp.sum(axis=1)\n",
      "    \n",
      "print pp\n",
      "print tt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr/>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Examine the properties of the Weierstrass-Mandelbrot process\n",
      "# %lprun -f monte_carlo_kernel res_wei = monte_carlo_serial( synth_Weier_2( N, 1.2, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )\n",
      "res_wei = monte_carlo_parallel( synth_Weier( N, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Finally have a look at the Rosenblatt process\n",
      "# res_ros = monte_carlo_parallel( synth_Rosenblatt( N // (2**6), H, K = 2**6 ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Save the results for later reuse\n",
      "import time as tm\n",
      "## Make a file with a timestamped name\n",
      "outfile = \"./MC m%d p%d h%.3f %s.npz\" % ( M, np.log2(N), H, tm.strftime(\"%Y%m%d-%H%M\") )\n",
      "\n",
      "## Save the copy of the monte carlo output\n",
      "np.savez( outfile, fbm = res_fbm, wei = res_wei )\n",
      "# np.savez( outfile, fbm = res_fbm, wei = res_wei, ros = res_ros )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Set the size of the monte carlo experiment\n",
      "M = 100\n",
      "## Determine how many levels of the crosssing tree to keep\n",
      "T = 5\n",
      "## And set the truncation threshold so that subcrossings of size greater\n",
      "##  than or equal to 34 are put in the tail of the offspring distribution.\n",
      "K = 32\n",
      "## Set the time-precision of the sampled paths\n",
      "N = 2**18\n",
      "## Set the studied Hurst exponent\n",
      "H = .85\n",
      "## The base grid spacing is going to be 2^{-6}\n",
      "# delta = 2**(-6)\n",
      "## Setting \\delta to zero construct the tree for adaptive\n",
      "##  base spacing equal to the standard deviation of the increments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Study the Fractional Brownian motion.\n",
      "res_fbm = monte_carlo_parallel( synth_fbm( N, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Examine the properties of the Weierstrass-Mandelbrot process\n",
      "res_wei = monte_carlo_parallel( synth_Weier( N, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Save the results for later reuse\n",
      "import time as tm\n",
      "## Make a file with a timestamped name\n",
      "outfile = \"./MC m%d p%d h%.3f %s.npz\" % ( M, np.log2(N), H, tm.strftime(\"%Y%m%d-%H%M\") )\n",
      "\n",
      "## Save the copy of the monte carlo output\n",
      "np.savez( outfile, fbm = res_fbm, wei = res_wei )\n",
      "# np.savez( outfile, fbm = res_fbm, wei = res_wei, ros = res_ros )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " \n",
      " \n",
      " \n",
      " \n",
      " "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_probs( res ) :\n",
      "## Compute the empirical distribution function of the number of offspring \n",
      "    return np.apply_along_axis( lambda f : f * 1.0 / np.sum( f ), 2, res )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This procedure plots the empirical probability of observing a set number of offspring at each node of thw crossing tree."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mc_plot_empirical_probs( res, H, title = None ) :\n",
      "## Compute the probabilities\n",
      "    probs = get_probs( res )\n",
      "## In homage to the original code, call the mean probabilities and errors by PrZ and StZ\n",
      "    PrZ = np.mean( probs, axis = 0 )\n",
      "    StZ =  np.std( probs, axis = 0 )\n",
      "## Create an appropriate array of offspring values\n",
      "    offs = np.arange( 2, 2 * probs.shape[ 2 ] + 1, 2, np.float )\n",
      "## Create a new plot\n",
      "    plt.figure( 1, figsize = ( 8, 6 ) )\n",
      "    if title is not None :\n",
      "        plt.title( title )\n",
      "    theta = 2**(1.0-1.0/H)\n",
      "    offs_prb = (1.0-theta)**(offs//2-1)*theta\n",
      "    plt.plot( offs, np.log( offs_prb ), \"k-\", linewidth = 2, markersize = 15 )\n",
      "## Plot the logarithm of the probability of observing a given number of subcrossings \n",
      "    for i, c in zip( range( 0, probs.shape[ 2 ] ), [\"r\", \"g\", \"b\", \"y\"] ) :\n",
      "        plt.plot( offs, np.log( PrZ[i,:] ), \"o\" + c )\n",
      "#         plt.errorbar( offs, PrZ[i,:], yerr = StZ[i,:], color = c, linewidth = 0 )\n",
      "    plt.show( )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Simulation results\n",
      "Below interspersed with the listings of code are the results obtained so far for the corssing tree monte carlo simulation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mc_plot_empirical_probs( res_fbm, H, \"fBM %0.2f\" % ( H ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "outfiles = [ './MC m100 p18 h0.500 20150226-1252.npz', './MC m100 p18 h0.850 20150226-1301.npz']\n",
      "for outfile in outfiles :\n",
      "    opt = dict( ( x.group(1).upper(), float(x.group(2)) )\n",
      "        for x in re.finditer( r\"\\b([a-z])([-+]?(?:\\d+(?:\\.\\d*)?|\\.\\d+))\\b\", outfile ) )\n",
      "    with np.load( outfile ) as f_res :\n",
      "        res_fbm, res_wei = f_res['fbm'], f_res['wei']\n",
      "        # res_ros = f_res['ros']\n",
      "        mc_plot_empirical_probs( res_fbm, opt['H'], \"fBM %0.2f\" % ( opt['H'] ) )\n",
      "        mc_plot_empirical_probs( res_wei, opt['H'], \"WM %0.2f\" % ( opt['H'] ) )\n",
      "# mc_plot_empirical_probs( res_ros, \"Rosenblat %0.2f\" % ( H ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr/>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res_fbm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## The MC results array is MxTxK. Fixing axes 0 and 1, compute\n",
      "##  the ML estimate of the parameter over the axis 2 -- the within\n",
      "##  tree-level smaple of the offspring distribution.\n",
      "theta = np.apply_along_axis( mle_theta, 2, res_fbm )\n",
      "# mle_theta(DD[:,0,0])\n",
      "\n",
      "# np.save( \"./run 2b22 2015-02-14\", DD_par )\n",
      "# XX_par = np.load( \"./run 2b22 2015-02-14.npy\" )\n",
      "\n",
      "# np.max(np.abs(DD_par - XX_par))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot( theta[:,0], \"r-\")\n",
      "plt.plot( theta[:,1], \"b-\")\n",
      "plt.plot( theta[:,2], \"k-\")\n",
      "1/(1-np.log(np.mean(theta, axis=0)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot( 1/(1-np.log(theta[:,0])), \"r-\")\n",
      "plt.plot( 1/(1-np.log(theta[:,1])), \"b-\")\n",
      "plt.plot( 1/(1-np.log(theta[:,2])), \"k-\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mean_subx( x ) :\n",
      "    return np.dot( x, 2*np.arange( 1, len( x ) + 1, dtype = np.float ) ) / np.sum( x )\n",
      "\n",
      "moff = np.apply_along_axis( mean_subx, 2, res_fbm )\n",
      "plt.plot( moff[:,0], \"k-\")\n",
      "plt.plot( moff[:,1], \"b-\")\n",
      "plt.plot( moff[:,2], \"r-\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DD_par[:,2,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theta2 = np.apply_along_axis(mle_theta, 2, DD_par2)\n",
      "\n",
      "plt.plot( theta2[:,0], \"r-\")\n",
      "plt.plot( theta2[:,1], \"b-\")\n",
      "plt.plot( theta2[:,2], \"k-\")\n",
      "1/(1-np.log(np.mean(theta2, axis=0)))\n",
      "# DD_par2[:,:,3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scaffolding_plot( t, x ) :\n",
      "    ht, hp, xt, exc = xtree_build( t, x )\n",
      "    l = len( ht ) - 5\n",
      "    plt.figure( figsize = (15, 8) )\n",
      "    plt.plot( t, x, \"y-\")\n",
      "# for p in tp[l] : plt.axhline( p, linewidth = 1, color = 'k' )\n",
      "    plt.step( ht[l+0], hp[l+0], \"g>\" ) #, where = 'mid' )\n",
      "    plt.step( ht[l+1], hp[l+1], \"b>\" ) #, where = 'mid' )\n",
      "    plt.step( ht[l+2], hp[l+2], \"r>\" ) #, where = 'mid' )\n",
      "    plt.step( ht[l+3], hp[l+3], \"k>\" ) #, where = 'mid' )\n",
      "    plt.show( )\n",
      "#     return [zip(*np.unique( x, return_counts = True)) for x in xt ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genr = synth_Weier(N, H)\n",
      "t,x = genr()\n",
      "plt.plot(t,x, \"y-\")\n",
      "scaffolding_plot(t,x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## The mean number of offspring\n",
      "## The empirical distribution of the subcrossings\n",
      "##  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Straighforward, dumb linear regression\n",
      "However, for the estimation purposes it is useful to worj with the complementary CDF, instead of the ``density'' itself:\n",
      "$$\\mathbb{P}(N\\geq k) = {(1-\\theta)}^k$$ this way no distinction between $k<\\bar{k}$ of $k=\\bar{k}$ needs to be done.\n",
      "\n",
      "For this purpose, let's estimate the following regression model: $$\\ln \\hat{p}_k \\sim C + \\beta k$$ where $\\hat{p}_k$ is the empirical probability that a crossing had no less than $k$ subcrossings and $\\beta = \\ln \\sqrt{(1-\\theta)}$.\n",
      "\n",
      "It is entirely posible that the distribution's shape depend on the depth. If it does, then there is no self similarity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import chi2_contingency as chisq_test\n",
      "def ctable( x, y ) :\n",
      "## This procedure makes a contingeny table out of x and y (they should be discrete)\n",
      "    lxy = np.append( x, y ).reshape( len( x ),2)\n",
      "    lxy = lxy.view(dtype = np.dtype([('x', x.dtype), ('y', y.dtype)]))\n",
      "    lc, lf = np.unique( lxy, return_counts = True )\n",
      "    print lc\n",
      "    xc = np.unique( x ) ; yc = np.unique( y )\n",
      "    txy = np.zeros( ( len( xc ), len( yc ) ), dtype = np.int )\n",
      "    vix = lc.view( ( np.int, len( lc.dtype ) ) )\n",
      "    ix = np.searchsorted( xc, vix[:,0] )\n",
      "    iy = np.searchsorted( yc, vix[:,1] )\n",
      "    txy[[ix, iy]] = lf\n",
      "    return txy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Appendix"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Testing on the deterministic cascade"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# scaffolding_plot( *genr( ) )\n",
      "def run() :\n",
      "    monte_carlo( genr, M=100, K = 16, T = 3 )\n",
      "%lprun -f xtree_integer_crossings_fast run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.plot(d[0,:], \"rx\", d[1,:], \"bx\", d[2,:], \"kx\")\n",
      "# f ~ a^(k-1)(1-a)\n",
      "# l\n",
      "plt.plot( range(2, 13, 2), np.log(np.mean( d, 1 )) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = 0\n",
      "for s in a[1:]:\n",
      "    plt.step( s[0], np.log( s[1] * 2**m ), \"b-\")\n",
      "    m+=1\n",
      "plt.step( a[1][0], np.log( a[1][1] ), \"r-\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 2**10\n",
      "H = .5\n",
      "\n",
      "# draw(synth_fbm( N, H ))\n",
      "# draw(synth_Weier( N, H ))\n",
      "# draw(synth_Rosenblatt( N, H ))\n",
      "# draw(synth_Hermite3( N, H ))\n",
      "# draw(synth_Hermite4( N, H ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Test the process generators\n",
      "def draw( gen, seed = None ) :\n",
      "\tt, u = gen( seed )\n",
      "\tt, v = gen( seed )\n",
      "\tplt.plot( t, u, \"r-\", t, v, \"b-\" )\n",
      "\tplt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Code testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genr = synth_fbm( 2**20, .5 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "T, X = genr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mht, mhp, mhx, mex = xtree_build( T, X, delta = 2**(np.floor(np.log2(np.max(X)-np.min(X)))-8) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import chisquare as chisq\n",
      "xlevels = mhx[-6:-4+1]\n",
      "xpool = np.concatenate( tuple( xlevels ) )\n",
      "pc, pf = np.unique( xpool, return_counts = True )\n",
      "xf = list()\n",
      "for x in xlevels :\n",
      "    c, f = np.unique( x, return_counts = True )\n",
      "    zf = np.zeros( pf.shape, np.int )\n",
      "    zf[ np.searchsorted( pc, c ) ] = f\n",
      "    xf.append( zf )\n",
      "[ chisq(x, pf) for x in xf ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [len( t ) for t in mht]\n",
      "print [x.sum() for x in mhx[1:]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.allclose( np.sum( np.abs( mex[2][:,:-1] ), axis = 1 ) * 2+2, mhx[2])\n",
      "mex[5][:,:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Weierstrass import *\n",
      "N = 2**20\n",
      "T, X = genr()\n",
      "# T, X = synthweier( N, 0.7, 1.2, 1000, deterministic = True, seed = None )\n",
      "# T = np.arange(N, dtype=np.float)/ (N-1)\n",
      "\n",
      "delta = np.std( np.diff( X ), ddof = 1 )\n",
      "Z = ( X - X[ 0 ] ) / delta\n",
      "delta\n",
      "lht, lhp, lhx, exc = xtree_integer_crossings_fast( T, Z )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ht, hp, hx, exc = xtree_integer_crossings( T, Z )\n",
      "print np.sum(np.abs(ht-lht))+np.sum(np.abs(hp-lhp))\n",
      "# lht, lhp, lhx, exc = xtree_super_crossing( lht, lhp, 2 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(lht), len(lhp)\n",
      "lhp[ np.append( [False], lhp[1:]==lhp[:-1]) ]\n",
      "print len(T), len(Z)\n",
      "np.std( np.diff( lht ), ddof = 1 )-5.3e-05\n",
      "scaffolding_plot( T, X )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test(M=10) :\n",
      "    genr = synth_fbm( 2**12, .5 )\n",
      "    for i in xrange(M) :\n",
      "        T, X = genr()\n",
      "        mht, mhp, mhx = xtree_build( T, X, delta = 2**(-6) )\n",
      "\n",
      "%lprun -f xtree_integer_crossings_fast test( 50 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genr = synth_fbm( 2**10, .5 )\n",
      "for i in xrange(100) :\n",
      "    T, X = genr()\n",
      "    j2 = int( np.floor( np.log2( max( X ) - min( X ) ) ) )\n",
      "    base = float( 2**(j2-6) )\n",
      "    mht, mhp, mhx = xtree_build( T, X, delta = base )\n",
      "    ght, ghp, ghx = f_get_w( T, X, delta = 1, levels = range( j2-6, j2+1 ), deleteFirst=False )\n",
      "    for m,g in zip( mhp, ghp ) :\n",
      "        assert( not [ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ])\n",
      "    for m,g in zip( mht, ght ) :\n",
      "        assert( not [ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ])\n",
      "    for m,g in zip( mhx[1:], ghx ) :\n",
      "        assert( not [ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ])\n",
      "# print [len(x)-len(y) for x, y in zip( ghp, mhp )]\n",
      "# print [len(x)-len(y) for x, y in zip( ght, mht )]\n",
      "# print [len(x)-len(y) for x, y in zip( ghx, mhx[1:] )]\n",
      "# print [ np.nanmax(np.abs(m/g-1)) for m,g in zip( mht, ght ) ]\n",
      "# print [[ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ] for m,g in zip( mhp, ghp )]\n",
      "# print [[ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ] for m,g in zip( mht, ght )]\n",
      "# print [[ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ] for m,g in zip( mhx[1:], ghx )]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}