{
 "metadata": {
  "name": "",
  "signature": "sha256:edd8de1dacbf6bcab990a14af9c3b9d7b2f2f03c92bee5373b9c0ebfa16a4e9b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "<center>Studying self-similarity using the crossing tree</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<center>Nazarov Ivan</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<center>Supervisor: DeCrouez GG</center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Crossing times\n",
      "Suppose ${( t_i, x_i)}^N_{k=1}$ is a sample of some continuous process ${( X_t )}_{t\\in T}$ where $X_i = X(t_i)$.<!--, with $T\\subseteq \\mathbb{R}$ an inteval.-->\n",
      "\n",
      "The crossing times are defined as follows: for a given base grid spacing $\\delta>0$ and for $n,k\\geq0$ they are the stopping times $$T^n_{k+1} = \\inf\\Big\\{ t > T^n_k\\,: \\, \\big | X_t - X_{T^n_k} \\big | \\geq \\delta 2^n \\Big\\}$$ with $T^n_0 = 0$. The forcing of the zero-th xcrossing time to $0$ is done to align the grid with the process, so in effect, without losss of generality we may consider processes, which start at the origin.\n",
      "\n",
      "The parameter $\\delta$ is the spacing of the finest grid, with respect to which the leaves of the crossing tree are computed. Parent nodes of these leaves represent crossings of a coraser grid, namely $2\\delta$. The choice of $\\delta$ affects the tree in the following way in the case of a sampled process:\n",
      "**_THIS SECTION MUST BE DISCUSSED_**\n",
      "1. The grid with too low a value of $\\delta$ would be crossed by straight line segments between each pair consecutive sample observations. This could poison the distribution with some unfavouralbe yet unknown mixture and lead to excessive number of seemingly meaningless crossings.\n",
      "2. Too large $\\delta$ lead to a very poor and under sampled crossing tree.\n",
      "\n",
      "By construction, for a binary crossing grid, $N^l_k$, the number of subcrossings in any complete crossing between $T^l_k$ and $T^l_{k+1}$ is always an even number. This is due to the fact, that each crossing is registered as soon as two unidirectional subcrossings are encoutered, as seen by the following.\n",
      "\n",
      "Suppose $T^{n+1}_k$ and $T^n_m$ are aligned in that $T^{n+1}_k=T^n_m$, and $T^{n+1}_{k+1}<+\\infty$, i.e. the $n+1$ grid crossing is complete. First of all $T^n_{m+1},T^n_{m+2}\\leq T^{n+1}_{k+1}$, since otherwise the process would have crossed left the $\\pm\\delta 2^n$ band before it left the $\\pm \\delta 2^{n+1}$ band, which is twice as wide.\n",
      "\n",
      "The process is continuous which means that almost surely for any $\\epsilon>0$ there is $\\eta>0$ such that for any $t$ with $\\big|t-T^n_{m+1}\\big| < \\eta$ it holds that $\\big |X_{T^n_{m+1}}-X_t\\big|<\\epsilon$.\n",
      "Also for every $t\\in\\big[T^n_k, T^n_{k+1}\\big)$ it cannot be otherwise but $\\big | X_t - X_{T^n_k} \\big | < \\delta 2^n$. \n",
      "In particular, for $\\epsilon = \\frac{1}{2}\\delta 2^n$ it means that for a small while after $T^n_{m+1}$ the process is almost surely still within the $\\pm \\delta 2^{n+1}$ band. Therefore $T^n_{m+1} < T^{n+1}_{k+1}$.\n",
      "\n",
      "Thus it is true that $$1\\leq \\bigg | \\frac{1}{\\delta 2^n} \\big(X_{T^n_{m+1}} - X_{T^n_m}\\big)\\bigg | < 2$$. The next crossing of $\\pm\\delta 2^n$ takes palce at $T^n_{m+2}$ and there are two possibilities:\n",
      "1. the process crossed a new $\\pm\\delta 2^{n+1}$ grid line: $\\big|X_{T^n_{m+2}} - X_{T^n_m}\\big|\\geq 2\\cdot\\delta 2^n$. In this case $T^{n+1}_{k+1}\\leq T^n_{m+2}$ and there are _two_ subcrosings.\n",
      "2. the process moved back to the level $X_{T^n_m}$, which does not incurr a crossing of $\\pm\\delta 2^{n+1}$ grid line, yet is registered by the $\\pm\\delta 2^n$ grid. In this case $T^n_{m+2} < T^{n+1}_{k+1}$ and $X_{T^n_{m+2}} = X_{T^{n+1}_{k+1}}$ -- back to the beginning of this argument.\n",
      "\n",
      "Since the crossing is complete, $T^{n+1}_{k+1}<+\\infty$ implies that sooner that later a crossing of $\\pm\\delta 2^{n+1}$ grid occurs, in which case $T^{n+1}_{k+1}=T^n_{m+2p}$, meaning that there were exactly $2p$ subcrossings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "from synthfbmcircul import synth_fbm\n",
      "from hsssi_processes import *\n",
      "from Weierstrass import synth_Weier\n",
      "\n",
      "from crossing_tree import *\n",
      "from monte_carlo import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### A model of the offspring distribution\n",
      "\n",
      "Let's test the hypothesis that the number of subcrossings follows a distribution similar to geometric. Recall that $G$ is a geometrically distributed random variable, $G\\sim \\text{Geom}(\\theta)$, if $\\mathbb{P}(G=k) = {(1-\\theta)}^{k-1}\\theta$ for all $k\\geq1$. Other properties of geometrically dsitributed random variables include\n",
      " * Complimentary CDF $\\mathbb{P}(G\\geq k) = {(1-\\theta)}^{k-1}$ for any $k\\geq1$;\n",
      " * Expectation $\\mathbb{E}(G) = \\theta^{-1}$;\n",
      " * memorylessness.\n",
      "\n",
      "The number of offspring of any $\\delta 2^n$-grid crossing is the number of subcrossings of a finer grid with spacing $\\delta 2^{n-1}$ during a typical crossing.\n",
      "\n",
      "Our hypothesis is that $N$, the number of offspring, follows a geometric distribution on the even numbers, i.e. $\\frac{1}{2}N\\sim \\text{Geom}(\\theta)$. To test it we utilize a truncated geometric distribution with a fixed threshold $\\bar{k}$, beacuse this approach  naturally and easily handles unbounded random variables. Truncating the data effectively means that two kinds of observations are registered:\n",
      " * a value less than $\\bar{k}$;\n",
      " * an event $\\big\\{N\\geq \\bar{k}\\big\\}$, indicating that the value has not been less than $\\bar{k}$.\n",
      "Basically such trincated random variable behaves like a typical geometric one on the values $\\big\\{ \\left . 2m\\right \\rvert 2m < \\bar{k}\\big\\}$, but happens ot have an unusual concentration of probability at the upper truncation level $\\bar{k}$.\n",
      "\n",
      "Therefore for even integers $k=2,4,\\ldots\\bar{k}$ the distribution of the number of offspring is given by\n",
      "$$\\mathbb{P}(N=k) = {(1-\\theta)}^{\\frac{k}{2}-1}\\theta\\,1_{k<\\bar{k}} + {(1-\\theta)}^{\\frac{\\bar{k}}{2}-1}\\,1_{k = \\bar{k}}$$\n",
      "where $1_{(\\cdot)}$ -- is the $0-1$ indicator.\n",
      "\n",
      "#### Maximum Likelihhod Estimation\n",
      "\n",
      "Suppose ${(g_i)}_{i=1}^N$ a sample of independent geometric random variables, with distribution truncated by $\\bar{k}$. Due to truncation there is a finite numebr of distinct values that are observed in any given sample. Therefore it is convenient to represent every sample in an equivalent value-frequency form: ${\\Big(j, f_j\\Big)}$ for even $j$ not greater than $\\bar{k}$ and \n",
      "$f_j = \\bigg\\lvert\\big\\{\\big.i\\,\\big\\rvert\\,g_i=j\\big\\}\\bigg\\rvert$ -- the number of observations with the specified value. Without the loss of generality, $f_j$ can be set to zero for those $j$ that were not observed.\n",
      "\n",
      "The log-likelihood function is given by\n",
      "$$\\ln\\mathcal{L} = \\sum_{j\\neq \\bar{k}} f_j {\\Big(\\frac{j}{2}-1\\Big)} \\ln {(1-\\theta)} + \\sum_{j\\neq \\bar{k}} f_j \\ln \\theta + f_{\\bar{k}} {\\Big(\\frac{\\bar{k}}{2} - 1\\Big)} \\ln {(1-\\theta)}$$\n",
      "where the summation is done over the all possible distinct values. The first-order condition on optimal $\\theta$ is given by\n",
      "$$\\frac{d}{d \\theta} \\ln\\mathcal{L}\\,:\\quad-\\sum_j f_j {\\Big(\\frac{j}{2}-1\\Big)} \\frac{1}{1-\\theta} + \\sum_{j\\neq \\bar{k}} f_j \\frac{1}{\\theta} = 0$$\n",
      "This is equivalent to $\\frac{S-N}{1-\\theta} = \\frac{N-f_{\\bar{k}}}{\\theta}$, where $S = \\sum_j \\frac{j}{2} f_j$ and $N = \\sum_j f_j$ becasue the frequencies sum up to the the total number of observations. Therefore the desired ML estimator of the probability parameter $\\theta$ is\n",
      "$$\\hat{\\theta} = \\frac{N-f_{\\bar{k}}}{S-f_{\\bar{k}}}$$\n",
      "\n",
      "I strongly suspec that the MLE of the truncated geometric distribution is biased. If so, this renders it useless for monte-carlo estimation purposes. Clearly the bias should depend on the truncation threshold, and $\\hat{\\theta}_T \\to \\hat{\\theta}$ as $T\\to \\infty$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Given the agregated value-count data in X, compute the MLE of \\theta of the geometric distribution.\n",
      "## I think the MLE is biased... This renders averaging across simulations useselss.(\n",
      "def mle_theta( x ) :\n",
      "    N = np.sum( x )\n",
      "    S = np.dot( x, np.arange( 1, len( x ) + 1, dtype = np.float ) )\n",
      "    return ( N+1 - x[ -1 ] ) / ( S+1 - x[ -1 ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####The Monte Carlo routine\n",
      "The procedure below is performs the specified $M$ number of MonteCralo simulations of the sample paths of the process specified by the generator object. The paratmeters $K$ and $T$ determine the truncation performed while collecting the crossing tree data.  \n",
      "For example $K=4$ menas that subcrossings of size up to and including 4 are recorded in full detail, while every subcrossing of larger size is agregated and stored in the ``tail''.  \n",
      "\n",
      "Similarly for the parameter $T$, which set the threshold level of the crossing tree starting from the leaf level and up, beyond which the data is strored in aggregate manner."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## The Monte Carlo kernel performs a single experiment and returns its\n",
      "## K'xT slice of the result.\n",
      "def monte_carlo_kernel( generator, K, T, delta = None ) :\n",
      "## K is the maximal number of subcrossings beyond which the data\n",
      "##  on subcrossings is agregateed into the tail. (truncation parameter)\n",
      "\tK = 2 * ( K // 2 + 1 )\n",
      "## T is the number of detailed levels of the crossing tree to stored in\n",
      "##  output. Any crossings of grids coarser than the treshold are\n",
      "##  aggregated.\n",
      "\tdistr = np.zeros( ( T+1, K // 2 ), dtype = np.int )\n",
      "## The output of the ChSquared independence test\n",
      "# \tchisq = np.empty( ( ) )\n",
      "## Generate a replication of the process\n",
      "\tt, x = generator( )\n",
      "## G. Decrouez 2015-02-12: the selection of the spacing of the finest grid\n",
      "##  based on the scale of the process is crucial as it allows comparison\n",
      "##  of the crossing tree between different sample paths.\n",
      "\tif delta is None :\n",
      "## Set the base scale so that the constructed tree is 6 layers deep.\n",
      "\t\tdelta = 2**( np.floor( np.log2( np.max( x ) - np.min( x ) ) ) - 6 )\n",
      "## Get the hitting times and points\n",
      "\tht, hp, subx, excur = xtree_build( t, x, delta )\n",
      "#\tfor m,g in zip( mhp, hp ) :\n",
      "#\t\tassert( not [ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ] )\n",
      "## Run the chi_square test on each level of the tree\n",
      "##\tct = ctable( subx[ :-1 ], subx[ 1: ] )\n",
      "##\tchisq_test( ct )\n",
      "\tfor level, xing in enumerate( subx[1:], 0 ) :\n",
      "## Count the absolute frequencies\n",
      "\t\tc, f = np.unique( xing, return_counts = True )\n",
      "## We collect the data on the distribution truncated by K (including).\n",
      "## Thus truncate the number of subcrossings by K -- everything less is\n",
      "##  detailed, otherwise -- agregated into tail\n",
      "\t\tc = np.minimum( c, K )\n",
      "## Similarly truncate the level by T + 1\n",
      "\t\tif level >= T : level = T\n",
      "## Fill the offspring distribution matrix\n",
      "\t\tfor c, f in zip( c, f ) :\n",
      "\t\t\tdistr[ level, c // 2 - 1 ] += f\n",
      "## Use straightforward bivariate regression implementation.\n",
      "## We could also use ML estimators, which is much better!\n",
      "## See the handwritten notes.\n",
      "\treturn distr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Fractional Brownian Motion\n",
      "Let's have a look at the estiate of the parameter of the offspring distribution.\n",
      "We set up the grid with base spacing equal to $2^{-6}$, as has been done in Geoffrey's paper.\n",
      "\n",
      "The continuous processes are confined to the $[0,1]$ interval and their smaple paths are observed at discrete knots of the uniformly spaced lattice ${\\big(t_i\\big)}_{i=0}^{N-1}$ with $t_0=0$ and $t_1=1$. In effect every single Monte Carlo replication deals with a sample discretized path ${\\big(t_k, x_k\\big)}_{k=0}^{N-1}$ where $x_k = X(t_k)$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Set the size of the monte carlo experiment\n",
      "M = 10\n",
      "## Determine how many levels of the crosssing tree to keep\n",
      "T = 5\n",
      "## And set the truncation threshold so that subcrossings of size greater\n",
      "##  than or equal to 34 are put in the tail of the offspring distribution.\n",
      "K = 32\n",
      "## Set the time-precision of the sampled paths\n",
      "N = 2**18\n",
      "## Set the studied Hurst exponent\n",
      "H = .5\n",
      "## The base grid spacing is going to be 2^{-6}\n",
      "# delta = 2**(-6)\n",
      "## Setting \\delta to zero construct the tree for adaptive\n",
      "##  base spacing equal to the standard deviation of the increments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Study the Fractional Brownian motion.\n",
      "%lprun -f xtree_integer_crossings_fast res_fbm = monte_carlo_serial( synth_fbm( N, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Examine the properties of the Weierstrass-Mandelbrot process\n",
      "res_wei = monte_carlo_parallel( synth_Weier( N, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res_fbm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Finally have a look at the Rosenblatt process\n",
      "# res_ros = monte_carlo_parallel( synth_Rosenblatt( N // (2**6), H, K = 2**6 ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Save the results for later reuse\n",
      "import time as tm\n",
      "## Make a file with a timestamped name\n",
      "outfile = \"./MC m%d p%d h%.3f %s.npz\" % ( M, np.log2(N), H, tm.strftime(\"%Y%m%d-%H%M\") )\n",
      "\n",
      "## Save the copy of the monte carlo output\n",
      "np.savez( outfile, fbm = res_fbm, wei = res_wei )\n",
      "# np.savez( outfile, fbm = res_fbm, wei = res_wei, ros = res_ros )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Set the size of the monte carlo experiment\n",
      "M = 100\n",
      "## Determine how many levels of the crosssing tree to keep\n",
      "T = 5\n",
      "## And set the truncation threshold so that subcrossings of size greater\n",
      "##  than or equal to 34 are put in the tail of the offspring distribution.\n",
      "K = 32\n",
      "## Set the time-precision of the sampled paths\n",
      "N = 2**18\n",
      "## Set the studied Hurst exponent\n",
      "H = .85\n",
      "## The base grid spacing is going to be 2^{-6}\n",
      "# delta = 2**(-6)\n",
      "## Setting \\delta to zero construct the tree for adaptive\n",
      "##  base spacing equal to the standard deviation of the increments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Study the Fractional Brownian motion.\n",
      "res_fbm = monte_carlo_parallel( synth_fbm( N, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Examine the properties of the Weierstrass-Mandelbrot process\n",
      "res_wei = monte_carlo_parallel( synth_Weier( N, H ), monte_carlo_kernel, M = M, quiet = True, K = K, T = T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Save the results for later reuse\n",
      "import time as tm\n",
      "## Make a file with a timestamped name\n",
      "outfile = \"./MC m%d p%d h%.3f %s.npz\" % ( M, np.log2(N), H, tm.strftime(\"%Y%m%d-%H%M\") )\n",
      "\n",
      "## Save the copy of the monte carlo output\n",
      "np.savez( outfile, fbm = res_fbm, wei = res_wei )\n",
      "# np.savez( outfile, fbm = res_fbm, wei = res_wei, ros = res_ros )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " \n",
      " \n",
      " \n",
      " \n",
      " "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_probs( res ) :\n",
      "## Compute the empirical distribution function of the number of offspring \n",
      "    return np.apply_along_axis( lambda f : f * 1.0 / np.sum( f ), 2, res )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This procedure plots the empirical probability of observing a set number of offspring at each node of thw crossing tree."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mc_plot_empirical_probs( res, H, title = None ) :\n",
      "## Compute the probabilities\n",
      "    probs = get_probs( res )\n",
      "## In homage to the original code, call the mean probabilities and errors by PrZ and StZ\n",
      "    PrZ = np.mean( probs, axis = 0 )\n",
      "    StZ =  np.std( probs, axis = 0 )\n",
      "## Create an appropriate array of offspring values\n",
      "    offs = np.arange( 2, 2 * probs.shape[ 2 ] + 1, 2, np.float )\n",
      "## Create a new plot\n",
      "    plt.figure( 1, figsize = ( 8, 6 ) )\n",
      "    if title is not None :\n",
      "        plt.title( title )\n",
      "    theta = 2**(1.0-1.0/H)\n",
      "    offs_prb = (1.0-theta)**(offs//2-1)*theta\n",
      "    plt.plot( offs, np.log( offs_prb ), \"k-\", linewidth = 2, markersize = 15 )\n",
      "## Plot the logarithm of the probability of observing a given number of subcrossings \n",
      "    for i, c in zip( range( 0, probs.shape[ 2 ] ), [\"r\", \"g\", \"b\", \"y\"] ) :\n",
      "        plt.plot( offs, np.log( PrZ[i,:] ), \"o\" + c )\n",
      "#         plt.errorbar( offs, PrZ[i,:], yerr = StZ[i,:], color = c, linewidth = 0 )\n",
      "    plt.show( )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Simulation results\n",
      "Below interspersed with the listings of code are the results obtained so far for the corssing tree monte carlo simulation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mc_plot_empirical_probs( res_fbm, H, \"fBM %0.2f\" % ( H ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "outfiles = [ './MC m100 p18 h0.500 20150226-1252.npz', './MC m100 p18 h0.850 20150226-1301.npz']\n",
      "for outfile in outfiles :\n",
      "    opt = dict( ( x.group(1).upper(), float(x.group(2)) )\n",
      "        for x in re.finditer( r\"\\b([a-z])([-+]?(?:\\d+(?:\\.\\d*)?|\\.\\d+))\\b\", outfile ) )\n",
      "    with np.load( outfile ) as f_res :\n",
      "        res_fbm, res_wei = f_res['fbm'], f_res['wei']\n",
      "        # res_ros = f_res['ros']\n",
      "        mc_plot_empirical_probs( res_fbm, opt['H'], \"fBM %0.2f\" % ( opt['H'] ) )\n",
      "        mc_plot_empirical_probs( res_wei, opt['H'], \"WM %0.2f\" % ( opt['H'] ) )\n",
      "# mc_plot_empirical_probs( res_ros, \"Rosenblat %0.2f\" % ( H ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr/>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res_fbm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## The MC results array is MxTxK. Fixing axes 0 and 1, compute\n",
      "##  the ML estimate of the parameter over the axis 2 -- the within\n",
      "##  tree-level smaple of the offspring distribution.\n",
      "theta = np.apply_along_axis( mle_theta, 2, res_fbm )\n",
      "# mle_theta(DD[:,0,0])\n",
      "\n",
      "# np.save( \"./run 2b22 2015-02-14\", DD_par )\n",
      "# XX_par = np.load( \"./run 2b22 2015-02-14.npy\" )\n",
      "\n",
      "# np.max(np.abs(DD_par - XX_par))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot( theta[:,0], \"r-\")\n",
      "plt.plot( theta[:,1], \"b-\")\n",
      "plt.plot( theta[:,2], \"k-\")\n",
      "1/(1-np.log(np.mean(theta, axis=0)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot( 1/(1-np.log(theta[:,0])), \"r-\")\n",
      "plt.plot( 1/(1-np.log(theta[:,1])), \"b-\")\n",
      "plt.plot( 1/(1-np.log(theta[:,2])), \"k-\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mean_subx( x ) :\n",
      "    return np.dot( x, 2*np.arange( 1, len( x ) + 1, dtype = np.float ) ) / np.sum( x )\n",
      "\n",
      "moff = np.apply_along_axis( mean_subx, 2, res_fbm )\n",
      "plt.plot( moff[:,0], \"k-\")\n",
      "plt.plot( moff[:,1], \"b-\")\n",
      "plt.plot( moff[:,2], \"r-\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DD_par[:,2,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theta2 = np.apply_along_axis(mle_theta, 2, DD_par2)\n",
      "\n",
      "plt.plot( theta2[:,0], \"r-\")\n",
      "plt.plot( theta2[:,1], \"b-\")\n",
      "plt.plot( theta2[:,2], \"k-\")\n",
      "1/(1-np.log(np.mean(theta2, axis=0)))\n",
      "# DD_par2[:,:,3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scaffolding_plot( t, x ) :\n",
      "    ht, hp, xt = xtree_build( t, x )\n",
      "    l = len( ht ) - 5\n",
      "    plt.figure( figsize = (15, 8) )\n",
      "    plt.plot( t, x, \"y-\")\n",
      "# for p in tp[l] : plt.axhline( p, linewidth = 1, color = 'k' )\n",
      "    plt.step( ht[l+0], hp[l+0], \"g>\" ) #, where = 'mid' )\n",
      "    plt.step( ht[l+1], hp[l+1], \"b>\" ) #, where = 'mid' )\n",
      "    plt.step( ht[l+2], hp[l+2], \"r>\" ) #, where = 'mid' )\n",
      "    plt.step( ht[l+3], hp[l+3], \"k>\" ) #, where = 'mid' )\n",
      "    plt.show( )\n",
      "#     return [zip(*np.unique( x, return_counts = True)) for x in xt ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genr = synth_Weier(N, H)\n",
      "t,x = genr()\n",
      "plt.plot(t,x, \"y-\")\n",
      "scaffolding_plot(t,x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## The mean number of offspring\n",
      "## The empirical distribution of the subcrossings\n",
      "##  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Straighforward, dumb linear regression\n",
      "However, for the estimation purposes it is useful to worj with the complementary CDF, instead of the ``density'' itself:\n",
      "$$\\mathbb{P}(N\\geq k) = {(1-\\theta)}^k$$ this way no distinction between $k<\\bar{k}$ of $k=\\bar{k}$ needs to be done.\n",
      "\n",
      "For this purpose, let's estimate the following regression model: $$\\ln \\hat{p}_k \\sim C + \\beta k$$ where $\\hat{p}_k$ is the empirical probability that a crossing had no less than $k$ subcrossings and $\\beta = \\ln \\sqrt{(1-\\theta)}$.\n",
      "\n",
      "It is entirely posible that the distribution's shape depend on the depth. If it does, then there is no self similarity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import chi2_contingency as chisq_test\n",
      "def ctable( x, y ) :\n",
      "## This procedure makes a contingeny table out of x and y (they should be discrete)\n",
      "    lxy = np.append( x, y ).reshape( len( x ),2)\n",
      "    lxy = lxy.view(dtype = np.dtype([('x', x.dtype), ('y', y.dtype)]))\n",
      "    lc, lf = np.unique( lxy, return_counts = True )\n",
      "    print lc\n",
      "    xc = np.unique( x ) ; yc = np.unique( y )\n",
      "    txy = np.zeros( ( len( xc ), len( yc ) ), dtype = np.int )\n",
      "    vix = lc.view( ( np.int, len( lc.dtype ) ) )\n",
      "    ix = np.searchsorted( xc, vix[:,0] )\n",
      "    iy = np.searchsorted( yc, vix[:,1] )\n",
      "    txy[[ix, iy]] = lf\n",
      "    return txy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Appendix"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Testing on the deterministic cascade"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# scaffolding_plot( *genr( ) )\n",
      "def run() :\n",
      "    monte_carlo( genr, M=100, K = 16, T = 3 )\n",
      "%lprun -f xtree_integer_crossings_fast run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.plot(d[0,:], \"rx\", d[1,:], \"bx\", d[2,:], \"kx\")\n",
      "# f ~ a^(k-1)(1-a)\n",
      "# l\n",
      "plt.plot( range(2, 13, 2), np.log(np.mean( d, 1 )) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = 0\n",
      "for s in a[1:]:\n",
      "    plt.step( s[0], np.log( s[1] * 2**m ), \"b-\")\n",
      "    m+=1\n",
      "plt.step( a[1][0], np.log( a[1][1] ), \"r-\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 2**10\n",
      "H = .5\n",
      "\n",
      "# draw(synth_fbm( N, H ))\n",
      "# draw(synth_Weier( N, H ))\n",
      "# draw(synth_Rosenblatt( N, H ))\n",
      "# draw(synth_Hermite3( N, H ))\n",
      "# draw(synth_Hermite4( N, H ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Test the process generators\n",
      "def draw( gen, seed = None ) :\n",
      "\tt, u = gen( seed )\n",
      "\tt, v = gen( seed )\n",
      "\tplt.plot( t, u, \"r-\", t, v, \"b-\" )\n",
      "\tplt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Code testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genr = synth_fbm( 2**12, .5 )\n",
      "T, X = genr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mht, mhp, mhx, mex = xtree_build( T, X, delta = 2**(-6) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mex[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.sum( mex[3], axis = 1) * 2 + 2 - mhx[3]\n",
      "mex[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Weierstrass import *\n",
      "N = 2**15\n",
      "# T, X = genr()\n",
      "T, X = synthweier( N, 0.7, 1.2, 1000, deterministic = True, seed = None )\n",
      "T = np.arange(N, dtype=np.float)/ (N-1)\n",
      "\n",
      "delta = np.std( np.diff( X ), ddof = 1 )\n",
      "Z = ( X - X[ 0 ] ) / delta\n",
      "delta\n",
      "lht, lhp, lhx = xtree_integer_crossings_fast( T, Z )\n",
      "\n",
      "print len(lht), len(lhp)\n",
      "lhp[ np.append( [False], lhp[1:]==lhp[:-1]) ]\n",
      "print len(T), len(Z)\n",
      "np.std( np.diff( lht ), ddof = 1 )-5.3e-05\n",
      "scaffolding_plot( T, X )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ht, hp, hx = xtree_integer_crossings( T, Z )\n",
      "print np.max(np.abs(ht-lht))+np.max(np.abs(hp-lhp))\n",
      "lht, lhp, lhx = xtree_super_crossing( lht, lhp, 2 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test(M=10) :\n",
      "    genr = synth_fbm( 2**12, .5 )\n",
      "    for i in xrange(M) :\n",
      "        T, X = genr()\n",
      "        mht, mhp, mhx = xtree_build( T, X, delta = 2**(-6) )\n",
      "\n",
      "%lprun -f xtree_integer_crossings_fast test( 50 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genr = synth_fbm( 2**10, .5 )\n",
      "for i in xrange(100) :\n",
      "    T, X = genr()\n",
      "    j2 = int( np.floor( np.log2( max( X ) - min( X ) ) ) )\n",
      "    base = float( 2**(j2-6) )\n",
      "    mht, mhp, mhx = xtree_build( T, X, delta = base )\n",
      "    ght, ghp, ghx = f_get_w( T, X, delta = 1, levels = range( j2-6, j2+1 ), deleteFirst=False )\n",
      "    for m,g in zip( mhp, ghp ) :\n",
      "        assert( not [ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ])\n",
      "    for m,g in zip( mht, ght ) :\n",
      "        assert( not [ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ])\n",
      "    for m,g in zip( mhx[1:], ghx ) :\n",
      "        assert( not [ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ])\n",
      "# print [len(x)-len(y) for x, y in zip( ghp, mhp )]\n",
      "# print [len(x)-len(y) for x, y in zip( ght, mht )]\n",
      "# print [len(x)-len(y) for x, y in zip( ghx, mhx[1:] )]\n",
      "# print [ np.nanmax(np.abs(m/g-1)) for m,g in zip( mht, ght ) ]\n",
      "# print [[ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ] for m,g in zip( mhp, ghp )]\n",
      "# print [[ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ] for m,g in zip( mht, ght )]\n",
      "# print [[ i for i, e in enumerate( zip( m, g ) ) if e[0]!=e[1] ] for m,g in zip( mhx[1:], ghx )]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}