\documentclass[a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage[russian, english]{babel}

% \usepackage{fullpage}
% \linespread{1.5}

\usepackage{graphicx, url}
\usepackage{amsmath, amsfonts, xfrac}
\usepackage{mathtools}

% \usepackage{natbib}

\newcommand{\Real}{\mathbb{R}}
\newcommand{\Cplx}{\mathbb{C}}

\newcommand{\pr}{\mathbb{P}}
\newcommand{\ex}{\mathbb{E}}
\newcommand{\var}{\text{var}}
\newcommand{\Pcal}{\mathcal{P}}

\newcommand{\defn}{\mathop{\overset{\Delta}{=}}\nolimits}
\newcommand{\lpto}{\mathop{\overset{L^p}{\to}}\nolimits}

\newcommand{\re}{\operatorname{Re}\nolimits}
\newcommand{\im}{\operatorname{Im}\nolimits}

\newcommand{\eng}[1]{\foreignlanguage{english}{#1}}

\newcommand{\rus}[1]{\foreignlanguage{russian}{#1}}
% \selectlanguage{english}

\title{Studying Self-similar Processes Using the Crossing Tree}
\author{Nazarov Ivan, \rus{101мНОД(ИССА)}}

\begin{document}
\pagenumbering{gobble}
%% Russian title page
\selectlanguage{russian}
\include{titlepage--rus}
\clearpage

%% English title page
\selectlanguage{english}
\include{titlepage}
\clearpage

%% Draft title page
\selectlanguage{english}
\maketitle
\begin{abstract}
\textbf{Shamelessly copied from Geoffrey's project ptich}.\hfill \\
Time-series data presenting scale invariance do not posses a well-defined time scale.
Instead, their dynamics are understood when studied across a whole range of scales.
Examples of data with empirical scale-invariance include network traffic, financial
time-series, and other natural phenomena in physics and biology. The crossing-tree
is a recent tool to analyze this kind of signals. It provides an ad-hoc representation
of the data which is adapted to its dynamics, and thus represents an alternative to
wavelet decompositions. In this project, the student will first learn about scale
invariance, and how the crossing-tree has been used previously as a tool to analyze
self-similar signals. The next step is to analyze self-similar processes with stationary
increments (known as H-SSSI processes) using the crossing tree. It is expected that
for this class of processes, the crossing tree presents common features which need
to be extracted.
\end{abstract}

\selectlanguage{english}
\tableofcontents
\clearpage
\pagenumbering{arabic}

%% The project itself
\selectlanguage{english}

\chapter*{Introduction} % (fold)
\label{cha:introduction}

% chapter* introduction (end)

\chapter{Crossing tree formalism} % (fold)
\label{cha:crossing_tree_formalism}

\section{the Crossing tree} % (fold)
\label{sec:the_crossing_tree}

Brief history in the literature. Cite the original papers \cite{jones2004}
and \cite{jonesshen2005}.

\subsection{Definition} % (fold)
\label{sub:definition}

Consider a path of real-valued continuous process $(X_t)_{t\in T}$ on $T = [0,+\infty)$.
Let $(G_n)_{n\geq0}$ be a collection of increasingly coarser uniformly spaced grids
on $\Real$ centred at $x_0\in \Real$ given by $G_n = x_0 + \delta 2^n \mathbb{Z}$
for any $n\geq 0$ and some base grid spacing $\delta>0$.\footnotemark
Each element of this family of nested grids represents the ``resolution'' through
which sample paths of $X_t$ are studied.
\footnotetext{ The addition $x_0+A$, for $A$ in an affine space such as $\Real$
represents shifting of every element of the set $A$ by a common value $x_0$.}

At the heart of the crossing tree lie crossing times of each particular grid $G_n$
properly aligned by $x_0$. The crossing times $T_k^n$ of process $X_t$ of grid $n\geq 0$
are its first passage times across a line of grid $G_n$ centred at $X(0)$ that is
different from a previously crossed line of the same grid. Formally $T_k^n$ are
defined as follows: let $T_0^n=0$ and for $k\geq 0$ put
\[
T_{k+1}^n = \inf \Bigl\{
	s > T^n_k \Bigr\rvert\,
	\Bigl.\bigr | X_s - X_{T^n_k} \bigr | \geq \delta 2^n \Bigr\}
\]
The forcing of the zero-th crossing time to $0$ automatically aligns the grid $G_n$
with the process, so in effect, without loss of generality one may consider processes
$X_t$, which start at the origin $X(0) = 0$.

%%%% Discuss subcrossings
%%%% More or less relevant
By construction, for a binary crossing grid, $N^l_k$, the number of subcrossings in
any complete crossing between $T^l_k$ and $T^l_{k+1}$ is always an even number. This
is due to the fact, that each crossing is registered as soon as two unidirectional
subcrossings are encountered, as seen by the following.

Suppose $T^{n+1}_k$ and $T^n_m$ are aligned so that $T^{n+1}_k=T^n_m$ and
$T^{n+1}_{k+1}<+\infty$, i.e. the $k$-th crossing of the $n+1$ grid is complete.
First of all, $T^n_{m+1}, T^n_{m+2} \leq T^{n+1}_{k+1}$, since otherwise the process
would have left the $\pm \delta 2^n$ band before it left the $\pm \delta 2^{n+1}$
band, which is twice as wide.

The process is continuous at $T^n_{m+1}$ which means that almost surely for any
$\epsilon>0$ there is $\eta>0$ such that for any $t$ with $\bigl|t - T^n_{m+1}\bigr| < \eta$
it holds that $\bigl|X_{T^n_{m+1}} - X_t \bigl| < \epsilon$. Also for every $t \in \bigl[ T^n_k, T^n_{k+1} \bigr)$
it cannot be otherwise but $\big | X_t - X_{T^n_k} \big | < \delta 2^n$.  In particular,
for $\epsilon = \frac{1}{2}\delta 2^n$ it means that for a small while after $T^n_{m+1}$
the process is almost surely still within the $\pm \delta 2^{n+1}$ band. Therefore
\[ T^n_{m+1} < T^{n+1}_{k+1} \]
and a crossing of a finer grid occurs almost surely before the crossing of a coarser
grid. Thus it is true that 
\[ 1 \leq \biggl| \frac{1}{\delta 2^n} \bigl( X_{T^n_{m+1}} - X_{T^n_m} \bigr) \biggr| < 2 \]

\noindent The next crossing of $\pm\delta 2^n$ takes place at $T^n_{m+2}$ and there
are two possibilities:
\begin{enumerate}
	\item the process crossed a new $\pm\delta 2^{n+1}$ line of $n+1$-st grid: 
	\[ \big|X_{T^n_{m+2}} - X_{T^n_m}\big|\geq 2\cdot\delta 2^n\] in which case
	$T^{n+1}_{k+1}\leq T^n_{m+2}$ and there are \emph{two} subcrosings in a crossing
	of grid $n+1$.
	\item the process moved back to the level $X_{T^n_m}$, which does not incur a
	crossing of $\pm\delta 2^{n+1}$ grid line, yet is registered by the $\pm\delta 2^n$
	grid. In this case $T^n_{m+2} < T^{n+1}_{k+1}$ and $X_{T^n_{m+2}} = X_{T^{n+1}_{k+1}}$,
	which brings one back to the beginning of this argument.
\end{enumerate}

Since the crossing is complete, $T^{n+1}_{k+1} < +\infty$ implies that sooner or later
a crossing of $\pm\delta 2^{n+1}$ grid occurs, in which case $T^{n+1}_{k+1} = T^n_{m+2p}$,
meaning that there were exactly $2p$ subcrossings in a crossing of grid $n+1$.

%%%% Given this relationship between the crossing times of neighbouring grid
%%%% contruct a crossing tree.
The exposed relationship between the crossing times enables a natural construction
of a crossing tree: each crossing of grig $n$ is a child of a grander crossing of
grid $n+1$, during which it took place.

%%%% Rewrite, as it is irrelevant
The parameter $\delta$ is the spacing of the finest grid, with respect to which
the leaves of the crossing tree are computed. Parent nodes of these leaves represent
crossings of a coarser grid, namely $2\delta$. The choice of $\delta$ affects the tree
in the following way in the case of a sampled process:
\begin{itemize}
	\item the grid with too low a value of $\delta$ would be crossed by straight
	line segments between each pair of consecutive sample observations. This could
	poison the distribution with some unfavourable yet unknown mixture and leads
	to excessive number of seemingly meaningless crossings.
	\item Too large $\delta$ leads to a very poor and under sampled crossing tree.
\end{itemize}


\noindent \textbf{A model of the offspring distribution} \hfill \\

Let's test the hypothesis that the number of subcrossings follows a distribution
similar to geometric. Recall that $G$ is a geometrically distributed random variable,
$G\sim \text{Geom}(\theta)$, if $\mathbb{P}(G=k) = {(1-\theta)}^{k-1}\theta$ for all
$k\geq1$. Other properties of geometrically distributed random variables include
\begin{itemize}
	\item Complimentary CDF $\mathbb{P}(G\geq k) = (1-\theta)^{k-1}$ for any $k\geq1$;
	\item Expectation $\mathbb{E}(G) = \theta^{-1}$;
	\item Memorylessness: for $m\geq 0$
	\begin{align*}
		\pr\bigl( G \geq n + m \bigr\rvert\bigl. G \geq n \bigr)
		&= \frac{\pr(G \geq n+m)}{\pr(G \geq n)} = \frac{(1-\theta)^{n+m-1}}{(1-\theta)^{n-1}} \\
		& = (1-\theta)^{m-1} = \pr(G \geq m)
	\end{align*}
\end{itemize}

The number of offspring of any $\delta 2^n$-grid crossing is the number of subcrossings
of a finer grid with spacing $\delta 2^{n-1}$ during a typical crossing.

Our hypothesis is that $N$, the number of offspring, follows a geometric distribution
on the even numbers, i.e. $\frac{1}{2}N \sim \text{Geom}(\theta)$. To test it we
utilize a truncated geometric distribution with a fixed threshold $\bar{k}$, because
this approach naturally and easily handles unbounded random variables. Truncating the
data effectively means that two kinds of observations are registered:
\begin{itemize}
	\item a value less than $\bar{k}$;
	\item an event $\big\{N\geq \bar{k}\big\}$, indicating that the value has not
	been less than $\bar{k}$.
\end{itemize}
Basically such truncated random variable behaves like a typical geometric one on
the values $\bigl\{ 2m \bigr\rvert \bigl. 2m < \bar{k}\bigr\}$, but happens to have
an unusual concentration of probability at the upper truncation level $\bar{k}$.

Therefore for even integers $k=2,4,\ldots\bar{k}$ the distribution of the number
of offspring is given by
\[
\mathbb{P}(N=k)
= (1-\theta)^{\frac{k}{2}-1} \theta 1_{k<\bar{k}}
+ (1-\theta)^{\frac{\bar{k}}{2}-1} 1_{k = \bar{k}}
\]
where $1_{(\cdot)}$ -- is the $0-1$ indicator.

\noindent \textbf{Maximum Likelihood Estimation} \hfill \\
Suppose ${(g_i)}_{i=1}^N$ a sample of independent geometric random variables, with
distribution truncated by $\bar{k}$. Due to truncation there is a finite number of
distinct values that are observed in any given sample. Therefore it is convenient to
represent every sample in an equivalent value-frequency form: ${\bigl(j, f_j\bigr)}$
for even $j$ not greater than $\bar{k}$ and 
$f_j = \Bigl| \bigl\{ i\bigr\rvert \bigl.g_i = j\bigr\}\Bigr|$ -- the number of
observations with the specified value. Without the loss of generality, $f_j$ can
be set to zero for those $j$ that were not observed.

The log-likelihood function is given by
\[
\ln\mathcal{L}
= \sum_{j\neq \bar{k}} f_j \Bigl(\frac{j}{2}-1\Bigr) \ln(1-\theta)
+ \sum_{j\neq \bar{k}} f_j \ln \theta
+ f_{\bar{k}} \Bigl( \frac{\bar{k}}{2} - 1 \Bigr) \ln(1-\theta)
\]
where the summation is done over the all possible distinct values. The first-order
condition on optimal $\theta$ is given by
\[
\frac{d}{d \theta} \ln\mathcal{L} \,:\quad
-\sum_j f_j \Bigl(\frac{j}{2}-1\Bigr) \frac{1}{1-\theta} + \sum_{j\neq \bar{k}} f_j \frac{1}{\theta} = 0
\]
This is equivalent to $\frac{S-N}{1-\theta} = \frac{N-f_{\bar{k}}}{\theta}$, where
$S = \sum_j \frac{j}{2} f_j$ and $N = \sum_j f_j$ because the frequencies sum up to
the total number of observations. Therefore the desired ML estimator of the probability
parameter $\theta$ is
\[ \hat{\theta} = \frac{N-f_{\bar{k}}}{S-f_{\bar{k}}} \]

I strongly suspect that the MLE of the truncated geometric distribution is biased. If so,
this renders it useless for Monte-Carlo estimation purposes. Clearly the bias should depend
on the truncation threshold, and $\hat{\theta}_T \to \hat{\theta}$ as $T\to \infty$.

%%%%%%%%%%%%

sampled at times $(t_i)_{i=0}^N$ with $t_0=0$ and $t_i<t_{i+1}$.

Denote a sample path of a real-valued continuous process by ${(t_i, x_i)}_{k=0}^N$
anchored $X_0 = 0$ with $t_0 = 0$ and $X_i = X(t_i)$.

% subsection definition (end)

\subsection{Practical construction} % (fold)
\label{sub:practical_construction}

% subsection practical_construction (end)

% section the_crossing_tree (end)

\section{Stochastic self-similarity} % (fold)
\label{sec:stochastic_self_similarity}

\subsection{General definition} % (fold)
\label{sub:general_definition}

For self-ssimilarity and H-ss see \cite{embrechtsselfsimilar} pp. 1-3 and \cite{embrechts2000introduction} pp. 2-5, 19

% subsection general_definition (end)

\subsection{Hurst self-similar stochastic processes} % (fold)
\label{sub:hurst_self_similar_stochastic_processes}

% subsection hurst_self_similar_stochastic_processes (end)

% section stochastic_self_similarity (end)

\section{Fractional Brownian Motion} % (fold)
\label{sec:fractional_brownian_motion}

For BM and FBM refer to \cite{embrechtsselfsimilar} pp. 4-5 and \cite{embrechts2000introduction} pp. 5-8

\subsection{Definiton} % (fold)
\label{sub:definiton}
Brief history, relation to H-SSSI processes.

Mention that BM is fBM for $H=0.5$.

\subsubsection{Sample paths} % (fold)
\label{ssub:sample_paths}

Reference the generation circulant embedding generation algorithm with complexity.

% subsubsection sample_paths (end)

% subsection definiton (end)

% section fractional_brownian_motion (end)

\section{Brownian Motion} % (fold)
\label{sec:brownian_motion}

\section{Literature review} % (fold)
\label{sec:literature_review}
Reviewed papers \cite{jones2004}, \cite{jonesshen2005} and \cite{decrouez2013}.

% section literature_review (end)

\subsection{Properties of the crossing tree} % (fold)
\label{sub:properties_of_the_crossing_tree}

% subsection properties_of_the_crossing_tree (end)

\subsection{Simulation study} % (fold)
\label{sub:simulation_study_bm}

% subsection simulation_study_bm (end)

% section brownian_motion (end)

\section{Conjecture for FBM with $H\in (\sfrac{1}{2},1)$} % (fold)
\label{sec:conjecture_for_fbm}

\subsection{Statement} % (fold)
\label{sub:statement}

% subsection statement (end)

\subsection{Simulation study} % (fold)
\label{sub:simulation_study_fbm}

See the paper by Owen Jones and Shen (2005) for the outline.

Each MonteCarlo realisation generates a discretized sample path $(t_i, X_i)_{i=0}^N$ of
a particular continuous stochastc process $X(t)$, where $X_i = X(t_i)$ and $(t_i)_{i=0}^N\in [0,1]$
is a uniformly spaced mesh with
\[0 = t_0 \geq \ldots \geq t_i < t_{i+1} \geq \ldots \geq t_N = 1\]

Main plots: let $\Delta X_i = X_i - X_{i-1}$ for $i=1,\ldots, N$.
\begin{itemize}
	\item for $\delta = \text{std}\bigl(\Delta X_i \bigr)$, where $\text{std}(Y^n)$ is
	the square root of the unbiased sample estimator of varaince of $Y$:
	\[ \text{std}(Y^n) = \sqrt{ \frac{1}{n-1} \sum_{i=1}^n \bigl( Y_i - \bar{Y}_n \bigr)^2 }\]
	and $\bar{Y}_n$ is tha sample mean: $\bar{Y}_n = \frac{1}{n}\sum_{i=1}^n Y_i$. 

	\item for $\delta = \text{iqr}\bigl(\Delta X_i \bigr)$, where $\text{iqr}(Y^n)$ is
	the \textbf{i}nter\textbf{q}uartile \textbf{r}ange of the sample $Y^n = (Y_i)_{i=1}^n$
	defiend as the difference of the $75\%$ and the $25\%$ sample quartiles of the sample:
	\[\text{iqr} = \hat{F}^{-1}_n\Bigl(\frac{3}{4}\Bigr) - \hat{F}^{-1}_n\Bigl(\frac{1}{4}\Bigr)\]
	where $\hat{F}^{-1}_n(p)$ is the generalized inverse of the empirical CDF of the sample $Y^n$
	given by
	\[\hat{F}_n(y) = \frac{1}{n} \sum_{i=1}^n 1_{(-\infty,y]}(Y_i)\]
	Ratinale for the IQR is that it is robust (this is poor!).
	\item for $\delta = \hat{F}^{-1}_n\Bigl(\frac{3}{4}\Bigr)$ -- the $75\%$ empirical qauntile of
	the process of increments $(\Delta_i)_{i=1}^N$.
\end{itemize}

Each group of plots should have: \begin{itemize}
	\item a plot of subcrossing distribution averaged across the MC realisations with
	the theoretical values;
	\item add histograms of $\pr(Z_n = 2k)$ (separately for $k=1,2,\ldots$) with
	superimposed theoretical $\theta = 2^{1-H^{-1}}$ and averaged values;
	$Z\sim\text{Geom}$ with porbability given by
	\[\pr(Z = 2k) = (1-\theta)^{k-1} \theta\]
	for $k\geq 1$.
	\item a table of excursion distribution averaged across the MC realisations;
	\item add histograms of $\pr(+-|++)$ and $\pr(+-|--)$ with superimposed theoretical
	and averaged values. Let $\mu = \ex Z$, which is $\frac{2}{\theta}$. Then the
	hypothesized probability of an up-down excursion $\delta 2^n$ in an upcrossing
	of resolution $\delta 2^{n+1}$ is $\frac{1}{\sqrt{\mu}}$.
\end{itemize}

% subsection simulation_study_fbm (end)

\subsection{Discussion} % (fold)
\label{sub:discussion}

% subsection discussion (end)

% section conjecture_for_fbm (end)

%% End of the report: lists of object and references
% \clearpage \listoffigures
% \clearpage \listoftables

\clearpage

\selectlanguage{english}

% \bibliographystyle{amsplain}
\bibliographystyle{ugost2008ls}
\bibliography{literature}

%% Supplementary material
% \selectlanguage{english}
% \include{appendix}

\end{document}
