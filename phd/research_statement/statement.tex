\documentclass{extarticle}
\usepackage{graphicx}

\usepackage{amsmath, amsfonts, amssymb, amsthm}

\newcommand{\ex}{\mathop{\mathbb{E}}\nolimits}

\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Xcal}{\mathcal{X}}
\newcommand{\Ycal}{\mathcal{Y}}
\newcommand{\Zcal}{\mathcal{Z}}

\newcommand{\Real}{\mathbb{R}}

\newcommand{\one}{\mathbf{1}}

\title{Research statement}
\author{Nazarov I.N.}

\begin{document}
\maketitle
\begin{abstract}
Many data-intense applied fields such as maintenance of complex systems, structural
integrity monitoring, diagnostic medicine, intrusion detection, and anti-fraud solutions
in banking and many others, require that it be possible to decide if the new data
diverges in some sense from the previously seen observations. Thus, I plan to focus
my PhD research primarily on developing a general framework for anomaly detection
which would provide a rigorous definition of an anomaly, a notion of detection precision
and a method for determining the amount of observations needed for the required precision.
My secondary goal is to design efficient procedures for distribution-free confidence
measures for various ML algorithms, and provide necessary theoretical basis for
their coverage guarantees and efficiency. The recent results of my numerical study
of conformal confidence intervals for kernel ridge regression have been accepted
to ICMLA 2016.
\end{abstract}

\section{Relevance} % (fold)
\label{sec:relevance}
% задача детектирования аномалий важна. Однако, в настоящее время появилось много
% прикладных ситуаций, типов данных и т.п., для которых:
%     а) надо развивать новые методы;
%     б) изучать теор. свойства методов.
% Кроме того, надо законченной мат. модели/теории о том, что такое аномалия, как
% оценивать качество детектирования аномалий и прогнозирования поломок. 

Anomaly detection is concerned with identifying observations in new incoming test
data, which diverge in a some sense from the previously seen data. Problems of this
nature arise in many applied fields such as predictive maintenance of complex industrial
systems \cite{tarassenko2009}, on-site structural integrity monitoring \cite{surace2010},
cancer detection based on screening data in diagnostic medicine \cite{tarassenko1995,quinn2007,clifton2011},
intrusion detection in data and general security \cite{jyothsna2011}, anti-fraud
solutions in banking and monitoring of insider trading in market regulation \cite{patcha2007},
et c.

Anomaly detection can be split in two categories: density-based and regression-based
methods, -- however there is no clearcut distinction between categories.

Regression-based approach encompass such models as multilayer neural networks for
supervised \cite{augusteijn2002}, and replicating neural networks, autoencoders
for unsupervised learning tasks \cite{hawkins2002,williams2002}. Spectral methods
infer combinations of input features, that comprehensively describe the variability
of the data separate anomalous from normal \cite{chandola2009}. Manifold-based
methods include approximation with principal components, \cite{dutta2007,shyu2003},
and \cite{jolliffe2014}, or more general non-linear kernel based representations,
\cite{hoffmann2007,scholkopf1998}. These methods produce a compact low-dimensional
internal representation of the data and use its' predictive or reconstructive properties
to derive abnormality scores.

In \cite{breunig2000} a density-based anomaly detection method based on a Local Outlier
Factor (LOF) score was suggested, which is estimated with respect to local topology,
defined by a metric neighbourhood containing at least the required number of data
points. This method relates the tightness of a point's closest neighbourhood to the
average across its neighbours. Original LOF does not provide confidence measure of
abnormality, which is why \cite{kriegel2009} suggested the ``LoOP'' (local outlier
probability) method. LoOP is similar in spirit to LOF, but yields probabilistic
estimates of confidence based in the same idea of tightness of the observations's
immediate locality.

% section relevance (end)

\section{General anomaly detection} % (fold)
\label{sec:general_anomaly_detection}

% Разработать некоторый general framework, в рамках которого можно было бы формулировать,
% что такое аномальность, точность обнаружения аномалий, и оценивать, какой размер
% выборки нужен для получения заданной точности, сравнивать эффективности различных
% методов обнаружения аномалий.

Each of the applications uses negative definition of abnormality: ``abrnormal'' is
something which is not ``normal'' in a particular domain. In security and finance
``normal'' is understood as strict compliance with some regulation or protocol, in
engineering and medicine ``normal'' is within the acceptable band of a nominal regime
of a machine or the usual phenomenology of a subject. In each of theses tasks it is
assumed that the majority of the observed data are ``normal'', and only a minute
fraction of it is ``anomalous'', which is why most methods of define an anomaly
as a substantial deviation form the internal representation of a ``normal'' pattern.
For instance, regression-based methods rely on the learnt feature-target relationship,
whereas density-based anomaly detectors use modes of the estimated data generating
distribution or the reconstructed manifold carrying the data.

In my thesis I plan to develop a general framework formalizing anomaly detection
problems which would include\begin{itemize}
  \item a rigorous definition of an anomaly and notion of detection precision;
  \item a method for determining the least amount of observations needed for the
  required detection precision;
  \item tools necessary for comparing efficiency of various detection methods.
\end{itemize}

% section general_anomaly_detection (end)

\section{Regression-based anomaly detection} % (fold)
\label{sec:regression_based_anomaly_detection}

% 2. Далее, надо написать, что одним из важных подходов детектирования аномалий является
% подход на основе virtual sensor, то есть у нас есть некоторая характеристика (например,
% мощность, производимая элетростнацией). Измеряются характеристики, которые характеризуют
% работу отдельных частей станции. Мы могли бы построить регрессионную модель, которая
% прогнозирует мощность в зависимости от этих характеристик, и, если сначала ошибка
% прогноза была мала, а потом - велика, мы могли бы понять, что начали происходить
% потери мощности, и понять - из-за каких параметров, что позволило бы нам выяснить
% причины поломки. Однако, чтобы решать такую задачу, нужен не только регрессионный
% метод, но и метод, который позволяет непараметрическим образом эффективно строить
% доверительные интервалы. Цель решения данной задачи
%     а) непараметрический метод построения дов. интервалов нелинейной регрессии на
%     основе ядерных методов;
%     б) сравнение его со стандартными методами;
%     в) изучение теор. свойств, в частности, эффективности.
% Пишите, что уже есть задел, подана статья на конф.

Supervised regression-based methods allow modelling of complex interactions between
features of the data, yet do not readily yield any sort of prediction confidence
measure, unless distributional assumptions are introduced. One method to keep them
distribution-free is to employ ``conformal prediction'' approach developed in \cite{vovk2005}.
Under the standard independence assumption it constructs a set that contains yet
unobserved data with a pre-specified confidence level. In essence, conformal prediction
amounts to the following: for every possible value $z$ of an object $Z_{n+1}$ the
procedure tests $H_0: Z_{n+1}=z$, and then inverts the test to get a confidence
region. The hypothesis tests are based on the observed sample $(Z_i)_{i=1}^n$ and
hypothesized $z$, and are designed to have a pre-specified type-I error rate.

In my PHD thesis I would like to continue the work on the Conformalized Kernel Ridge
regression, that, in contrast to the Gaussian Process regression, produces prediction
confidence intervals without any distributional assumptions. More specifically I
would like to focus on: \begin{enumerate}
  \item designing efficient conformal procedures for endowing other kernel-based
  ML algorithms with distribution-free prediction confidence measures;
  \item providing necessary theoretical basis for coverage guarantees and efficiency
  compared to related state-of-the-art Bayesian methods.
\end{enumerate}

In this vein I co-authored an accepted paper for the upcoming ICMLA 2016 conference,
in which I outline the results of an extensive numerical study concerning both coverage
and efficiency issues of the Conformalized Kernel Ridge regression.

% section regression_based_anomaly_detection (end)

\section{Density-based anomaly detection} % (fold)
\label{sec:density_based_anomaly_detection}

% Следующий пункт - есть много методов детектирования аномалий, например, LoOF, LOP и
% т.п. Они так или иначе основаны на некотором "инженерном" способе определить, что
% новое наблюдение попало в регион, где мало наблюдений выборки.
% Однако, надо самом
% деле надо по сути определять, что наблюдение порождено распределнием, отличным от
% распределения, которое породило основную часть выборки. По этой причине имеет смысл
% применять kernel mean embedding и т.п. (ну в общем, то, что вы делали в дипломе).
% Цель решения данной задачи
%     а) разработать непараметрический метод обнаружения аномалий, который не полагается
%     на какие-либо определения того, что такое аномалия;
%     б) сравнить его со стандартными методами;
%     в) изучить его теор. свойства, в частности, эффективность.

Unsupervised anomaly detection in essence boils down to determining how likely it
is that an observation was generated from the ``normal regime'' distribution. For
instance, density-based methods define the normal regime distribution simply as
the modes of the data distribution inferred from the training data. Bayesian outlier
detection techniques models use prior distributions and data-generating model to
compute the posterior of a new observation given the already observed data.

One promising research direction is conformal procedures for kernel embeddings of
probability distributions introduced \cite{smola2007}. Basically, in a suitable
Reproducing Kernel Hilbert Space (RKHS) many non-pathological distributions on metric
spaces can be identified with a unique element of the said RKHS. Specifically, if
$K$ is a kernel that induces a universal real RKHS $\Hcal$ then for any probability
distribution $P$ on $\Xcal$ with $\ex_{x\sim P} \sqrt{K(x,x)} < +\infty$ there is
a unique representative $\mu_P\in \Hcal$ such that $\ex_{x\sim P} f(x) = \langle \mu_P, f\rangle$
for all $f\in \Hcal$ and
\begin{equation*}
  \mu_P(x) = \langle \mu_P, K(x, \cdot) \rangle = \ex_{y\sim P} K(x, y) \,.
\end{equation*}

A possible anomaly detection method stems from the fact that if $\Xcal$ is a compact
metric then the distributions $P$ and $Q$ coincide if and only if $\ex_P f = \ex_Q f$
for all continuous and bounded $f:\Xcal\mapsto \Real$. For example, based on this
\cite{gretton2012} propose the \textit{maximum mean discrepancy} (MDD) -- an effective
non-parametric criterion for comparing distributions by measuring the norm of the
deviation of their kernel embeddings. Analogously, in order to decide the abnormality
of $z_n$ with respect to a given sample $Z_{:n-1} = (z_i)_{i=1}^{n-1}$ it is could
be sufficient to compute $\|\hat{\mu}_{:n} - \hat{\mu}_{:n-1}\|$, where
\begin{equation*}
  \hat{\mu}_{:n}(x) = \ex_{z\sim Z_{:n}} K(x, z) = n^{-1} \sum_{i=1}^n K(x, z_i) \,,
\end{equation*}
the kernel mean embedding of the empirical distribution of $Z_{:n}$.

Another approach to this problem is to use recent results from \cite{Baktashmotlaghetal2016}
which uses kernel embeddings to construct a low dimensional invariant representation
of the observed data to tackle the domain shift problem (domain adaptation). For
example, it could be possible to construct a map such that the distribution of observed
data looks the closest to a multivariate Gaussian, and then define normal regions
via elliptical confidence regions. To this end in my PHD thesis I propose to:
\begin{itemize}
  \item further study the properties and theoretical guarantees of anomaly detection
  based on conformalized kernel embeddings;
  \item develop an approach based on the ideas from domain adaptation and establish
  its theoretical soundness.
\end{itemize}

% section density_based_anomaly_detection (end)

% \bibliographystyle{amsplain}
\clearpage
\bibliographystyle{ugost2008ls}
\bibliography{references}

\end{document}
