\documentclass{extarticle}
\usepackage{graphicx}

\usepackage{amsmath, amsfonts, amssymb, amsthm}

\newcommand{\ex}{\mathop{\mathbb{E}}\nolimits}

\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Xcal}{\mathcal{X}}
\newcommand{\Ycal}{\mathcal{Y}}
\newcommand{\Zcal}{\mathcal{Z}}

\newcommand{\Real}{\mathbb{R}}

\newcommand{\one}{\mathbf{1}}

\title{Research statement}
\author{Nazarov I.N.}

\begin{document}
\maketitle

\section{Relevance} % (fold)
\label{sec:relevance}
% задача детектирования аномалий важна. Однако, в настоящее время появилось много
% прикладных ситуаций, типов данных и т.п., для которых:
%     а) надо развивать новые методы;
%     б) изучать теор. свойства методов.
% Кроме того, надо законченной мат. модели/теории о том, что такое аномалия, как
% оценивать качество детектирования аномалий и прогнозирования поломок. 

Anomaly detection is concerned with identifying observations in new incoming test
data, which diverge in a some sense from the previously seen data. Problems of this
nature arise in many applied fields such as predictive maintenance of complex industrial
systems \cite{tarassenko2009}, on-site structural integrity monitoring \cite{surace2010},
cancer detection based on screening data in diagnostic medicine \cite{tarassenko1995,quinn2007,clifton2011},
intrusion detection in data and general security \cite{jyothsna2011}, anti-fraud
solutions in banking and monitoring of insider trading in market regulation \cite{patcha2007},
et c.

Each of these problems uses negative definition of abnormality: ``abrnormal'' is
something which is not ``normal'' in a particular domain. In security and finance
``normal'' is understood as strict compliance with some regulation or protocol, in
engineering and medicine ``normal'' is within the acceptable band of a nominal regime
of a machine or the usual phenomenology of a subject. In each of theses tasks it is
assumed that the majority of the observed data are ``normal'', and only a minute
fraction of it is ``anomalous'', which is why most methods of anomaly detection
define an anomaly as a substantial deviation form what the internal representation
of a ``normal'' pattern. Regression-based methods rely on the learnt feature-target
relationship, whereas density-based anomaly detectors use modes of the estimated
data generating distribution or the reconstructed manifold carrying the data.

Regression-based approach encompass such models as multilayer neural networks for
supervised (c.f. \cite{augusteijn2002}), and replicating neural networks, autoencoders
for unsupervised learning tasks (c.f. \cite{hawkins2002,williams2002}). Spectral
methods, \cite{chandola2009}, infer combinations of input features, that comprehensively
describe the variability of the data separate anomalous from normal. Manifold-based
methods include approximation with principal components, \cite{dutta2007,shyu2003},
and \cite{jolliffe2014}, or more general non-linear kernel based representations,
\cite{hoffmann2007,scholkopf1998}. These methods produce a compact low-dimensional
internal representation of the data and use its' predictive or reconstructive properties
to derive abnormality scores.

In \cite{breunig2000} a density-based anomaly detection method based on a Local Outlier
Factor (LOF) score was suggested, which is estimated with respect to local topology,
defined by a metric neighbourhood containing at least the required number of data
points. This method relates the tightness of a point's closest neighbourhood to the
average across its neighbours. Original LOF does not provide confidence measure of
abnormality, which is why \cite{kriegel2009} suggested the ``LoOP'' (local outlier
probability) method. LoOP is similar in spirit to LOF, but yields probabilistic
estimates of confidence based in the same idea of tightness of the observations's
immediate locality.

% section relevance (end)

\section{Regression-based anomaly detection} % (fold)
\label{sec:regression_based_anomaly_detection}

% 2. Далее, надо написать, что одним из важных подходов детектирования аномалий является
% подход на основе virtual sensor, то есть у нас есть некоторая характеристика (например,
% мощность, производимая элетростнацией). Измеряются характеристики, которые характеризуют
% работу отдельных частей станции. Мы могли бы построить регрессионную модель, которая
% прогнозирует мощность в зависимости от этих характеристик, и, если сначала ошибка
% прогноза была мала, а потом - велика, мы могли бы понять, что начали происходить
% потери мощности, и понять - из-за каких параметров, что позволило бы нам выяснить
% причины поломки. Однако, чтобы решать такую задачу, нужен не только регрессионный
% метод, но и метод, который позволяет непараметрическим образом эффективно строить
% доверительные интервалы. Цель решения данной задачи
%     а) непараметрический метод построения дов. интервалов нелинейной регрессии на
%     основе ядерных методов;
%     б) сравнение его со стандартными методами;
%     в) изучение теор. свойств, в частности, эффективности.
% Пишите, что уже есть задел, подана статья на конф.

Supervised regression-based methods allow modelling of complex interactions between
features of the data, yet do not readily yield any sort of prediction confidence
measure, unless distributional assumptions are introduced. One method to keep them
distribution-free is to employ ``conformal prediction'' approach developed in \cite{vovk2005}.
Under the standard independence assumption and for any ML algorithm it constructs
a set in the space of targets, that contains yet unobserved data with a pre-specified
confidence level. IOn essence conformal prediction amounts to the following: for
every possible value $z$ of an object $Z_{n+1}$ the procedure tests $H_0: Z_{n+1}=z$,
and then inverts the test to get a confidence region. The hypothesis tests are based
on the observed sample $(Z_i)_{i=1}^n$ and hypothesized $z$, and are designed to
have a pre-specified type-I error rate $\alpha$.

In my PHD thesis I would like to focus on the following: \begin{enumerate}
  \item to explore conformal prediction and other distribution-free methods for
  the task of endowing kernel-based regression models with prediction confidence
  intervals;
  \item compare the suggested enhancements to the state-of-the art methods;
  \item provide necessary theoretical foundations for correct coverage and
  efficiency.
\end{enumerate}
In this vein I co-authored and submitted a paper to the ICMLA 2017 conference which
outlines the results of an extensive numerical study concerning both coverage and
efficiency issues.

% section regression_based_anomaly_detection (end)

\section{Conformalized kernel embeddings} % (fold)
\label{sec:conformalized_kernel_embeddings}

% Следующий пункт - есть много методов детектирования аномалий, например, LoOF, LOP и
% т.п. Они так или иначе основаны на некотором "инженерном" способе определить, что
% новое наблюдение попало в регион, где мало наблюдений выборки.
% Однако, надо самом
% деле надо по сути определять, что наблюдение порождено распределнием, отличным от
% распределения, которое породило основную часть выборки. По этой причине имеет смысл
% применять kernel mean embedding и т.п. (ну в общем, то, что вы делали в дипломе).
% Цель решения данной задачи
%     а) разработать непараметрический метод обнаружения аномалий, который не полагается
%     на какие-либо определения того, что такое аномалия;
%     б) сравнить его со стандартными методами;
%     в) изучить его теор. свойства, в частности, эффективность.

Unsupervised anomaly detection in essence boils down to determining how likely it
is that an observation was generated from the ``normal regime'' distribution. For
instance, density-based methods define the normal regime distribution simply as
the modes of the data distribution inferred from the training data. Bayesian outlier
detection techniques models use prior distributions and data-generating model to
compute the posterior of a new observation given the already observed data.

One promising research direction is conformal procedures for kernel embedding of
probability distributions, introduced \cite{smola2007}. Basically, in a suitable
Reproducing Kernel Hilbert Space (RKHS) many non-pathological distributions on
metric spaces can be identified with a unique element of said RKHS. Specifically,
if $K$ is a kernel that induces a universal RKHS $\Hcal$ of functions $\Xcal\mapsto\Real$,
then for any probability distribution $P$ on $\Xcal$ with $\ex_{x\sim P} \sqrt{K(x,x)} < +\infty$
there is a unique representative $\mu_P\in \Hcal$ such that $\ex_P f = \langle \mu_P, f\rangle$
for all $f\in \Hcal$ and
\begin{equation*}
  \mu_P(x) = \langle \mu_P, K(x, \cdot) \rangle = \ex_{y\sim P} K(x, y) \,.
\end{equation*}

Now, for a compact metric space $\Xcal$ the distributions $P$ and $Q$ coincide if
and only if $\ex_P f = \ex_Q f$ for all continuous and bounded $f:\Xcal\mapsto \Real$.
Based on this \cite{gretton2012} propose the \textit{maximum mean discrepancy} (MDD)
-- an effective non-parametric criterion that compares the distributions, which is
the RKHS norm of the deviation of the kernel embeddings $\mu_Q$ and $\mu_P$. Therefore
in order to decide if a new example $z_n$ is anomalous or not with respect to a given
sample $Z_{:n-1} = (z_i)_{i=1}^{n-1}$ it is could be sufficient to compute
$\|\hat{\mu}_{:n} - \hat{\mu}_{:n-1}\|_\Hcal$, where
\begin{equation*}
  \hat{\mu}_{:n}(x) = \ex_{z\sim Z_{:n}} K(x, z) = n^{-1} \sum_{i=1}^n K(x, z_i) \,,
\end{equation*}
the kernel mean embedding of the empirical distribution of $Z_{:n}$.

Empirical estimate of Hellinger distance for measuring deviation of probability
distributions was used in \cite{Baktashmotlaghetal2016} together with MDD for
constructing domain-invariant representations to tackle the domain shift problem
(domain adaptation).

% section conformalized_kernel_embeddings (end)

\section{General anomaly detection} % (fold)
\label{sec:general_anomaly_detection}

% Разработать некоторый general framework, в рамках которого можно было бы формулировать,
% что такое аномальность, точность обнаружения аномалий, и оценивать, какой размер
% выборки нужен для получения заданной точности, сравнивать эффективности различных
% методов обнаружения аномалий.

% section general_anomaly_detection (end)

% \bibliographystyle{amsplain}
\clearpage
\bibliographystyle{ugost2008ls}
\bibliography{references}

\end{document}