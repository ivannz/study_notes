{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, gc\n",
    "os.chdir( '/Users/user/ownCloud/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings ; warnings.simplefilter( \"ignore\" )\n",
    "import numpy as np, pandas as pd, flex as fl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist_npz = '/Users/user/study_notes/year_14_15/spring_2015/machine_learning/data/mldata/mnist_scikit.npz'\n",
    "assert( os.path.exists( mnist_npz ) )\n",
    "with np.load( mnist_npz, 'r' ) as npz :\n",
    "    mnist_labels, mnist_data = np.asarray( npz[ 'labels' ], np.int ), npz[ 'data' ] / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_ = cross_validation.train_test_split( mnist_data, mnist_labels, test_size = 0.75 )\n",
    "X_train, X_test, y_train, y_test = split_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple average pattern classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate averaged images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_labels_ = np.unique( mnist_labels )\n",
    "\n",
    "train_digits_ = { label_ : X_train[ np.flatnonzero( y_train == label_ ) ]\n",
    "                           for label_ in mnist_labels_ }\n",
    "\n",
    "avg_patterns_ = { label_ : samples_.mean( axis = 0 )[ np.newaxis ]\n",
    "                  for label_, samples_ in train_digits_.iteritems() }\n",
    "\n",
    "## Construct an aligned pair of arrays\n",
    "average_digits = np.concatenate( [ array_ for array_ in avg_patterns_.itervalues() ], axis = 0 )\n",
    "average_labels = np.array( [ label_ for label_ in avg_patterns_.iterkeys() ], dtype = np.int )\n",
    "\n",
    "## Sort them\n",
    "order_ = np.argsort( average_labels )[::-1]\n",
    "average_labels = average_labels[ order_ ] ; average_digits = average_digits[ order_ ] ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plot the patterns\n",
    "axis = plt.figure( figsize = ( 16, 9 ) ).add_subplot( 111 )\n",
    "axis.set_title( u\"Averaged digits on train\" )\n",
    "fl.plot( axis, average_digits, shape = ( 28, -1 ), cmap = plt.cm.hot, interpolation = \"nearest\" )\n",
    "plt.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple MAP calssifier based on mean patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Compute the squared error ...\n",
    "yp_ = - 2 * np.tensordot( X_test, average_digits, axes = [ -1, -1 ] ) \\\n",
    "      + average_digits.dot( average_digits.T )[:1]\n",
    "## ... and based on it find the closest label.\n",
    "pred_labels_ = average_labels[ yp_.argmin(axis = 1) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "tbl_ = sp.coo_matrix( ( np.ones_like( pred_labels_ ), ( pred_labels_, y_test ) ) ).todense( )\n",
    "tbl = pd.DataFrame( tbl_, index = average_labels, columns = average_labels )\n",
    "tbl.index.name = \"Predicted\" ; tbl.columns.name = \"Actual\" ;\n",
    "\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Achieved accuracy is %.3f%%\" % ( np.mean( y_test == pred_labels_ ) * 100.0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest WTF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_ = ensemble.RandomForestClassifier( n_estimators = 50, n_jobs = -1, random_state = None ).fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_labels_ = rfc_.classes_[ rfc_.predict_proba( X_test ).argmax( axis = 1 ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Achieved accuracy is %.3f%%\" % ( np.mean( y_test == pred_labels_ ) * 100.0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "tbl_ = sp.coo_matrix( ( np.ones_like( pred_labels_ ), ( pred_labels_, y_test ) ) ).todense( )\n",
    "tbl = pd.DataFrame( tbl_, index = average_labels, columns = average_labels )\n",
    "tbl.index.name = \"Predicted\" ; tbl.columns.name = \"Actual\" ;\n",
    "\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plot the patterns\n",
    "axis = plt.figure( figsize = ( 16, 9 ) ).add_subplot( 111 )\n",
    "axis.set_title( u\"Random Forest feature importances\" )\n",
    "fl.plot( axis, rfc_.feature_importances_[ np.newaxis ], n_row = 1, n_col = 1,\n",
    "         shape = ( 28, -1 ), cmap = plt.cm.hot, interpolation = \"nearest\" )\n",
    "plt.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw and plot some random subset of train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_perm_ = np.random.permutation( X_train.shape[ 0 ] )\n",
    "X = mnist_data[ index_perm_[ : 400 ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axis = plt.figure( figsize = ( 16, 9 ) ).add_subplot( 111 )\n",
    "axis.set_title( u\"200 random MNIST digits.\" )\n",
    "fl.plot( axis, X, n = 400, shape = ( 28, -1 ), cmap = plt.cm.hot, interpolation = \"nearest\" )\n",
    "plt.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne, theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement as simple neural network with lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.tensor4( 'inputs' )\n",
    "target_var = T.ivector( 'targets' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## The input layer\n",
    "network = lasagne.layers.InputLayer( shape = ( None, 1, 28, 28 ),\n",
    "                                     input_var = input_var )\n",
    "\n",
    "## The 2D 5x5 conv layer with ReLU and 2x2 max-pooling\n",
    "## (28-7+1) // 1\n",
    "network = lasagne.layers.Conv2DLayer( network, num_filters = 32, filter_size = ( 5, 5 ),\n",
    "                                      nonlinearity = lasagne.nonlinearities.rectify,\n",
    "                                      border_mode = \"valid\", W = lasagne.init.GlorotUniform( ) )\n",
    "network = lasagne.layers.MaxPool2DLayer( network, pool_size = ( 2, 2 ) )\n",
    "\n",
    "## The 2D 3x3 conv layer with ReLU and 2x2 max-pooling\n",
    "network = lasagne.layers.Conv2DLayer( lasagne.layers.dropout( network, p = .2 ),\n",
    "                                      num_filters = 64, filter_size = ( 3, 3 ),\n",
    "                                      nonlinearity = lasagne.nonlinearities.rectify,\n",
    "                                      border_mode = \"valid\", W = lasagne.init.GlorotUniform( ) )\n",
    "network = lasagne.layers.MaxPool2DLayer( network, pool_size = ( 2, 2 ) )\n",
    "\n",
    "## FC layer with dropout\n",
    "network = lasagne.layers.DenseLayer( lasagne.layers.dropout( network, p = .5 ),\n",
    "                                     num_units = 256, nonlinearity = lasagne.nonlinearities.rectify )\n",
    "\n",
    "network = lasagne.layers.DenseLayer( lasagne.layers.dropout( network, p = .5 ),\n",
    "                                     num_units = 10, nonlinearity = lasagne.nonlinearities.softmax )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = lasagne.layers.get_output( network )\n",
    "loss = lasagne.objectives.categorical_crossentropy( prediction, target_var ).mean( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = lasagne.layers.get_all_params( network, trainable = True )\n",
    "updates = lasagne.updates.nesterov_momentum( loss, params, learning_rate = 0.01, momentum = 0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = lasagne.layers.get_output( network, deterministic = True )\n",
    "test_loss = lasagne.objectives.categorical_crossentropy( test_prediction, target_var ).mean( )\n",
    "\n",
    "test_acc = T.mean( T.eq( T.argmax( test_prediction, axis = 1 ), target_var ), dtype = theano.config.floatX )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
