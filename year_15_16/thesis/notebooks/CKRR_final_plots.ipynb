{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKRR -- plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from utils.mpl_mid_point_norm import MidPointNorm\n",
    "\n",
    "from utils.state import _load\n",
    "from scipy.stats import binom_test\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdirifnot(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \".\"\n",
    "DATA_PATH = os.path.join(BASE_PATH, \"..\", \"thesis_exp\")\n",
    "OUTPUT_PATH = mkdirifnot(os.path.join(BASE_PATH, \"output_pdf-2\"))\n",
    "\n",
    "PROFILE_PATH = mkdirifnot(os.path.join(OUTPUT_PATH, \"profile\"))\n",
    "EXP1D_PATH = mkdirifnot(os.path.join(OUTPUT_PATH, \"exp_1d\"))\n",
    "EXP2D_PATH = mkdirifnot(os.path.join(OUTPUT_PATH, \"exp_2d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dumps(path, n_jobs=-1, verbose=1, include_target=False):\n",
    "    parallel_ = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "    jobs_ = (delayed(_load)(os.path.join(path, fname_))\n",
    "             for fname_ in os.listdir(path)\n",
    "             if fname_.endswith(\".gz\"))\n",
    "    dumps_ = parallel_(jobs_)\n",
    "    experiment = [exp_ for dump_ in dumps_ for exp_ in dump_]\n",
    "    \n",
    "    temp_ = dict()\n",
    "    for exp_ in experiment:\n",
    "        key_ = exp_[0][:-1]\n",
    "        if key_ not in temp_:\n",
    "            temp_[key_] = list()\n",
    "        temp_[key_].append((exp_[0][-1], exp_[1:]))\n",
    "\n",
    "    temp_ = {key_ : sorted(res_, key=lambda x: x[0])\n",
    "             for key_, res_ in temp_.iteritems()}\n",
    "\n",
    "    results_ = dict()\n",
    "    for key_, result_ in temp_.iteritems():\n",
    "        ratio_ = np.stack([np.mean((res_[1][0]-res_[1][1])**2, axis=0, keepdims=True) /\n",
    "                           np.std(res_[1][0], axis=0, keepdims=True)**2 for res_ in result_], axis=0)\n",
    "        sizes_ = np.array([res_[0] for res_ in result_])\n",
    "        coverage_ = np.stack([np.stack([res_[1][3+2*j] for res_ in result_], axis=0)\n",
    "                              for j in xrange(6)], axis=0)\n",
    "        width_ = np.stack([np.stack([res_[1][2+2*j] for res_ in result_], axis=0)\n",
    "                           for j in xrange(6)], axis=0)\n",
    "\n",
    "        if include_target:\n",
    "            target_ = np.stack([res_[1][0] for res_ in result_], axis=0)\n",
    "            target_hat_ = np.stack([res_[1][1] for res_ in result_], axis=0)\n",
    "            results_[key_] = ratio_, sizes_, coverage_, width_, target_, target_hat_\n",
    "        else:\n",
    "            results_[key_] = ratio_, sizes_, coverage_, width_\n",
    "\n",
    "    return results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_profiles(path, n_jobs=-1, verbose=1):\n",
    "    parallel_ = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "    jobs_ = (delayed(_load)(os.path.join(path, fname_))\n",
    "             for fname_ in os.listdir(path)\n",
    "             if fname_.endswith(\".gz\"))\n",
    "    dumps_ = parallel_(jobs_)\n",
    "    experiment = [exp_ for dump_ in dumps_ for exp_ in dump_]\n",
    "    \n",
    "    temp_ = dict()\n",
    "    for exp_ in experiment:\n",
    "        key_ = exp_[0][:-1]\n",
    "        if key_ not in temp_:\n",
    "            temp_[key_] = list()\n",
    "        temp_[key_].append((exp_[0][-1], exp_[1:]))\n",
    "\n",
    "    temp_ = {key_ : sorted(res_, key=lambda x: x[0])\n",
    "             for key_, res_ in temp_.iteritems()}\n",
    "\n",
    "    results_ = dict()\n",
    "    for key_, result_ in temp_.iteritems():\n",
    "        ratio_ = np.stack([np.mean((res_[1][0]-res_[1][1])**2, axis=0, keepdims=True) /\n",
    "                           np.std(res_[1][0], axis=0, keepdims=True)**2 for res_ in result_], axis=0)\n",
    "        sizes_ = np.array([res_[0] for res_ in result_])\n",
    "        bounds_ = np.stack([np.stack([res_[1][2+j] for res_ in result_], axis=0)\n",
    "                            for j in xrange(6)], axis=0)\n",
    "        target_ = np.stack([res_[1][0] for res_ in result_], axis=0)\n",
    "        target_hat_ = np.stack([res_[1][1] for res_ in result_], axis=0)\n",
    "        results_[key_] = ratio_, sizes_, bounds_, target_, target_hat_\n",
    "\n",
    "    return results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coverage_plot(ax, sizes, cov, levels):\n",
    "    cov_med_ = np.median(cov, axis=-1)\n",
    "    cov_lo_, cov_hi_ = np.percentile(cov, [25, 75], axis=-1)\n",
    "\n",
    "    ax.set_ylim(0.65, 1.025)\n",
    "    ax.set_xlim(25, 1600)\n",
    "    ax.locator_params(axis=\"x\", nbins=5)\n",
    "    ax.set_yticks(1-levels)\n",
    "    for i in xrange(cov_med_.shape[1]):\n",
    "        ax.plot(sizes, cov_med_[:, i], color=\"bgrm\"[i%4])\n",
    "        ax.plot(sizes, cov_hi_[:, i], color=\"bgrm\"[i%4], alpha=0.5)\n",
    "        ax.plot(sizes, cov_lo_[:, i], color=\"bgrm\"[i%4], alpha=0.5)\n",
    "        ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "    return ax\n",
    "\n",
    "def nomorethan(x, bound=0):\n",
    "    x_ = np.array(x, dtype=float)\n",
    "    x_[x_>bound] = np.nan\n",
    "    return x_\n",
    "\n",
    "def width_plot(ax, sizes, width):\n",
    "    avg_width_ = width.mean(axis=-1)\n",
    "    aw_med_ = np.median(avg_width_, axis=-2)\n",
    "    aw_q95_ = np.percentile(avg_width_, [95,], axis=-2)[0]\n",
    "    aw_min_ = np.percentile(avg_width_, [ 5,], axis=-2)[0]\n",
    "    aw_max_ = np.max(avg_width_, axis=-2)\n",
    "\n",
    "    ax.set_xlim(25, 1600)\n",
    "    ax.locator_params(axis=\"x\", nbins=5)\n",
    "    for i in xrange(aw_med_.shape[1]):\n",
    "        ax.plot(sizes, nomorethan(aw_med_[:, i], 2), color=\"bgrm\"[i%4])\n",
    "#         ax.plot(sizes, nomorethan(aw_q95_[:, i], 2), color=\"bgrm\"[i%4], alpha=0.5, marker='x')\n",
    "        ax.plot(sizes, nomorethan(aw_max_[:, i], 2), color=\"bgrm\"[i%4], alpha=0.5, marker='v')\n",
    "        ax.plot(sizes, nomorethan(aw_min_[:, i], 2), color=\"bgrm\"[i%4], alpha=0.5, marker='^')\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "\n",
    "titles_ = pd.Index([\"GPR-p\", \"GPR-f\", \"RRCM\", \"CRR\", \"RRCM-loo\", \"CRR-loo\"], name=\"type\")\n",
    "ncms_ = pd.Index([\"GPR\", \"GPR\", \"RRCM\", \"CRR\", \"RRCM\", \"CRR\"], name=\"type\")\n",
    "levels_ = pd.Index([\"%0.2f\"%(lvl,) for lvl in levels], name=\"alpha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "\n",
    "exp_gauss_1d = load_dumps(os.path.join(DATA_PATH, 'exp_gauss_1d_25'), verbose=1, n_jobs=-1)\n",
    "exp_nongauss_1d = load_dumps(os.path.join(DATA_PATH, 'exp_nongauss_1d_25'), verbose=1, n_jobs=-1)\n",
    "\n",
    "exp_gauss_1d.update(exp_nongauss_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make coverage tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "for key_ in sorted(exp_gauss_1d.keys(), key=lambda x: (x[0], x[1], x[3], x[2])):\n",
    "    name_, noise_, theta0_, nugget_ = key_\n",
    "    ratio_, sizes_, coverage_, width_ = exp_gauss_1d[key_]\n",
    "\n",
    "    output_path_ = mkdirifnot(os.path.join(EXP1D_PATH, name_))\n",
    "    output_path_ = mkdirifnot(os.path.join(output_path_, \"%g_%g\"%(noise_, nugget_,)))\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"$'%s'$\")%(theta0_,)\n",
    "    title_template_ = \"%%s ($\\\\theta=%s, \\\\lambda=%g, \\\\gamma=%g$)\"%(theta_, nugget_, noise_)\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"%s\")%(theta0_,)\n",
    "    filename_template_ = \"%%s%s %g %g %s %%s\"%(name_, noise_, nugget_, theta_)\n",
    "\n",
    "    ## width dynamics\n",
    "    output_path_current_ = mkdirifnot(os.path.join(output_path_, \"width\"))\n",
    "    for j in xrange(6):\n",
    "        output_path_local_ = mkdirifnot(os.path.join(output_path_current_, titles_[j]))\n",
    "        fig = plt.figure(figsize=(4, 3))\n",
    "        ax = fig.add_subplot(111)\n",
    "#         ax.set_yscale(\"log\")\n",
    "        width_plot(ax, sizes_, width_[j])\n",
    "        ax.set_title(title_template_%(titles_[j],))\n",
    "\n",
    "        filename_ = (filename_template_%(\"width \", titles_[j],)).replace(\" \", \"_\").replace(\".\", \",\")\n",
    "        fig_file_name_ = os.path.join(output_path_local_, filename_ + \".pdf\")\n",
    "        fig.savefig(fig_file_name_, dpi=120)\n",
    "        plt.close()\n",
    "#         print fig_file_name_\n",
    "\n",
    "    ## Coverage asymptotics\n",
    "    output_path_current_ = mkdirifnot(os.path.join(output_path_, \"coverage\"))\n",
    "    for j in xrange(6):\n",
    "        output_path_local_ = mkdirifnot(os.path.join(output_path_current_, titles_[j]))\n",
    "        fig = plt.figure(figsize=(4, 3))\n",
    "        ax = fig.add_subplot(111)\n",
    "        coverage_plot(ax, sizes_, coverage_[j], levels)\n",
    "        ax.set_title(title_template_%(titles_[j],))\n",
    "\n",
    "        filename_ = (filename_template_%(\"coverage \", titles_[j],)).replace(\" \", \"_\").replace(\".\", \",\")\n",
    "        fig_file_name_ = os.path.join(output_path_local_, filename_ + \".pdf\")\n",
    "        fig.savefig(fig_file_name_, dpi=120)\n",
    "        plt.close()\n",
    "#         print fig_file_name_\n",
    "\n",
    "    ## rmse/var dynamics\n",
    "    output_path_current_ = output_path_\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ratio_ = nomorethan(ratio_.mean(axis=-1), 1)\n",
    "#     ax.set_ylim(bottom = -0.001)\n",
    "    ax.plot(sizes_, ratio_)\n",
    "    ax.set_title(title_template_%('MSE - var',))\n",
    "\n",
    "    filename_ = (filename_template_%(\"\", \"ratio\",)).replace(\" \", \"_\").replace(\".\", \",\")\n",
    "    fig_file_name_ = os.path.join(output_path_, filename_ + \".pdf\")\n",
    "    fig.savefig(fig_file_name_, dpi=120)\n",
    "    plt.close()\n",
    "#     print fig_file_name_\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX_test = np.linspace(0, 1, num=501).reshape((-1, 1))\n",
    "\n",
    "prof_gauss = load_profiles(os.path.join(DATA_PATH, 'prof_gauss'), verbose=1, n_jobs=1)\n",
    "prof_nongauss = load_profiles(os.path.join(DATA_PATH, 'prof_nongauss'), verbose=1, n_jobs=1)\n",
    "\n",
    "prof_gauss.update(prof_nongauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key_ in sorted(prof_gauss.keys(), key=lambda x: (x[0], x[1], x[3], x[2])):\n",
    "    name_, noise_, theta0_, nugget_ = key_\n",
    "    ratio_, sizes_, bounds_, y_test_, y_hat_ = prof_gauss[key_]\n",
    "    ## Skip\n",
    "#     if name_ != \"heaviside\": continue\n",
    "#     if theta0_ == \"auto\": continue\n",
    "\n",
    "    output_path_ = mkdirifnot(os.path.join(PROFILE_PATH, name_))\n",
    "    output_path_ = mkdirifnot(os.path.join(output_path_, \"%g_%g\"%(noise_, nugget_,)))\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"$'%s'$\")%(theta0_,)\n",
    "    title_template_ = \"%%s: %%s ($\\\\theta=%s, \\\\lambda=%g, \\\\gamma=%g$)\"%(theta_, nugget_, noise_)\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"%s\")%(theta0_,)\n",
    "    filename_template_ = \"%%s%s %g %g %s %%s\"%(name_, noise_, nugget_, theta_)\n",
    "\n",
    "    ## Profile\n",
    "    for s_ in xrange(len(sizes_)):\n",
    "#         if s_ > 1: continue\n",
    "        output_path_current_ = mkdirifnot(os.path.join(output_path_, \"%d\"%(sizes_[s_],)))\n",
    "        for i_ in xrange(4):\n",
    "            # max_, min_ = np.percentile(bounds_[:, s_, :, i_], [92.5, 7.5])*2\n",
    "            max_, min_ = y_test_[s_].max()*1.5, y_test_[s_].min()*1.5\n",
    "            if name_==\"heaviside\": min_, max_ = -0.95, 1.95\n",
    "            for ncm_ in pd.unique(ncms_):\n",
    "                fig = plt.figure(figsize=(5, 4))\n",
    "                ax = fig.add_subplot(111)\n",
    "                if np.isfinite(min_) and np.isfinite(max_):\n",
    "                    ax.set_ylim(min_, max_)\n",
    "                ax.plot(XX_test, y_test_[s_], c=\"#c0c0c0\", lw=2, alpha=.5, label=\"$y_x$\")\n",
    "                ax.plot(XX_test, y_hat_[s_], c='k', label=\"$\\\\hat{y}_x$\")\n",
    "                for j, b in enumerate(np.flatnonzero(ncms_==ncm_)):\n",
    "                    ax.plot(XX_test, bounds_[b, s_, :, i_, 0], color=\"rb\"[j], label=titles_[b])\n",
    "                    ax.plot(XX_test, bounds_[b, s_, :, i_, 1], color=\"rb\"[j])\n",
    "                ax.set_title(title_template_%(\"%.1f%%-%s\"%(levels[i_]*100, ncm_,), name_,))\n",
    "                ax.legend(loc=\"best\", ncol=2)\n",
    "\n",
    "                filename_ = (filename_template_%(\"profile \", \"%dp-%s %d\"%(levels[i_]*100, ncm_, sizes_[s_],),))\n",
    "                fig_file_name_ = os.path.join(output_path_current_,\n",
    "                                              filename_.replace(\" \", \"_\").replace(\".\", \",\") + \".pdf\")\n",
    "                fig.savefig(fig_file_name_, dpi=120)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nd = 2\n",
    "mesh_ = np.meshgrid(*nd*[np.linspace(0, 1, num=51)])\n",
    "XX_test = np.concatenate([ax_.reshape((-1, 1)) for ax_ in mesh_], axis=1)\n",
    "\n",
    "exp_gauss_2d = load_dumps(os.path.join(DATA_PATH, 'exp_gauss_2d_25'),\n",
    "                          verbose=1, n_jobs=1, include_target=True)\n",
    "exp_nongauss_2d = load_dumps(os.path.join(DATA_PATH, 'exp_nongauss_2d_25'),\n",
    "                             verbose=1, n_jobs=1, include_target=True)\n",
    "\n",
    "exp_gauss_2d.update(exp_nongauss_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# EXP2D_PATH\n",
    "for key_ in sorted(exp_gauss_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]:\n",
    "    name_, noise_, theta0_, nugget_ = key_\n",
    "    ratio_, sizes_, coverage_, width_, y_test, y_hat = exp_gauss_2d[key_]\n",
    "\n",
    "    df_coverage_ = pd.Panel(np.mean(coverage_[:, 1:], axis=-1), items=titles_, minor_axis=levels_,\n",
    "                            major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "\n",
    "    avg_width_ = np.mean(width_, axis=-1)[:, 1:]\n",
    "    aw_med_ = np.median(avg_width_, axis=-2)\n",
    "    aw_q95_ = np.percentile(avg_width_, [95,], axis=-2)[0]\n",
    "    aw_min_ = np.percentile(avg_width_, [ 5,], axis=-2)[0]\n",
    "    aw_max_ = np.max(avg_width_, axis=-2)\n",
    "    pn_med_ = pd.Panel(aw_med_, items=titles_, minor_axis=levels_, major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "    pn_q95_ = pd.Panel(aw_q95_, items=titles_, minor_axis=levels_, major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "\n",
    "    pv_ = np.stack([ttest_1samp(coverage_[:, 1:, j], (1 - levels[j]), axis=-1)[1] for j in xrange(4)], axis=-1)\n",
    "    pn_pv_ = pd.Panel(pv_, items=titles_, minor_axis=levels_, major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "\n",
    "    df_output_ = pd.concat({\"width. med\": pn_med_.to_frame(),\n",
    "                            \"width 95%\": pn_q95_.to_frame(),\n",
    "                            \"coverage\": df_coverage_.to_frame(),\n",
    "                            \"t-test\": pn_pv_.to_frame()},\n",
    "                           axis=0, names=[\"statistic\"])\\\n",
    "                   .swaplevel(0, 1, axis=0).sort_index(axis=0)\n",
    "    print key_\n",
    "#     display(HTML(df_output_.to_html(float_format=lambda f: \"%0.3f\"%(f,))))\n",
    "#     print df_output_.to_latex(float_format=lambda f: \"%0.3f\"%(f,))\n",
    "    \n",
    "    ## Show the true surface\n",
    "    y_test_ = y_test[1].mean(axis=-1)\n",
    "    y_hat_ = y_hat[1].mean(axis=-1)\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(mesh_[0], mesh_[1], y_test_.reshape(mesh_[0].shape),\n",
    "                    cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                    antialiased=False, alpha=0.9)\n",
    "    ax.view_init(60, -60)\n",
    "    plt.show()\n",
    "\n",
    "    ## The approximated surface\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(mesh_[0], mesh_[1], y_hat_.reshape(mesh_[0].shape),\n",
    "                    cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                    antialiased=False, alpha=0.9)\n",
    "    ax.view_init(60, -60)\n",
    "    plt.show()\n",
    "    \n",
    "#     ## The GPR-p\n",
    "#     fig = plt.figure(figsize=(6, 3))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     ax.plot_surface(mesh_[0], mesh_[1], avg_width_[0, 0, :, 2].reshape(mesh_[0].shape),\n",
    "#                     cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "#                     antialiased=False, alpha=0.9)\n",
    "#     ax.view_init(60, -60)\n",
    "#     ax.set_title(titles_[0])\n",
    "#     plt.show()\n",
    "    \n",
    "#     ## The RRCM / GPR-p : j=0..3, i=2..5\n",
    "#     i, j = 3, 2\n",
    "#     awr_ = avg_width_[i, 0, :, j] / avg_width_[0, 0, :, j] - 1\n",
    "#     fig = plt.figure(figsize=(6, 3))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     ax.plot_surface(mesh_[0], mesh_[1], awr_.reshape(mesh_[0].shape),\n",
    "#                     cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "#                     antialiased=False, alpha=0.9)\n",
    "#     ax.view_init(60, -60)\n",
    "#     ax.set_title(titles_[2])\n",
    "#     plt.show()\n",
    "    \n",
    "    print ratio_.mean(axis=-1)[1, 0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.log(awr_), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pn_pv_.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coverage_ = dict()\n",
    "for key_, item_ in exp_gauss_1d.iteritems():\n",
    "    sizes_ = pd.Index(item_[1], name=\"size\")\n",
    "    noise_, theta0_, nugget_ = key_[1:]\n",
    "    df_cov_ = pd.Panel(item_[2].mean(axis=-1), items=titles_, major_axis=sizes_, minor_axis=levels_).to_frame()\n",
    "    pv_ = np.stack([ttest_1samp(item_[2][:,:,j], (1-levels[j]), axis=-1)[1] for j in xrange(4)], axis=-1)\n",
    "    df_cov_pv_ = pd.Panel(pv_, items=titles_, major_axis=sizes_, minor_axis=levels_).to_frame()\n",
    "    coverage_[key_] = df_cov_, df_cov_pv_, item_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.stack([ttest_1samp(item_[2][:,:,j], (1-levels[j]), axis=-1)[1] for j in xrange(4)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.abs(item_[2].mean(axis=-1)-(1-levels)[np.newaxis, np.newaxis]) / item_[2].std(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hits_ = np.round(item_[2].mean(axis=-1)*2601)\n",
    "pv_ = np.stack([np.vectorize(lambda x: binom_test(x, n=2601, p=1 - levels[j]))(hits_[..., j]) for j in range(4)], axis=-1)\n",
    "pv_[pv_ < 0.001] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_[2][..., j, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_.T.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], m_w_[1, 1, :, 0].reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX_test = np.linspace(-1, 1, num=501).reshape((-1, 1))\n",
    "prof_nongauss = load_profiles(os.path.join(\".\", 'prof_nongauss_lap'), verbose=1, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key_ in sorted(prof_nongauss.keys(), key=lambda x: (x[0], x[1], x[3], x[2])):\n",
    "    name_, noise_, theta0_, nugget_ = key_\n",
    "    ratio_, sizes_, bounds_, y_test_, y_hat_ = prof_nongauss[key_]\n",
    "    ## Skip\n",
    "#     if name_ != \"heaviside\": continue\n",
    "#     if theta0_ == \"auto\": continue\n",
    "\n",
    "    output_path_ = mkdirifnot(os.path.join(PROFILE_PATH, name_ + \"lap\"))\n",
    "    output_path_ = mkdirifnot(os.path.join(output_path_, \"%g %g\"%(noise_, nugget_,)))\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"$'%s'$\")%(theta0_,)\n",
    "    title_template_ = \"%%s: %%s ($\\\\theta=%s, \\\\lambda=%g, \\\\gamma=%g$)\"%(theta_, nugget_, noise_)\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"%s\")%(theta0_,)\n",
    "    filename_template_ = \"%%s%s %g %g %s %%s\"%(name_, noise_, nugget_, theta_)\n",
    "\n",
    "    ## Profile\n",
    "    for s_ in xrange(len(sizes_)):\n",
    "#         if s_ > 1: continue\n",
    "        output_path_current_ = mkdirifnot(os.path.join(output_path_, \"%d\"%(sizes_[s_],)))\n",
    "        for i_ in xrange(4):\n",
    "            # max_, min_ = np.percentile(bounds_[:, s_, :, i_], [92.5, 7.5])*2\n",
    "#             max_, min_ = y_test_[s_].max()*1.5, y_test_[s_].min()*1.5\n",
    "            if name_==\"heaviside\": min_, max_ = -0.95, 1.95\n",
    "            for ncm_ in pd.unique(ncms_):\n",
    "                fig = plt.figure(figsize=(5, 4))\n",
    "                ax = fig.add_subplot(111)\n",
    "#                 if np.isfinite(min_) and np.isfinite(max_):\n",
    "#                     ax.set_ylim(min_, max_)\n",
    "                ax.plot(XX_test, y_test_[s_], c=\"#c0c0c0\", lw=2, alpha=.5, label=\"$y_x$\")\n",
    "                ax.plot(XX_test, y_hat_[s_], c='k', label=\"$\\\\hat{y}_x$\")\n",
    "                for j, b in enumerate(np.flatnonzero(ncms_==ncm_)):\n",
    "                    ax.plot(XX_test, bounds_[b, s_, :, i_, 0], color=\"rb\"[j], label=titles_[b])\n",
    "                    ax.plot(XX_test, bounds_[b, s_, :, i_, 1], color=\"rb\"[j])\n",
    "                ax.set_title(title_template_%(\"%.1f%%-%s\"%(levels[i_]*100, ncm_,), name_,))\n",
    "                ax.legend(loc=\"best\", ncol=2)\n",
    "\n",
    "                filename_ = (filename_template_%(\"profile \", \"%dp-%s %d\"%(levels[i_]*100, ncm_, sizes_[s_],),))\n",
    "                fig_file_name_ = os.path.join(output_path_current_,\n",
    "                                              filename_.replace(\" \", \"_\").replace(\".\", \",\") + \".pdf\")\n",
    "                fig.savefig(fig_file_name_, dpi=120)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "titles_ = [\"GPR\", \"RRCM\" ,\"CRR\", \"RRCM-loo\", \"CRR-loo\"]\n",
    "colors_ = \"bgrm\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "from sklearn.base import clone\n",
    "\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from utils.functions_1d import f6, pressure2, heaviside\n",
    "\n",
    "from utils.conformal import RRCM, CRR\n",
    "from utils.KRR import KRR_AB\n",
    "\n",
    "def _helper(y, A, B, proc=RRCM, levels=levels, parallel=None, n_jobs=1, verbose=0):\n",
    "    if not isinstance(parallel, Parallel):\n",
    "        parallel = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "## Construct the CKRR confidence interval: RRCM\n",
    "    regions = parallel(delayed(proc)(A[k], B[k], levels=levels)\n",
    "                       for k in xrange(y.shape[0]))\n",
    "\n",
    "## See if the transformed test target valeus are with the conformal region\n",
    "    hits_ = np.asarray(\n",
    "        [[np.any(((int_[:, 0] <= target) & (target <= int_[:, 1]))).astype(float)\n",
    "          for int_ in region]\n",
    "         for target, region in zip(y, regions)])\n",
    "\n",
    "    width_ = np.asarray(\n",
    "        [[np.sum(int_[:, 1] - int_[:, 0]) for int_ in region] for region in regions])\n",
    "    \n",
    "    bounds_ = np.asarray(\n",
    "        [[[int_[:, 0].min(), int_[:, 1].max()] for int_ in region] for region in regions])\n",
    "    return hits_, width_, bounds_\n",
    "\n",
    "n_jobs, verbose = -1, 0\n",
    "parallel_ = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "random_state = np.random.RandomState(0x6AE89C43)\n",
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "\n",
    "## Initialize\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "kernel = 'rbf' # 'laplacian'\n",
    "gp = GaussianProcess(beta0=0, normalize=False, corr='squared_exponential')\n",
    "\n",
    "funcs_ = [f6, pressure2, heaviside]\n",
    "\n",
    "grid_ = ParameterGrid(dict(size=[150, 500,],\n",
    "                           nugget=[1e-6, 1e-2],\n",
    "                           theta0=[1e-1, 1.0, 1e+1,]))\n",
    "\n",
    "## Get a sample realisation\n",
    "XX_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "XX_train = random_state.uniform(size=(10000, 1))\n",
    "\n",
    "XX = np.concatenate([XX_test, XX_train], axis=0)\n",
    "test_ = np.s_[:XX_test.shape[0]]\n",
    "\n",
    "output_path_ = mkdirifnot(os.path.join(PLOT_PATH, \"profiles\"))\n",
    "for dgp_ in funcs_:\n",
    "    for noise_ in [1e-6, 1e-1,]:\n",
    "        yy = dgp_(XX)\n",
    "        if yy.ndim == 1:\n",
    "            yy = yy.reshape((-1, 1))\n",
    "        if noise_ > 0:\n",
    "            yy += random_state.normal(size=yy.shape) * noise_\n",
    "        yy_train, yy_test = np.delete(yy, test_, axis=0), yy[test_].copy()\n",
    "        del yy\n",
    "\n",
    "        for i_, par_ in enumerate(grid_):\n",
    "            size_, nugget_, theta0_ = par_['size'], par_['nugget'], par_['theta0']\n",
    "\n",
    "            \n",
    "            theta_= (\"%g\" if isinstance(theta0_, float) else \"$'%s'$\")%(theta0_,)\n",
    "            title_template_ = \"%%s %%g ($n=%d, \\\\theta=%s, \\\\lambda=%g$)\"%(size_, theta_, nugget_)\n",
    "\n",
    "            # Draw random train sample\n",
    "            train_ = random_state.choice(range(XX_train.shape[0]),\n",
    "                                         size=size_, replace=False)\n",
    "            X, y = XX_train[train_], yy_train[train_]\n",
    "\n",
    "            Xscl_, yscl_ = clone(scaler).fit(X), clone(scaler).fit(y)\n",
    "            X_, XX_test_ = Xscl_.transform(X), Xscl_.transform(XX_test)\n",
    "            y_, yy_test_ = yscl_.transform(y), yscl_.transform(yy_test)\n",
    "        \n",
    "            # Fir a gpr\n",
    "            gp_ = clone(gp)\n",
    "            gp_.nugget = nugget_\n",
    "            if isinstance(theta0_, float):\n",
    "                gp_.theta0 = theta0_\n",
    "            elif theta0_ == \"auto\":\n",
    "                gp_.thetaL, gp_.thetaU, gp_.theta0 = 1e-4, 1e4, float(size_)\n",
    "            gp_.fit(X_, y_)\n",
    "\n",
    "            # Compute the A, B matrices\n",
    "            A, B, y_hat_, MM, loo_, A_loo, B_loo = KRR_AB(\n",
    "                X_, y_, XX_test_, forecast=True, nugget=gp_.nugget,\n",
    "                metric=kernel, gamma=gp_.theta_[0])\n",
    "            del loo_\n",
    "\n",
    "            # Inflate by the estimated magnitude\n",
    "            MM *= gp_.sigma2\n",
    "\n",
    "\n",
    "        ## Construct the Bayesian interval\n",
    "            z_a = norm.ppf(1 - .5 * levels)\n",
    "            half_width_ = np.sqrt(MM) * z_a[np.newaxis]\n",
    "            b_bounds_ = yscl_.inverse_transform(\n",
    "                np.stack([y_hat_ - half_width_, y_hat_ + half_width_], axis=-1))\n",
    "            b_width_ = b_bounds_[..., 1] - b_bounds_[..., 0]\n",
    "            b_hits_ = ((b_bounds_[..., 0] <= yy_test) & (yy_test <= b_bounds_[..., 1])).astype(float)\n",
    "\n",
    "        ## Construct the CKRR confidence interval: RRCM\n",
    "            rrcm_hits_, rrcm_width_, rrcm_bounds_ = _helper(yy_test_, A[0], B, proc=RRCM,\n",
    "                                              levels=levels, parallel=parallel_)\n",
    "            if yscl_.scale_ is not None:\n",
    "                rrcm_width_ *= yscl_.scale_\n",
    "\n",
    "        ## Construct the CKRR confidence interval: CCR-sided\n",
    "            crr_hits_, crr_width_, crr_bounds_ = _helper(yy_test_, A[0], B, proc=CRR,\n",
    "                                            levels=levels, parallel=parallel_)\n",
    "            if yscl_.scale_ is not None:\n",
    "                crr_width_ *= yscl_.scale_\n",
    "\n",
    "        ## Construct the CKRR confidence interval: RRCM\n",
    "            loo_rrcm_hits_, loo_rrcm_width_, loo_rrcm_bounds_ = _helper(yy_test_, A_loo[0], B_loo, proc=RRCM,\n",
    "                                                      levels=levels, parallel=parallel_)\n",
    "            if yscl_.scale_ is not None:\n",
    "                loo_rrcm_width_ *= yscl_.scale_\n",
    "\n",
    "        ## Construct the CKRR confidence interval: CCR-sided\n",
    "            loo_crr_hits_, loo_crr_width_, loo_crr_bounds_ = _helper(yy_test_, A_loo[0], B_loo, proc=CRR,\n",
    "                                                    levels=levels, parallel=parallel_)\n",
    "            if yscl_.scale_ is not None:\n",
    "                loo_crr_width_ *= yscl_.scale_\n",
    "\n",
    "            rrcm_bounds = yscl_.inverse_transform(rrcm_bounds_)\n",
    "            crr_bounds = yscl_.inverse_transform(crr_bounds_)\n",
    "            loo_rrcm_bounds = yscl_.inverse_transform(loo_rrcm_bounds_)\n",
    "            loo_crr_bounds = yscl_.inverse_transform(loo_crr_bounds_)\n",
    "            y_hat = yscl_.inverse_transform(y_hat_)\n",
    "\n",
    "            bounds = np.stack([rrcm_bounds, crr_bounds,\n",
    "                               loo_rrcm_bounds, loo_crr_bounds],\n",
    "                              axis=-1)\n",
    "\n",
    "            ## Profile\n",
    "            col_ = list(\"rbgk\")\n",
    "            fig = plt.figure(figsize=(5, 3))\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.plot(XX_test, yy_test, c=\"k\", alpha=0.5)\n",
    "            ax.plot(XX_test, y_hat, c='y')\n",
    "            for j in range(4):\n",
    "                ax.plot(XX_test, bounds[:, -2, 0, j], color=col_[j], alpha=.5)\n",
    "                ax.plot(XX_test, bounds[:, -2, 1, j], color=col_[j], alpha=.5)\n",
    "            ax.plot(XX_test, b_bounds_[:, -2, 0], color=\"m\")\n",
    "            ax.plot(XX_test, b_bounds_[:, -2, 1], color=\"m\")\n",
    "            ax.set_title(title_template_%(dgp_.__name__, noise_))\n",
    "\n",
    "#             plt.show()\n",
    "            \n",
    "            fig_file_name_ = os.path.join(output_path_, \"%s %g %d %s %g.png\"\n",
    "                                          %(dgp_.__name__, noise_, size_, theta_, nugget_,))\n",
    "            fig.savefig(fig_file_name_)\n",
    "            plt.close()\n",
    "            print fig_file_name_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_1 = load_dumps('./exp1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the plots for the first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "gs = gridspec.GridSpec(3, 2, height_ratios=[6, 6, 1])\n",
    "# ax = figure.add_subplot(gs[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "titles_ = [\"GPR\", \"RRCM\" ,\"CRR\", \"RRCM-loo\", \"CRR-loo\"]\n",
    "colors_ = \"bgrm\"\n",
    "# gs = gridspec.GridSpec(3, 2, height_ratios=[6, 6, 1])\n",
    "gs = gridspec.GridSpec(2, 2, height_ratios=[6, 6])\n",
    "\n",
    "for key_, (rmse_, sizes_, coverage_, width_) in experiment_1.iteritems():\n",
    "    output_path_ = mkdirifnot(os.path.join(PLOT_PATH, key_[0]))\n",
    "    theta_= (\"%g\" if isinstance(key_[2], float) else \"$'%s'$\")%(key_[2],)\n",
    "    title_template_ = \"%%s ($\\\\theta=%s, \\\\lambda=%g$)\"%(theta_, key_[3])\n",
    "    cov_ = np.median(coverage_, axis=-1)\n",
    "    cov_lo_, cov_hi_ = np.percentile(coverage_, [25, 75], axis=-1)\n",
    "    fig = plt.figure(figsize=(7, 6))\n",
    "#     ax = fig.add_subplot(gs[-1:, :])\n",
    "#     ax.plot(sizes_, rmse_)\n",
    "#     ax.set_yticks([])\n",
    "    for j in xrange(1, 5):\n",
    "#         ax = fig.add_subplot(2, 2, j+1-1)\n",
    "        ax = fig.add_subplot(gs[j-1])\n",
    "        ax.set_ylim(0.65, 1.025)\n",
    "        ax.set_xlim(25, 1600)\n",
    "        ax.locator_params(axis=\"x\", nbins=5)\n",
    "        ax.set_yticks(1-levels)\n",
    "        ax.set_title(title_template_%(titles_[j],))\n",
    "        for i in xrange(4):\n",
    "            ax.plot(sizes_, cov_[j, :, i], color=colors_[i])\n",
    "            ax.plot(sizes_, cov_hi_[j, :, i], color=colors_[i], alpha=0.5)\n",
    "            ax.plot(sizes_, cov_lo_[j, :, i], color=colors_[i], alpha=0.5)\n",
    "            ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "#     fig.tight_layout()\n",
    "    theta_= (\"%g\" if isinstance(key_[2], float) else \"%s\")%(key_[2],)\n",
    "    fig_file_name_ = os.path.join(output_path_, \"%s %g %s %g conf_coverage.png\"\n",
    "                                  %(key_[0], key_[1], theta_, key_[3],))\n",
    "    fig.savefig(fig_file_name_)\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "    print fig_file_name_\n",
    "    \n",
    "## Bayes\n",
    "    fig = plt.figure(figsize=(7, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_ylim(0.65, 1.025)\n",
    "    ax.set_xlim(25, 1600)\n",
    "    ax.locator_params(axis=\"x\", nbins=5)\n",
    "    ax.set_yticks(1-levels)\n",
    "    ax.set_title(title_template_%(titles_[0],))\n",
    "    for i in xrange(4):\n",
    "        ax.plot(sizes_, cov_[0, :, i], color=colors_[i])\n",
    "        ax.plot(sizes_, cov_hi_[0, :, i], color=colors_[i], alpha=0.5)\n",
    "        ax.plot(sizes_, cov_lo_[0, :, i], color=colors_[i], alpha=0.5)\n",
    "        ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "    \n",
    "    fig_file_name_ = os.path.join(output_path_, \"%s %g %s %g gpr_coverage.png\"\n",
    "                                  %(key_[0], key_[1], theta_, key_[3],))\n",
    "    fig.savefig(fig_file_name_)\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.stack(MM.shape, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from utils.functions import gaussian\n",
    "from utils.functions_2d import f2, f5\n",
    "\n",
    "func_ = f5\n",
    "\n",
    "\n",
    "# random_state = np.random.RandomState(0xCAFFE14E)\n",
    "nd = 2\n",
    "mesh_ = np.meshgrid(*nd*[np.linspace(-1, 1, num=51)])\n",
    "XX_test = np.concatenate([ax_.reshape((-1, 1)) for ax_ in mesh_], axis=1)\n",
    "XX_train = 2*random_state.uniform(size=(1500, nd))-1\n",
    "\n",
    "# XX_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "# XX_train = random_state.uniform(size=(1000, 1))\n",
    "\n",
    "\n",
    "\n",
    "XX = np.concatenate([XX_test, XX_train], axis=0)\n",
    "test_ = np.s_[:XX_test.shape[0]]\n",
    "# yy = gaussian(XX, scale=1.0, nugget=1e-6, metric=kernel,\n",
    "#               gamma=100, random_state=random_state)\n",
    "yy = func_(XX)\n",
    "if yy.ndim == 1:\n",
    "    yy = yy.reshape((-1, 1))\n",
    "yy += random_state.normal(size=yy.shape) * 1e-1\n",
    "\n",
    "\n",
    "yy_train, yy_test = np.delete(yy, test_, axis=0), yy[test_].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(2, 2, j, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], yy_test.reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(2, 2, j, projection='3d')\n",
    "ax.plot_trisurf(XX_train[:, 0], XX_train[:, 1], yy_train[:,0],\n",
    "                cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9, shade=True)\n",
    "ax.view_init(60, -60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp = GaussianProcess(beta0=0, normalize=False, corr='squared_exponential', nugget=1e-1,\n",
    "                     theta0=10)#, thetaL=1, thetaU=1e+4)\n",
    "gp.fit(XX_train, yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp.theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hat_, mse_ = gp.predict(XX_test, eval_MSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean((yy_test-hat_)**2) / np.var(yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(2, 2, j, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], np.abs(yy_test-hat_).reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)\n",
    "\n",
    "# plt.plot(np.sqrt(mse_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(2, 2, j, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], hat_.reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(XX_test, yy_test)\n",
    "plt.plot(XX_test, hat_, c='r', lw=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(XX_test, np.abs(yy_test-hat_), c='r', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_3 = load_dumps('./exp3')\n",
    "import matplotlib.gridspec as gridspec\n",
    "gs = gridspec.GridSpec(3, 2, height_ratios=[6, 6, 1])\n",
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "titles_ = [\"GPR\", \"RRCM\" ,\"CRR\", \"RRCM-loo\", \"CRR-loo\"]\n",
    "colors_ = \"bgrm\"\n",
    "# gs = gridspec.GridSpec(3, 2, height_ratios=[6, 6, 1])\n",
    "gs = gridspec.GridSpec(2, 2, height_ratios=[6, 6])\n",
    "\n",
    "for key_, (rmse_, sizes_, coverage_, width_) in experiment_3.iteritems():\n",
    "    output_path_ = mkdirifnot(os.path.join(PLOT_PATH, key_[0]))\n",
    "    theta_= (\"%g\" if isinstance(key_[2], float) else \"$'%s'$\")%(key_[2],)\n",
    "    title_template_ = \"%%s ($\\\\theta=%s, \\\\lambda=%g$)\"%(theta_, key_[3])\n",
    "    cov_ = np.median(coverage_, axis=-1)\n",
    "    cov_lo_, cov_hi_ = np.percentile(coverage_, [25, 75], axis=-1)\n",
    "    fig = plt.figure(figsize=(7, 6))\n",
    "#     ax = fig.add_subplot(gs[-1:, :])\n",
    "#     ax.plot(sizes_, rmse_)\n",
    "#     ax.set_yticks([])\n",
    "    for j in xrange(1, 5):\n",
    "#         ax = fig.add_subplot(2, 2, j+1-1)\n",
    "        ax = fig.add_subplot(gs[j-1])\n",
    "        ax.set_ylim(0.65, 1.025)\n",
    "        ax.set_xlim(25, 1600)\n",
    "        ax.locator_params(axis=\"x\", nbins=5)\n",
    "        ax.set_yticks(1-levels)\n",
    "        ax.set_title(title_template_%(titles_[j],))\n",
    "        for i in xrange(4):\n",
    "            ax.plot(sizes_, cov_[j, :, i], color=colors_[i])\n",
    "            ax.plot(sizes_, cov_hi_[j, :, i], color=colors_[i], alpha=0.5)\n",
    "            ax.plot(sizes_, cov_lo_[j, :, i], color=colors_[i], alpha=0.5)\n",
    "            ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "#     fig.tight_layout()\n",
    "    theta_= (\"%g\" if isinstance(key_[2], float) else \"%s\")%(key_[2],)\n",
    "    fig_file_name_ = os.path.join(output_path_, \"%s %g %s %g conf_coverage.png\"\n",
    "                                  %(key_[0], key_[1], theta_, key_[3],))\n",
    "    fig.savefig(fig_file_name_)\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "    print fig_file_name_\n",
    "    \n",
    "## Bayes\n",
    "    fig = plt.figure(figsize=(7, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_ylim(0.65, 1.025)\n",
    "    ax.set_xlim(25, 1600)\n",
    "    ax.locator_params(axis=\"x\", nbins=5)\n",
    "    ax.set_yticks(1-levels)\n",
    "    ax.set_title(title_template_%(titles_[0],))\n",
    "    for i in xrange(4):\n",
    "        ax.plot(sizes_, cov_[0, :, i], color=colors_[i])\n",
    "        ax.plot(sizes_, cov_hi_[0, :, i], color=colors_[i], alpha=0.5)\n",
    "        ax.plot(sizes_, cov_lo_[0, :, i], color=colors_[i], alpha=0.5)\n",
    "        ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "    \n",
    "    fig_file_name_ = os.path.join(output_path_, \"%s %g %s %g gpr_coverage.png\"\n",
    "                                  %(key_[0], key_[1], theta_, key_[3],))\n",
    "    fig.savefig(fig_file_name_)\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_5 = load_dumps('./exp5')\n",
    "import matplotlib.gridspec as gridspec\n",
    "gs = gridspec.GridSpec(3, 2, height_ratios=[6, 6, 1])\n",
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "titles_ = [\"GPR\", \"RRCM\" ,\"CRR\", \"RRCM-loo\", \"CRR-loo\"]\n",
    "colors_ = \"bgrm\"\n",
    "# gs = gridspec.GridSpec(3, 2, height_ratios=[6, 6, 1])\n",
    "gs = gridspec.GridSpec(2, 2, height_ratios=[6, 6])\n",
    "\n",
    "for key_, (rmse_, sizes_, coverage_, width_) in experiment_5.iteritems():\n",
    "    output_path_ = mkdirifnot(os.path.join(PLOT_PATH, key_[0]))\n",
    "    theta_= (\"%g\" if isinstance(key_[2], float) else \"$'%s'$\")%(key_[2],)\n",
    "    title_template_ = \"%%s ($\\\\theta=%s, \\\\lambda=%g$)\"%(theta_, key_[3])\n",
    "    cov_ = np.median(coverage_, axis=-1)\n",
    "    cov_lo_, cov_hi_ = np.percentile(coverage_, [25, 75], axis=-1)\n",
    "    fig = plt.figure(figsize=(7, 6))\n",
    "#     ax = fig.add_subplot(gs[-1:, :])\n",
    "#     ax.plot(sizes_, rmse_)\n",
    "#     ax.set_yticks([])\n",
    "    for j in xrange(1, 5):\n",
    "#         ax = fig.add_subplot(2, 2, j+1-1)\n",
    "        ax = fig.add_subplot(gs[j-1])\n",
    "        ax.set_ylim(0.65, 1.025)\n",
    "        ax.set_xlim(25, 1600)\n",
    "        ax.locator_params(axis=\"x\", nbins=5)\n",
    "        ax.set_yticks(1-levels)\n",
    "        ax.set_title(title_template_%(titles_[j],))\n",
    "        for i in xrange(4):\n",
    "            ax.plot(sizes_, cov_[j, :, i], color=colors_[i])\n",
    "            ax.plot(sizes_, cov_hi_[j, :, i], color=colors_[i], alpha=0.5)\n",
    "            ax.plot(sizes_, cov_lo_[j, :, i], color=colors_[i], alpha=0.5)\n",
    "            ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "#     fig.tight_layout()\n",
    "    theta_= (\"%g\" if isinstance(key_[2], float) else \"%s\")%(key_[2],)\n",
    "    fig_file_name_ = os.path.join(output_path_, \"%s %g %s %g conf_coverage.png\"\n",
    "                                  %(key_[0], key_[1], theta_, key_[3],))\n",
    "    fig.savefig(fig_file_name_)\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "    print fig_file_name_\n",
    "    \n",
    "## Bayes\n",
    "    fig = plt.figure(figsize=(7, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_ylim(0.65, 1.025)\n",
    "    ax.set_xlim(25, 1600)\n",
    "    ax.locator_params(axis=\"x\", nbins=5)\n",
    "    ax.set_yticks(1-levels)\n",
    "    ax.set_title(title_template_%(titles_[0],))\n",
    "    for i in xrange(4):\n",
    "        ax.plot(sizes_, cov_[0, :, i], color=colors_[i])\n",
    "        ax.plot(sizes_, cov_hi_[0, :, i], color=colors_[i], alpha=0.5)\n",
    "        ax.plot(sizes_, cov_lo_[0, :, i], color=colors_[i], alpha=0.5)\n",
    "        ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "    \n",
    "    fig_file_name_ = os.path.join(output_path_, \"%s %g %s %g gpr_coverage.png\"\n",
    "                                  %(key_[0], key_[1], theta_, key_[3],))\n",
    "    fig.savefig(fig_file_name_)\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "from sklearn.base import clone\n",
    "\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from utils.functions_1d import f6, pressure2, heaviside\n",
    "\n",
    "from utils.conformal import RRCM, CRR\n",
    "from utils.KRR import KRR_AB\n",
    "\n",
    "def _helper(y, A, B, proc=RRCM, levels=levels, parallel=None, n_jobs=1, verbose=0):\n",
    "    if not isinstance(parallel, Parallel):\n",
    "        parallel = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "## Construct the CKRR confidence interval: RRCM\n",
    "    regions = parallel(delayed(proc)(A[k], B[k], levels=levels)\n",
    "                       for k in xrange(y.shape[0]))\n",
    "\n",
    "## See if the transformed test target valeus are with the conformal region\n",
    "    hits_ = np.asarray(\n",
    "        [[np.any(((int_[:, 0] <= target) & (target <= int_[:, 1]))).astype(float)\n",
    "          for int_ in region]\n",
    "         for target, region in zip(y, regions)])\n",
    "\n",
    "    width_ = np.asarray(\n",
    "        [[np.sum(int_[:, 1] - int_[:, 0]) for int_ in region] for region in regions])\n",
    "    \n",
    "    bounds_ = np.asarray(\n",
    "        [[[int_[:, 0].min(), int_[:, 1].max()] for int_ in region] for region in regions])\n",
    "    return hits_, width_, bounds_\n",
    "\n",
    "n_jobs, verbose = -1, 0\n",
    "parallel_ = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "random_state = np.random.RandomState(0x6AE89C43)\n",
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "\n",
    "## Initialize\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "kernel = 'rbf' # 'laplacian'\n",
    "gp = GaussianProcess(beta0=0, normalize=False, corr='squared_exponential')\n",
    "\n",
    "funcs_ = [f6, pressure2, heaviside]\n",
    "\n",
    "grid_ = ParameterGrid(dict(size=[150, 500,],\n",
    "                           nugget=[1e-6, 1e-2],\n",
    "                           theta0=[1e-1, 1.0, 1e+1,]))\n",
    "\n",
    "## Get a sample realisation\n",
    "XX_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "XX_train = random_state.uniform(size=(10000, 1))\n",
    "\n",
    "XX = np.concatenate([XX_test, XX_train], axis=0)\n",
    "test_ = np.s_[:XX_test.shape[0]]\n",
    "\n",
    "output_path_ = mkdirifnot(os.path.join(PLOT_PATH, \"profiles\"))\n",
    "for dgp_ in funcs_:\n",
    "    for noise_ in [1e-6, 1e-1,]:\n",
    "        yy = dgp_(XX)\n",
    "        if yy.ndim == 1:\n",
    "            yy = yy.reshape((-1, 1))\n",
    "        if noise_ > 0:\n",
    "            yy += random_state.normal(size=yy.shape) * noise_\n",
    "        yy_train, yy_test = np.delete(yy, test_, axis=0), yy[test_].copy()\n",
    "        del yy\n",
    "\n",
    "        for i_, par_ in enumerate(grid_):\n",
    "            size_, nugget_, theta0_ = par_['size'], par_['nugget'], par_['theta0']\n",
    "\n",
    "            \n",
    "            theta_= (\"%g\" if isinstance(theta0_, float) else \"$'%s'$\")%(theta0_,)\n",
    "            title_template_ = \"%%s %%g ($n=%d, \\\\theta=%s, \\\\lambda=%g$)\"%(size_, theta_, nugget_)\n",
    "\n",
    "            # Draw random train sample\n",
    "            train_ = random_state.choice(range(XX_train.shape[0]),\n",
    "                                         size=size_, replace=False)\n",
    "            X, y = XX_train[train_], yy_train[train_]\n",
    "\n",
    "            Xscl_, yscl_ = clone(scaler).fit(X), clone(scaler).fit(y)\n",
    "            X_, XX_test_ = Xscl_.transform(X), Xscl_.transform(XX_test)\n",
    "            y_, yy_test_ = yscl_.transform(y), yscl_.transform(yy_test)\n",
    "        \n",
    "            # Fir a gpr\n",
    "            gp_ = clone(gp)\n",
    "            gp_.nugget = nugget_\n",
    "            if isinstance(theta0_, float):\n",
    "                gp_.theta0 = theta0_\n",
    "            elif theta0_ == \"auto\":\n",
    "                gp_.thetaL, gp_.thetaU, gp_.theta0 = 1e-4, 1e4, float(size_)\n",
    "            gp_.fit(X_, y_)\n",
    "\n",
    "            # Compute the A, B matrices\n",
    "            A, B, y_hat_, MM, loo_, A_loo, B_loo = KRR_AB(\n",
    "                X_, y_, XX_test_, forecast=True, nugget=gp_.nugget,\n",
    "                metric=kernel, gamma=gp_.theta_[0])\n",
    "            del loo_\n",
    "\n",
    "            # Inflate by the estimated magnitude\n",
    "            MM *= gp_.sigma2\n",
    "\n",
    "\n",
    "        ## Construct the Bayesian interval\n",
    "            z_a = norm.ppf(1 - .5 * levels)\n",
    "            half_width_ = np.sqrt(MM) * z_a[np.newaxis]\n",
    "            b_bounds_ = yscl_.inverse_transform(\n",
    "                np.stack([y_hat_ - half_width_, y_hat_ + half_width_], axis=-1))\n",
    "            b_width_ = b_bounds_[..., 1] - b_bounds_[..., 0]\n",
    "            b_hits_ = ((b_bounds_[..., 0] <= yy_test) & (yy_test <= b_bounds_[..., 1])).astype(float)\n",
    "\n",
    "        ## Construct the CKRR confidence interval: RRCM\n",
    "            rrcm_hits_, rrcm_width_, rrcm_bounds_ = _helper(yy_test_, A[0], B, proc=RRCM,\n",
    "                                              levels=levels, parallel=parallel_)\n",
    "            if yscl_.scale_ is not None:\n",
    "                rrcm_width_ *= yscl_.scale_\n",
    "\n",
    "        ## Construct the CKRR confidence interval: CCR-sided\n",
    "            crr_hits_, crr_width_, crr_bounds_ = _helper(yy_test_, A[0], B, proc=CRR,\n",
    "                                            levels=levels, parallel=parallel_)\n",
    "            if yscl_.scale_ is not None:\n",
    "                crr_width_ *= yscl_.scale_\n",
    "\n",
    "        ## Construct the CKRR confidence interval: RRCM\n",
    "            loo_rrcm_hits_, loo_rrcm_width_, loo_rrcm_bounds_ = _helper(yy_test_, A_loo[0], B_loo, proc=RRCM,\n",
    "                                                      levels=levels, parallel=parallel_)\n",
    "            if yscl_.scale_ is not None:\n",
    "                loo_rrcm_width_ *= yscl_.scale_\n",
    "\n",
    "        ## Construct the CKRR confidence interval: CCR-sided\n",
    "            loo_crr_hits_, loo_crr_width_, loo_crr_bounds_ = _helper(yy_test_, A_loo[0], B_loo, proc=CRR,\n",
    "                                                    levels=levels, parallel=parallel_)\n",
    "            if yscl_.scale_ is not None:\n",
    "                loo_crr_width_ *= yscl_.scale_\n",
    "\n",
    "            rrcm_bounds = yscl_.inverse_transform(rrcm_bounds_)\n",
    "            crr_bounds = yscl_.inverse_transform(crr_bounds_)\n",
    "            loo_rrcm_bounds = yscl_.inverse_transform(loo_rrcm_bounds_)\n",
    "            loo_crr_bounds = yscl_.inverse_transform(loo_crr_bounds_)\n",
    "            y_hat = yscl_.inverse_transform(y_hat_)\n",
    "\n",
    "            bounds = np.stack([rrcm_bounds, crr_bounds,\n",
    "                               loo_rrcm_bounds, loo_crr_bounds],\n",
    "                              axis=-1)\n",
    "\n",
    "            ## Profile\n",
    "            col_ = list(\"rbgk\")\n",
    "            fig = plt.figure(figsize=(5, 5))\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.plot(XX_test, yy_test, c=\"k\")\n",
    "            ax.plot(XX_test, y_hat, linestyle=':')\n",
    "            for j in range(4):\n",
    "                ax.plot(XX_test, bounds[:, -2, 0, j], color=col_[j], alpha=.5)\n",
    "                ax.plot(XX_test, bounds[:, -2, 1, j], color=col_[j], alpha=.5)\n",
    "            ax.plot(XX_test, b_bounds_[:, -2, 0], color=\"m\")\n",
    "            ax.plot(XX_test, b_bounds_[:, -2, 1], color=\"m\")\n",
    "            ax.set_title(title_template_%(dgp_.__name__, noise_))\n",
    "\n",
    "#             plt.show()\n",
    "            \n",
    "            fig_file_name_ = os.path.join(output_path_, \"%s %g %d %s %g.png\"\n",
    "                                          %(dgp_.__name__, noise_, size_, theta_, nugget_,))\n",
    "            fig.savefig(fig_file_name_)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(sizes_, rmse_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse_, sizes_, coverage_, width_ = results_[('heaviside', 0.01, 1, 1e-06)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "w_ = np.mean(width_, axis=-1)\n",
    "# w_std_ = np.std(width_, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j in xrange(11):\n",
    "    for i in xrange(5):\n",
    "        plt.plot(X_test, w_[i, j, ..., -1].T, label=titles_[i])\n",
    "        plt.legend(loc=\"best\", ncol=2)\n",
    "#     plt.title(titles_[j])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.concatenate([exp_[1] for exp_ in experiment], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "plt.plot(X_test, np.concatenate([exp_[1] for exp_ in experiment[:88]], axis=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_ = \"./exp2\"\n",
    "dumps_ = [_load(os.path.join(base_, fname_))\n",
    "          for fname_ in os.listdir(base_)\n",
    "          if fname_.endswith(\".gz\")]\n",
    "experiment = [exp_ for dump_ in dumps_ for exp_ in dump_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nd = 2\n",
    "mesh_ = np.meshgrid(*nd*[np.linspace(-1, 1, num=51)])\n",
    "X_test = np.concatenate([ax_.reshape((-1, 1)) for ax_ in mesh_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "titles_ = [\"GPR\", \"RRCM\" ,\"CRR\", \"RRCM-loo\", \"CRR-loo\"]\n",
    "colors_ = \"bgrm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_ = dict()\n",
    "for exp_ in experiment:\n",
    "    key_ = exp_[0][:-1]\n",
    "    if key_ not in temp_:\n",
    "        temp_[key_] = list()\n",
    "    temp_[key_].append((exp_[0][-1], exp_[1:]))\n",
    "    \n",
    "temp_ = {key_ : sorted(res_, key=lambda x: x[0])\n",
    "         for key_, res_ in temp_.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_ = dict()\n",
    "for key_, result_ in temp_.iteritems():\n",
    "    rmse_ = np.stack([np.mean((res_[1][0]-res_[1][1])**2, axis=-1) for res_ in result_], axis=0)\n",
    "    sizes_ = np.array([res_[0] for res_ in result_])\n",
    "    coverage_ = np.stack([np.stack([res_[1][3::2][j] for res_ in result_], axis=0) for j in xrange(5)], axis=0)\n",
    "    width_ = np.stack([np.stack([res_[1][2::2][j] for res_ in result_], axis=0) for j in xrange(5)], axis=0)\n",
    "    results_[key_] = rmse_, sizes_, coverage_, width_\n",
    "\n",
    "    print key_\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    for j in xrange(1, len(titles_)):\n",
    "        ax = fig.add_subplot(2, 2, j, projection='3d')\n",
    "        s_, pv_ = 0, 0\n",
    "        rel_ = np.median(width_, axis=-1)[j, s_, :, pv_] / np.median(width_, axis=-1)[0, s_, :, pv_] - 1\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], rel_.reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.9)\n",
    "        ax.view_init(60, -60)\n",
    "        ax.set_title(\"%s / %s - 1\"%(titles_[j], titles_[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print key_\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], rmse_[0].reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)\n",
    "ax.set_title(title_template_%(\"%s %g\"%(key_[:2]),))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key_, (rmse_, sizes_, coverage_, width_) in results_.iteritems():\n",
    "    output_path_ = mkdirifnot(os.path.join(PLOT_PATH, key_[0]))\n",
    "    theta_= (\"%g\" if isinstance(key_[2], float) else \"$'%s'$\")%(key_[2],)\n",
    "    title_template_ = \"%%s ($\\\\theta=%s, \\\\lambda=%g$)\"%(theta_, key_[3])\n",
    "    cov_ = np.median(coverage_, axis=-1)\n",
    "    cov_lo_, cov_hi_ = np.percentile(coverage_, [25, 75], axis=-1)\n",
    "#     break\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 3))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(mesh_[0], mesh_[1], rmse_[0].reshape(mesh_[0].shape),\n",
    "                    cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                    antialiased=False, alpha=0.9)\n",
    "    ax.view_init(60, -60)\n",
    "    ax.set_title(title_template_%(\"%s %g\"%(key_[:2]),))\n",
    "    plt.show()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for exp_ in experiment:\n",
    "    \n",
    "#     theta_= (\"%g\" if isinstance(key_[2], float) else \"$'%s'$\")%(key_[2],)\n",
    "#     title_template_ = \"%%s ($\\\\theta=%s, \\\\lambda=%g$)\"%(theta_, key_[3])\n",
    "    y_test_ = exp_[1].mean(axis=-1, keepdims=True)\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 3))\n",
    "#     ax = fig.add_subplot(121, projection='3d')\n",
    "#     ax.plot_surface(mesh_[0], mesh_[1], y_test_.reshape(mesh_[0].shape),\n",
    "#                     cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "#                     antialiased=False, alpha=0.9)\n",
    "#     ax.view_init(60, -60)\n",
    "#     ax.set_title(exp_[0][0])\n",
    "    \n",
    "    y_test_ = (exp_[1]-exp_[2]).mean(axis=-1, keepdims=True)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(mesh_[0], mesh_[1], y_test_.reshape(mesh_[0].shape),\n",
    "                    cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                    antialiased=False, alpha=0.9)\n",
    "    ax.view_init(60, -60)\n",
    "    ax.set_title(exp_[0][0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_ = \"./exp3\"\n",
    "dumps_ = [_load(os.path.join(base_, fname_))\n",
    "          for fname_ in os.listdir(base_)\n",
    "          if fname_.endswith(\".pic.gz\")]\n",
    "experiment = [exp_ for dump_ in dumps_ for exp_ in dump_]\n",
    "\n",
    "temp_ = dict()\n",
    "for exp_ in experiment:\n",
    "    key_ = exp_[0][:-1]\n",
    "    if key_ not in temp_:\n",
    "        temp_[key_] = list()\n",
    "    temp_[key_].append((exp_[0][-1], exp_[1:]))\n",
    "    \n",
    "temp_ = {key_ : sorted(res_, key=lambda x: x[0])\n",
    "         for key_, res_ in temp_.iteritems()}\n",
    "\n",
    "results_ = dict()\n",
    "for key_, result_ in temp_.iteritems():\n",
    "    rmse_ = np.stack([np.mean((res_[1][0]-res_[1][1])**2) for res_ in result_], axis=0)\n",
    "    sizes_ = np.array([res_[0] for res_ in result_])\n",
    "    coverage_ = np.stack([np.stack([res_[1][3::2][j] for res_ in result_], axis=0) for j in xrange(5)], axis=0)\n",
    "    width_ = np.stack([np.stack([res_[1][2::2][j] for res_ in result_], axis=0) for j in xrange(5)], axis=0)\n",
    "    results_[key_] = rmse_, sizes_, coverage_, width_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "titles_ = [\"GPR\", \"RRCM\" ,\"CRR\", \"RRCM-loo\", \"CRR-loo\"]\n",
    "colors_ = \"bgrm\"\n",
    "# gs = gridspec.GridSpec(3, 2, height_ratios=[6, 6, 1])\n",
    "gs = gridspec.GridSpec(2, 2, height_ratios=[6, 6])\n",
    "\n",
    "for key_, (rmse_, sizes_, coverage_, width_) in results_.iteritems():\n",
    "    output_path_ = mkdirifnot(os.path.join(PLOT_PATH, key_[0]))\n",
    "    theta_= (\"%g\" if isinstance(key_[2], float) else \"$'%s'$\")%(key_[2],)\n",
    "    title_template_ = \"%%s ($\\\\theta=%s, \\\\lambda=%g$)\"%(theta_, key_[3])\n",
    "    cov_ = np.median(coverage_, axis=-1)\n",
    "    cov_lo_, cov_hi_ = np.percentile(coverage_, [25, 75], axis=-1)\n",
    "    fig = plt.figure(figsize=(7, 6))\n",
    "#     ax = fig.add_subplot(gs[-1:, :])\n",
    "#     ax.plot(sizes_, rmse_)\n",
    "#     ax.set_yticks([])\n",
    "    for j in xrange(1, 5):\n",
    "#         ax = fig.add_subplot(2, 2, j+1-1)\n",
    "        ax = fig.add_subplot(gs[j-1])\n",
    "        ax.set_ylim(0.65, 1.025)\n",
    "        ax.set_xlim(25, 1600)\n",
    "        ax.locator_params(axis=\"x\", nbins=5)\n",
    "        ax.set_yticks(1-levels)\n",
    "        ax.set_title(title_template_%(titles_[j],))\n",
    "        for i in xrange(4):\n",
    "            ax.plot(sizes_, cov_[j, :, i], color=colors_[i])\n",
    "            ax.plot(sizes_, cov_hi_[j, :, i], color=colors_[i], alpha=0.5)\n",
    "            ax.plot(sizes_, cov_lo_[j, :, i], color=colors_[i], alpha=0.5)\n",
    "            ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "#     fig.tight_layout()\n",
    "    theta_= (\"%g\" if isinstance(key_[2], float) else \"%s\")%(key_[2],)\n",
    "    fig_file_name_ = os.path.join(output_path_, \"%s %g %s %g conf_coverage.png\"\n",
    "                                  %(key_[0], key_[1], theta_, key_[3],))\n",
    "    fig.savefig(fig_file_name_)\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "    print fig_file_name_\n",
    "    \n",
    "## Bayes\n",
    "    fig = plt.figure(figsize=(7, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_ylim(0.65, 1.025)\n",
    "    ax.set_xlim(25, 1600)\n",
    "    ax.locator_params(axis=\"x\", nbins=5)\n",
    "    ax.set_yticks(1-levels)\n",
    "    ax.set_title(title_template_%(titles_[0],))\n",
    "    for i in xrange(4):\n",
    "        ax.plot(sizes_, cov_[0, :, i], color=colors_[i])\n",
    "        ax.plot(sizes_, cov_hi_[0, :, i], color=colors_[i], alpha=0.5)\n",
    "        ax.plot(sizes_, cov_lo_[0, :, i], color=colors_[i], alpha=0.5)\n",
    "        ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "    \n",
    "    fig_file_name_ = os.path.join(output_path_, \"%s %g %s %g gpr_coverage.png\"\n",
    "                                  %(key_[0], key_[1], theta_, key_[3],))\n",
    "    fig.savefig(fig_file_name_)\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.linspace(0, 1, num=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for exp_ in experiment:\n",
    "    \n",
    "    theta_= (\"%g\" if isinstance(exp_[0][2], float) else \"$'%s'$\")%(exp_[0][2],)\n",
    "    title_template_ = \"%%s ($\\\\theta=%s, \\\\lambda=%g$)\"%(theta_, exp_[0][3])\n",
    "    y_test_ = exp_[2][..., -1, np.newaxis]#(axis=-1, keepdims=True)\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 3))\n",
    "#     ax = fig.add_subplot(121, projection='3d')\n",
    "#     ax.plot_surface(mesh_[0], mesh_[1], y_test_.reshape(mesh_[0].shape),\n",
    "#                     cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "#                     antialiased=False, alpha=0.9)\n",
    "#     ax.view_init(60, -60)\n",
    "#     ax.set_title(exp_[0][0])\n",
    "    \n",
    "    y_test_ = (exp_[1] - exp_[2]).mean(axis=-1, keepdims=True)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(X_test, y_test_)\n",
    "    ax.set_title(title_template_%(\"%s %g\"%(exp_[0][:2]),))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from utils.functions import gaussian\n",
    "random_state = np.random.RandomState(0xCAFFE14E)\n",
    "\n",
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "\n",
    "\n",
    "## Define the grid\n",
    "kernel = 'rbf' # 'laplacian'\n",
    "\n",
    "## Run: experiment #3\n",
    "# nd = 2\n",
    "# mesh_ = np.meshgrid(*nd*[np.linspace(-1, 1, num=51)])\n",
    "# X_test = np.concatenate([ax_.reshape((-1, 1)) for ax_ in mesh_], axis=1)\n",
    "X_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "test_ = np.s_[:X_test.shape[0]]\n",
    "## Draw f(x)\n",
    "XX_train = random_state.uniform(size=(10000, 1))\n",
    "XX = np.concatenate([X_test, XX_train], axis=0)\n",
    "yy = gaussian(XX, scale=1.0, nugget=1e-2, metric=kernel,\n",
    "              gamma=100.0, random_state=random_state)\n",
    "if yy.ndim == 1:\n",
    "    yy = yy.reshape((-1, 1))\n",
    "\n",
    "## Split the pooled sample\n",
    "yy_train, y_test = np.delete(yy, test_, axis=0), yy[test_].copy()\n",
    "# del XX, yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(XX, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "\n",
    "from utils.conformal import RRCM, CRR\n",
    "from utils.KRR import KRR_AB\n",
    "\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.base import clone\n",
    "\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "## Define the grid\n",
    "grid_ = ParameterGrid(dict(dgp=[gaussian,],\n",
    "                           size=[25, 50, 100, 200, 400, 600, 800, 1000, 1200, 1400, 1600,],\n",
    "                           # size=[150, 1500,],\n",
    "                           nugget=[1e-6, 1e-2,],\n",
    "                           theta0=[1e-1, 1, 1e+1, \"auto\"],\n",
    "                           noise=[1e-6,]))\n",
    "\n",
    "## Initialize\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "gp = GaussianProcess(beta0=0, normalize=False, corr='squared_exponential')\n",
    "kernel = 'rbf' # 'laplacian'\n",
    "\n",
    "n_jobs, verbose = -1, 0\n",
    "parallel_ = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "def _helper(y, A, B, proc=RRCM, levels=levels, parallel=None, n_jobs=1, verbose=0):\n",
    "    if not isinstance(parallel, Parallel):\n",
    "        parallel = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "## Construct the CKRR confidence interval: RRCM\n",
    "    regions = parallel(delayed(proc)(A[k], B[k], levels=levels)\n",
    "                       for k in xrange(y.shape[0]))\n",
    "\n",
    "## See if the transformed test target valeus are with the conformal region\n",
    "    hits_ = np.asarray(\n",
    "        [[np.any(((int_[:, 0] <= target) & (target <= int_[:, 1]))).astype(float)\n",
    "          for int_ in region]\n",
    "         for target, region in zip(y, regions)])\n",
    "\n",
    "    width_ = np.asarray(\n",
    "        [[np.sum(int_[:, 1] - int_[:, 0]) for int_ in region] for region in regions])\n",
    "    \n",
    "    bounds_ = np.asarray(\n",
    "        [[[int_[:, 0].min(), int_[:, 1].max()] for int_ in region] for region in regions])\n",
    "    return hits_, width_, bounds_\n",
    "\n",
    "\n",
    "## Run: experiment #3\n",
    "# nd = 2\n",
    "# mesh_ = np.meshgrid(*nd*[np.linspace(-1, 1, num=51)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i_, par_ in enumerate(grid_):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    n_replications, replications = 20, list()\n",
    "\n",
    "    dgp_, size_, noise_ = par_['dgp'], par_['size'], par_['noise']\n",
    "    nugget_, theta0_ = par_['nugget'], par_['theta0']\n",
    "\n",
    "    tick_ = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## START: one replication\n",
    "## Draw random train sample\n",
    "train_ = random_state.choice(range(XX_train.shape[0]),\n",
    "                             size=size_, replace=False)\n",
    "X_train, y_train = XX_train[train_], yy_train[train_]\n",
    "\n",
    "## Standardize the sample\n",
    "Xscl_, yscl_ = clone(scaler).fit(X_train), clone(scaler).fit(y_train)\n",
    "X_train_, X_test_ = Xscl_.transform(X_train), Xscl_.transform(X_test)\n",
    "y_train_, y_test_ = yscl_.transform(y_train), yscl_.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Fit a GPR\n",
    "gp_ = clone(gp)\n",
    "gp_.nugget = nugget_\n",
    "if isinstance(theta0_, float):\n",
    "    gp_.theta0 = theta0_\n",
    "elif theta0_ == \"auto\":\n",
    "    gp_.thetaL, gp_.thetaU, gp_.theta0 = 1e-4, 1e4, float(size_)\n",
    "gp_.fit(X_train_, y_train_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Compute the A, B matrices\n",
    "A, B, y_hat_, MM, loo_, A_loo, B_loo = KRR_AB(\n",
    "    X_train_, y_train_, X_test_, forecast=True,\n",
    "    nugget=gp_.nugget, metric=kernel, gamma=gp_.theta_[0])\n",
    "del loo_\n",
    "## Inflate by the estimated magnitude\n",
    "MM *= gp_.sigma2\n",
    "\n",
    "## Construct the Bayesian interval\n",
    "z_a = norm.ppf(1 - .5 * levels)\n",
    "half_width_ = np.sqrt(MM) * z_a[np.newaxis]\n",
    "b_bounds_ = yscl_.inverse_transform(\n",
    "    np.stack([y_hat_ - half_width_, y_hat_ + half_width_], axis=-1))\n",
    "b_width_ = b_bounds_[..., 1] - b_bounds_[..., 0]\n",
    "b_hits_ = ((b_bounds_[..., 0] <= y_test) & (y_test <= b_bounds_[..., 1])).astype(float)\n",
    "\n",
    "## Construct the CKRR confidence interval: RRCM\n",
    "rrcm_hits_, rrcm_width_, rrcm_bounds_ = _helper(y_test_, A[0], B, proc=RRCM,\n",
    "                                  levels=levels, parallel=parallel_)\n",
    "rrcm_bounds_ = yscl_.inverse_transform(rrcm_bounds_)\n",
    "if yscl_.scale_ is not None:\n",
    "    rrcm_width_ *= yscl_.scale_\n",
    "\n",
    "## Construct the CKRR confidence interval: CCR-sided\n",
    "crr_hits_, crr_width_, crr_bounds_ = _helper(y_test_, A[0], B, proc=CRR,\n",
    "                                levels=levels, parallel=parallel_)\n",
    "crr_bounds_ = yscl_.inverse_transform(crr_bounds_)\n",
    "if yscl_.scale_ is not None:\n",
    "    crr_width_ *= yscl_.scale_\n",
    "\n",
    "## Construct the CKRR confidence interval: RRCM\n",
    "loo_rrcm_hits_, loo_rrcm_width_, loo_rrcm_bounds_ = _helper(y_test_, A_loo[0], B_loo, proc=RRCM,\n",
    "                                          levels=levels, parallel=parallel_)\n",
    "loo_rrcm_bounds_ = yscl_.inverse_transform(loo_rrcm_bounds_)\n",
    "if yscl_.scale_ is not None:\n",
    "    loo_rrcm_width_ *= yscl_.scale_\n",
    "\n",
    "## Construct the CKRR confidence interval: CCR-sided\n",
    "loo_crr_hits_, loo_crr_width_, loo_crr_bounds_ = _helper(y_test_, A_loo[0], B_loo, proc=CRR,\n",
    "                                        levels=levels, parallel=parallel_)\n",
    "loo_crr_bounds_ = yscl_.inverse_transform(loo_crr_bounds_)\n",
    "if yscl_.scale_ is not None:\n",
    "    loo_crr_width_ *= yscl_.scale_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa_, bb_ = b_bounds_[:, 0].T\n",
    "aa, bb = loo_rrcm_bounds_[:, 0].T\n",
    "aa_, bb_ = rrcm_bounds_[:, 0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X_test, aa)\n",
    "plt.plot(X_test, bb)\n",
    "plt.plot(X_test, aa_)\n",
    "plt.plot(X_test, bb_)\n",
    "plt.plot(X_test, y_test)\n",
    "plt.plot(X_test, y_hat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X_test, aa)\n",
    "plt.plot(X_test, bb)\n",
    "plt.plot(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from utils.monte_carlo import run_ckrr_mc_experiment\n",
    "from utils.state import _save\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from utils.functions_1d import get_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the functions to experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "funcs_ = [\"f6\", \"pressure2\", \"heaviside\"]\n",
    "func1d_ = {fname_: fn_\n",
    "           for fname_, fn_ in get_functions().iteritems() if fname_ in funcs_}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot typical profiles for the 1D test functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fname_, fn_ in func1d_.iteritems():\n",
    "    fig = plt.figure(figsize=(5, 4))\n",
    "    X = np.linspace(0, 1, num=1001)\n",
    "    y = fn_(X)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(X, y)\n",
    "    if fname_ != 'pressure2':\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "    fig_name_ = os.path.join(PLOT_PATH, \"1d_func_%s.png\"%(fname_,))\n",
    "    fig.savefig(fig_name_)\n",
    "    plt.close()\n",
    "    print fig_name_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment #1: validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment #2: gaussian case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment #3: 2d case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.percentile((np.abs(exp_[1] - exp_[2])**2), [25, 75], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.base import clone\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.grid_search import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_ = ParameterGrid(dict(dgp=func1d_.values(),\n",
    "                           size=[25, 50, 100, 200, 400, 600, 800, 1000, 1200, 1400, 1600,],\n",
    "                           nugget=[1e-6, 1e-2],\n",
    "                           theta0=[1e-1, 1, 1e+1],\n",
    "                           use_loo=[True, False],\n",
    "                           noise=[0.0, 1e-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_ = ParameterGrid(dict(dgp=func1d_.values()[:1],\n",
    "                           size=[25, 50, 100, 200, 400, 600, 800],#, 1000, 1200, 1400, 1600,],\n",
    "                           nugget=[1e-6,],\n",
    "                           theta0=[1e+1,],\n",
    "                           use_loo=[False,],\n",
    "                           noise=[0.0,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0x0BADA550)\n",
    "\n",
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "gp = GaussianProcess(beta0=0, normalize=False, corr='squared_exponential')\n",
    "kernel = 'rbf' # 'laplacian'\n",
    "z_a = norm.ppf(1 - .5 * levels)\n",
    "n_jobs, verbose = -1, 0\n",
    "\n",
    "parallel_ = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "c_proc = delayed(RRCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run (maybe paly with bad samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "test_ = np.s_[:X_test.shape[0]]\n",
    "\n",
    "experiment = list()\n",
    "for i_, par_ in enumerate(grid_):\n",
    "    print par_\n",
    "    n_replications, replications = 20, list()\n",
    "\n",
    "    dgp_, size_, noise_ = par_['dgp'], par_['size'], par_['noise']\n",
    "    nugget_, theta0_, use_loo_ =  par_['nugget'], par_['theta0'], par_['use_loo']\n",
    "    tick_ = time.time()\n",
    "    while n_replications > 0:\n",
    "    ## START: one replication\n",
    "    ## Draw random train sample\n",
    "        X_train = random_state.uniform(size=(size_, 1))\n",
    "\n",
    "    ## Draw f(x)\n",
    "        XX = np.concatenate([X_test, X_train], axis=0)\n",
    "        yy = dgp_(XX)\n",
    "        if yy.ndim == 1:\n",
    "            yy = yy.reshape((-1, 1))\n",
    "        if noise_ > 0:\n",
    "            yy += random_state.normal(size=yy.shape)\n",
    "\n",
    "    ## Split the pooled sample\n",
    "        y_train, y_test = np.delete(yy, test_, axis=0), yy[test_]\n",
    "\n",
    "    ## Standardize the sample\n",
    "        Xscl_, yscl_ = clone(scaler).fit(X_train), clone(scaler).fit(y_train)\n",
    "        X_train_, X_test_ = Xscl_.transform(X_train), Xscl_.transform(X_test)\n",
    "        y_train_, y_test_ = yscl_.transform(y_train), yscl_.transform(y_test)\n",
    "\n",
    "    ## Fit a GPR\n",
    "        gp_ = clone(gp)\n",
    "        gp_.theta0, gp_.nugget = theta0_, nugget_\n",
    "        gp_.fit(X_train_, y_train_)\n",
    "\n",
    "    ## Compute the A, B matrices\n",
    "        A, B, y_hat_, MM, loo_ = KRR_AB(X_train_, y_train_, X_test_, loo=use_loo_,\n",
    "                                        forecast=True, nugget=gp_.nugget,\n",
    "                                        metric=kernel, gamma=gp_.theta_[0])\n",
    "        del loo_\n",
    "    ## Inflate by the estimated magnitude\n",
    "        MM *= gp_.sigma2\n",
    "\n",
    "    ## Construct the Bayesian interval\n",
    "        half_width_ = np.sqrt(MM) * z_a[np.newaxis]\n",
    "        b_bounds_ = yscl_.inverse_transform(\n",
    "            np.stack([y_hat_ - half_width_, y_hat_ + half_width_], axis=-1))\n",
    "        b_width_ = b_bounds_[..., 1] - b_bounds_[..., 0]\n",
    "        b_hits_ = ((b_bounds_[..., 0] <= y_test) & (y_test <= b_bounds_[..., 1])).astype(float)\n",
    "\n",
    "    ## Construct the CKRR confidence interval\n",
    "        regions = parallel_(c_proc(A[0, k], B[k], levels=levels)\n",
    "                            for k in xrange(y_test.shape[0]))\n",
    "    ## See if the transformed test target valeus are with the conformal region\n",
    "        c_hits_ = np.asarray(\n",
    "            [[np.any(((int_[:, 0] <= y) & (y <= int_[:, 1]))).astype(float)\n",
    "              for int_ in region]\n",
    "             for y, region in zip(y_test_, regions)])\n",
    "\n",
    "        c_width_ = np.asarray(\n",
    "            [[np.sum(int_[:, 1] - int_[:, 0]) for int_ in region] for region in regions])\n",
    "        if yscl_.scale_ is not None:\n",
    "            c_width_ *= yscl_.scale_\n",
    "\n",
    "    ## END: one replication\n",
    "        n_replications -= 1\n",
    "    \n",
    "        # y_test_hat_ = yscl_.inverse_transform(y_hat_)\n",
    "        # replications.append((y_test, y_test_hat_, b_width_, c_width_,\n",
    "        #                      b_hits_.mean(axis=0, keepdims=True),\n",
    "        #                      c_hits_.mean(axis=0, keepdims=True)))\n",
    "        replications.append((b_hits_.mean(axis=0, keepdims=True),\n",
    "                             c_hits_.mean(axis=0, keepdims=True)))\n",
    "    tock_ = time.time()\n",
    "## Consolidate the simultions\n",
    "    b_coverage_ = np.concatenate([rep_[0] for rep_ in replications], axis=0)\n",
    "    c_coverage_ = np.concatenate([rep_[1] for rep_ in replications], axis=0)\n",
    "\n",
    "    key_ = dgp_.__name__, noise_, use_loo_, theta0_, nugget_, size_\n",
    "    experiment.append((key_, b_coverage_, c_coverage_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ = _load('./exp1/exp1 -20160511_221424.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[(key_, np.median(b_, axis=0), np.median(c_, axis=0)) for key_, b_, c_ in experiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import _save, _load\n",
    "basename_ = os.path.join(OUTPUT_PATH, \"..\", \"partial2 10.0 0.0 1e-06 noloo\")\n",
    "_save(experiment, \"%s-%04d \"%(basename_, i_), gz=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment = _load('./new-20160511_194105/partial 10.0 0.0 1e-06 noloo-0032 -20160511_202641.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_coverage_ = np.concatenate([np.stack([replication_[4]\n",
    "                                  for replication_ in replications_], axis=-1)\n",
    "                        for par_, replications_ in experiment], axis=0)\n",
    "c_coverage_ = np.concatenate([np.stack([replication_[5]\n",
    "                                  for replication_ in replications_], axis=-1)\n",
    "                        for par_, replications_ in experiment], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_cov_mean_ = np.mean(b_coverage_ , axis=-1).reshape((3, 11, 4))\n",
    "b_cov_median_ = np.median(b_coverage_ , axis=-1).reshape((3, 11, 4))\n",
    "b_cov_std_ = np.std(b_coverage_, axis=-1).reshape((3, 11, 4))\n",
    "\n",
    "c_cov_mean_ = np.mean(c_coverage_ , axis=-1).reshape((3, 11, 4))\n",
    "c_cov_median_ = np.median(c_coverage_ , axis=-1).reshape((3, 11, 4))\n",
    "c_cov_std_ = c_coverage_.std(axis=-1).reshape((3, 11, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(grid_.param_grid[0][\"size\"], c_dyn_[0]+c_cov_std_[0])\n",
    "plt.plot(grid_.param_grid[0][\"size\"], c_cov_mean_[0])\n",
    "plt.plot(grid_.param_grid[0][\"size\"], c_cov_median_[0])\n",
    "# plt.plot(grid_.param_grid[0][\"size\"], c_dyn_[0]-c_cov_std_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(grid_.param_grid[0][\"size\"], b_cov_mean_[0])\n",
    "plt.plot(grid_.param_grid[0][\"size\"], b_cov_median_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(b_coverage_.std(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_coverage_, c_coverage_ = \\\n",
    "                    [np.stack([rep_[j] for rep_ in replications], axis=-1) for j in [4, 5]]\n",
    "b_perf_ = b_coverage_.mean(axis=-1), b_coverage_.std(axis=-1)\n",
    "c_perf_ = c_coverage_.mean(axis=-1), c_coverage_.std(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_perf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_perf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y_test)\n",
    "plt.plot(y_test_hat_)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(b_width_)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(c_width_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random_state = np.random.RandomState(0xC01DF00D)\n",
    "# random_state = np.random.RandomState(0xA1157AFF)\n",
    "# random_state = np.random.RandomState(0x0BADA550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_hits_.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_hits_.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random_state = np.random.RandomState(0x0ABACABA)\n",
    "# random_state = np.random.RandomState(0x0DABACAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basename_ = os.path.join(OUTPUT_PATH, \"func_1d\")\n",
    "for i_, par_ in enumerate(grid_):\n",
    "    head_ = _unpack(**par_)\n",
    "    tick_ = time.time()\n",
    "    result_ = run_ckrr_mc_experiment(random_state=random_state, n_jobs=-1, verbose=0,\n",
    "                                     levels=levels, nd=1, ng=1001,\n",
    "                                     n_replications=20, **par_)\n",
    "    _save((head_, result_), \"%s-%04d \"%(basename_, i_), gz=9)\n",
    "    tock_ = time.time()\n",
    "    print head_, \"%0.3fsec.\"%(tock_ - tick_,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependence on the sample size: 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_ = list()\n",
    "n_replications = 20\n",
    "use_loo = False\n",
    "\n",
    "funcs_ = [(\"f1\", func1d_[\"f1\"]),\n",
    "          (\"pressure2\", func1d_[\"pressure2\"])]\n",
    "\n",
    "for fname_, fun_ in [(\"f1\", func1d_[\"f1\"])]: #func1d_.iteritems():\n",
    "    # Domain dependent rbf precision\n",
    "    for theta0_ in theta0_list:\n",
    "        for nugget_ in nugget_list:\n",
    "            for size_ in size_list:\n",
    "                print fname_, nugget_, size_\n",
    "                tick_ = time.time()\n",
    "                X_test_, reps_ = run_ckrr_mc_experiment(fun_, levels, ccr_proc=CCR, nd=1, ng=1001, theta0=theta0_,\n",
    "                                                        n_replications=n_replications, size=size_, nugget=nugget_,\n",
    "                                                        use_loo=use_loo, random_state=random_state)\n",
    "                tock_ = time.time()\n",
    "                b_coverage_, c_coverage_ = \\\n",
    "                    [np.stack([rep_[j] for rep_ in reps_], axis=-1) for j in [4, 5]]\n",
    "                b_perf_ = b_coverage_.mean(axis=-1), b_coverage_.std(axis=-1)\n",
    "                c_perf_ = c_coverage_.mean(axis=-1), c_coverage_.std(axis=-1)\n",
    "                results_.append((fname_, theta0_, nugget_, size_, c_perf_, b_perf_))\n",
    "                print \"%0.3fsec.\"%(tock_ - tick_,)\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ = run_ckrr_mc_experiment(fun, levels, ccr_proc=RRCM, nd=1, ng=1001,\n",
    "                              n_replications=20, size=200, nugget=1e-6,\n",
    "                              use_loo=False, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_, reps_ = res_\n",
    "y_test_, y_hat_, b_width_, c_width_, b_coverage_, c_coverage_ = \\\n",
    "    [np.stack([rep_[j] for rep_ in reps_], axis=-1) for j in xrange(6)]\n",
    "abs_err_ = np.abs(y_test_ - y_hat_)\n",
    "\n",
    "b_perf_ = b_coverage_.mean(axis=-1), b_coverage_.std(axis=-1)\n",
    "c_perf_ = c_coverage_.mean(axis=-1), c_coverage_.std(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b_coverage_.std(axis=-1), b_coverage_.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_coverage_.std(axis=-1), c_coverage_.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typcal plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "order_ = [1, 4, 2, 5, 3, 6]\n",
    "\n",
    "ax = fig.add_subplot(2, 3, order_[0])\n",
    "ax.plot(X_test_, np.mean(y_test_[:, 0], axis=-1), color=\"blue\")\n",
    "ax.plot(X_test_, np.mean(y_hat_[:, 0], axis=-1), color=\"red\")\n",
    "ax.set_title(\"Actual/Prediction: %s\"%(func_,))\n",
    "\n",
    "ax = fig.add_subplot(2, 3, order_[1])\n",
    "ae_rmse_ = np.sqrt(np.mean(abs_err_[:, 0] ** 2, axis=-1))\n",
    "\n",
    "ax.plot(X_test_, ae_rmse_)\n",
    "ax.set_title(\"Root mean squared error\")\n",
    "\n",
    "for i in xrange(4):\n",
    "    ax = fig.add_subplot(2, 3, order_[i + 2])\n",
    "\n",
    "    ax.plot(X_test_, np.median(abs_err_[:, 0], axis=-1), alpha=0.25, label=\"$|y-\\\\hat{y}|$\")\n",
    "    ax.plot(X_test_, np.median(b_width_[:, i], axis=-1) / 2,\n",
    "            label=\"bayes ($%0.1f\\\\pm%0.1f$)\"%(100*b_perf_[0][0, i], 100*b_perf_[1][0, i]))\n",
    "    ax.plot(X_test_, np.median(c_width_[:, i], axis=-1) / 2,\n",
    "            label=\"%s ($%.1f\\\\pm%.1f$)\"%(name_, 100*c_perf_[0][0, i], 100*c_perf_[1][0, i]))\n",
    "    ax.set_title(\"Accuracy %s %s-CI\"%(name_, lvl_cols_[i],))\n",
    "    ax.legend(loc=\"best\", ncol=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig_name_ = os.path.join(PLOT_PATH, \"%s 1k-%d %.1e %.1e %s%s.png\"\n",
    "                         %(func_, X_train.shape[0], nugget, noise_, name_,\n",
    "                           \" loo\" if use_loo else \"\"))\n",
    "print fig_name_\n",
    "\n",
    "# fig.savefig(fig_name_)\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X_test_, np.median(y_test_[:, 0], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean absolute square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae_ = abs_err_[:, 0].copy()\n",
    "ae_rmse_ = np.sqrt(np.mean(ae_ ** 2, axis=-1))\n",
    "plt.plot(X_test_, ae_rmse_, \"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the minimum and maximum of all of the data[1] (as in figure 2)\n",
    "* the lowest datum still within 1.5 IQR of the lower quartile, and the highest datum still within 1.5 IQR of the upper quartile (often called the Tukey boxplot)[2][3] (as in figure 3)\n",
    "* one standard deviation above and below the mean of the data\n",
    "* the 9th percentile and the 91st percentile\n",
    "* the 2nd percentile and the 98th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae_ = abs_err_[:, 0].copy()\n",
    "ae_max = np.max(ae_, axis=-1)\n",
    "ae_qnt = np.percentile(ae_, [25, 75], axis=-1)\n",
    "ae_iqr = np.diff(ae_qnt, axis=0)\n",
    "ae_mean = np.sqrt(np.mean(ae_**2, axis=-1))\n",
    "ae_median = np.median(ae_, axis=-1)\n",
    "ae_std = np.std(ae_, axis=-1)\n",
    "ae_[(ae_ > (ae_qnt[1] + ae_iqr * 1.5).T)] = -np.inf\n",
    "ae_hiqr = ae_.max(axis=-1)\n",
    "\n",
    "# plt.plot(X_test_, ae_max, \"-\")\n",
    "# plt.plot(X_test_, ae_hiqr, \"-\")\n",
    "# plt.plot(X_test_, ae_median, \"-\")\n",
    "plt.plot(X_test_, ae_mean, \"-\")\n",
    "# plt.plot(X_test_, ae_hiqr - ae_mean, \"-\")\n",
    "# plt.plot(X_test_, ae_mean + ae_std - ae_mean, \"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X_test_, (np.median(c_width_, axis=-1) / 2))\n",
    "plt.plot(X_test_, ae_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X_test_, (np.median(b_width_, axis=-1) / 2))\n",
    "plt.plot(X_test_, ae_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(X_test_, b_width_[..., 0, 0], \"r\")\n",
    "# plt.plot(X_test_, c_width_[..., 0, 0], \"b\")\n",
    "plt.plot(X_test_, np.median(c_width_, axis=-1) / np.median(b_width_, axis=-1) - 1 )\n",
    "# plt.plot(abs_err_[..., 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.functions_1d import get_functions\n",
    "func1d_ = get_functions()\n",
    "\n",
    "from scipy.stats import norm\n",
    "from itertools import chain\n",
    "from joblib import Parallel, delayed\n",
    "parallel_ = Parallel(n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# random_state = np.random.RandomState(0x0ABACABA)\n",
    "# random_state = np.random.RandomState(0x0DABACAB)\n",
    "random_state = np.random.RandomState(0x0EABACAB)\n",
    "use_loo = True\n",
    "\n",
    "noise_ = 1e-6\n",
    "z_a = norm.ppf(1 - .5 * levels)\n",
    "for size_ in [400,]:\n",
    "## train\n",
    "    X_train = random_state.uniform(size=(size_, 1))\n",
    "## test\n",
    "    X_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "    X = np.concatenate([X_train, X_test], axis=0)\n",
    "    train_ = np.s_[:X_train.shape[0]]\n",
    "    for nugget in np.logspace(-4, 0, num=3):\n",
    "        for func_ in func1d_.iterkeys():\n",
    "            print size_, nugget, func_,\n",
    "            y = func1d_[func_](X)\n",
    "            y += random_state.normal(size=y.shape) * noise_\n",
    "\n",
    "            y_train = y[train_]\n",
    "            y_test = np.delete(y, train_, axis=0)\n",
    "\n",
    "            gp = GaussianProcess(thetaL=1e-4, thetaU=1e4, beta0=0,\n",
    "                                 normalize=False, nugget=nugget).fit(X_train, y_train)\n",
    "\n",
    "            A, B, y_hat_, MM, loo_ = KRR_AB(X_train, y_train, X_test, forecast=True, loo=use_loo,\n",
    "                                            nugget=gp.nugget, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "            MM *= gp.sigma2\n",
    "\n",
    "            jobs_ = (delayed(_pccia)(k, levels, y_test[k], y_hat_[k], MM[k], A[0, k], B[k])\n",
    "                     for k in xrange(y_test.shape[0]))\n",
    "            results_ = parallel_(jobs_)\n",
    "\n",
    "            width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                               for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                              for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                                for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            hit_prob_ = hits_.mean(axis=0)\n",
    "            hit_prob_std_ = hits_.std(axis=0)\n",
    "\n",
    "            for j, name_ in enumerate([\"rrcm\", \"crr\"]):\n",
    "                fig = plt.figure(figsize=(12, 6))\n",
    "                order_ = [1, 4, 2, 5, 3, 6]\n",
    "\n",
    "                ax = fig.add_subplot(2, 3, order_[0])\n",
    "                ax.plot(X_test, y_test, color=\"blue\")\n",
    "                ax.plot(X_test, y_hat_, color=\"red\")\n",
    "                ax.set_title(\"Actual/Prediction: %s\"%(func_,))\n",
    "\n",
    "                ax = fig.add_subplot(2, 3, order_[1])\n",
    "                ax.plot(X_test, np.abs(y_hat_ - y_test))\n",
    "                ax.set_title(\"Absolute error\")\n",
    "\n",
    "                for i in xrange(4):\n",
    "                    ax = fig.add_subplot(2, 3, order_[i + 2])\n",
    "\n",
    "                    ax.plot(X_test, np.abs(y_hat_ - y_test), alpha=0.25, label=\"$|y-\\\\hat{y}|$\")\n",
    "                    ax.plot(X_test, np.sqrt(MM), label=\"bayes\")\n",
    "            #         ax.plot(X_test, (bounds_[:, i, 1, 2] - bounds_[:, i, 0, 2]) / (2 * z_a[i]), label=\"bayes\")\n",
    "                    ax.plot(X_test, (bounds_[:, i, 1, j] - bounds_[:, i, 0, j]) / (2 * z_a[i]), label=name_)\n",
    "                    ax.set_title(\"Absolute error/accuracy %s %s-CI\"%(name_, lvl_cols_[i],))\n",
    "                    ax.legend(loc=\"best\")\n",
    "\n",
    "                fig.tight_layout()\n",
    "                fig_name_ = os.path.join(PLOT_PATH, \"%s 1k-%d %.1e %.1e %s%s.png\"\n",
    "                                         %(func_, X_train.shape[0], nugget, noise_, name_,\n",
    "                                           \" loo\" if use_loo else \"\"))\n",
    "                print fig_name_\n",
    "\n",
    "                fig.savefig(fig_name_)\n",
    "                plt.close()\n",
    "#                 plt.show()\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce the 1D test plots for a $10k$ grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0x0BADC0DE)\n",
    "\n",
    "z_a = norm.ppf(1 - .5 * levels)\n",
    "for size_ in [10, 20,]:\n",
    "## train\n",
    "    X_train = random_state.uniform(size=(size_, 1))\n",
    "## test\n",
    "    X_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "    X = np.concatenate([X_train, X_test], axis=0)\n",
    "    train_ = np.s_[:X_train.shape[0]]\n",
    "    for nugget in np.logspace(-4, 0, num=3):\n",
    "        for func_ in func1d_.iterkeys():\n",
    "            print size_, nugget, func_,\n",
    "            y = func1d_[func_](X)\n",
    "\n",
    "            y_train = y[train_]\n",
    "            y_test = np.delete(y, train_, axis=0)\n",
    "\n",
    "            gp = GaussianProcess(thetaL=1e-4, thetaU=1e4, beta0=0,\n",
    "                                 normalize=False, nugget=nugget).fit(X_train, y_train)\n",
    "\n",
    "            A, B, y_hat_, MM, loo_ = KRR_AB(X_train, y_train, X_test, forecast=True,\n",
    "                                            nugget=gp.nugget, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "            MM *= gp.sigma2\n",
    "\n",
    "            jobs_ = (delayed(_pccia)(k, levels, y_test[k], y_hat_[k], MM[k], A[0, k], B[k])\n",
    "                     for k in xrange(y_test.shape[0]))\n",
    "            results_ = parallel_(jobs_)\n",
    "\n",
    "            width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                               for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                              for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                                for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            hit_prob_ = hits_.mean(axis=0)\n",
    "            hit_prob_std_ = hits_.std(axis=0)\n",
    "\n",
    "            for j, name_ in enumerate([\"rrcm\", \"crr\"]):\n",
    "                fig = plt.figure(figsize=(12, 6))\n",
    "                order_ = [1, 4, 2, 5, 3, 6]\n",
    "\n",
    "                ax = fig.add_subplot(2, 3, order_[0])\n",
    "                ax.plot(X_test, y_test, color=\"blue\")\n",
    "                ax.plot(X_test, y_hat_, color=\"red\")\n",
    "                ax.set_title(\"Actual/Prediction: %s\"%(func_,))\n",
    "\n",
    "                ax = fig.add_subplot(2, 3, order_[1])\n",
    "                ax.plot(X_test, np.abs(y_hat_ - y_test))\n",
    "                ax.set_title(\"Absolute error\")\n",
    "\n",
    "                for i in xrange(4):\n",
    "                    ax = fig.add_subplot(2, 3, order_[i + 2])\n",
    "\n",
    "                    ax.plot(X_test, np.abs(y_hat_ - y_test), alpha=0.25, label=\"$|y-\\\\hat{y}|$\")\n",
    "                    ax.plot(X_test, np.sqrt(MM), label=\"bayes\")\n",
    "            #         ax.plot(X_test, (bounds_[:, i, 1, 2] - bounds_[:, i, 0, 2]) / (2 * z_a[i]), label=\"bayes\")\n",
    "                    ax.plot(X_test, (bounds_[:, i, 1, j] - bounds_[:, i, 0, j]) / (2 * z_a[i]), label=name_)\n",
    "                    ax.set_title(\"Absolute error/accuracy %s %s-CI\"%(name_, lvl_cols_[i],))\n",
    "                    ax.legend(loc=\"best\")\n",
    "\n",
    "                fig.tight_layout()\n",
    "                fig_name_ = os.path.join(PLOT_PATH, \"%s 1k-%d %.1e %s.png\"%(func_, X_train.shape[0],\n",
    "                                                                            nugget, name_,))\n",
    "                print fig_name_\n",
    "\n",
    "                fig.savefig(fig_name_)\n",
    "                plt.close()\n",
    "            #     plt.show()\n",
    "            #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from itertools import chain\n",
    "from joblib import Parallel, delayed\n",
    "parallel_ = Parallel(n_jobs=-1, verbose=1)\n",
    "\n",
    "step_ = 7\n",
    "for func_ in [\"heaviside\",]:#func1d_.iterkeys():\n",
    "    print func_,\n",
    "    X = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "    y = func1d_[func_](X)\n",
    "\n",
    "    train_ = np.s_[::5]\n",
    "    X_train, y_train = X[train_], y[train_]\n",
    "    X_test, y_test = X, y# np.delete(X, train_, axis=0), np.delete(y, train_, axis=0)\n",
    "    \n",
    "    gp = GaussianProcess(thetaL=1e-4, thetaU=1e4, beta0=0,\n",
    "                         normalize=False, nugget=1e-6).fit(X_train, y_train)\n",
    "    \n",
    "    A, B, y_hat_, MM, loo_ = KRR_AB(X_train, y_train, X_test, forecast=True,\n",
    "                                    nugget=gp.nugget, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "    MM *= gp.sigma2\n",
    "\n",
    "    jobs_ = (delayed(_pccia)(k, levels, y_test[k], y_hat_[k], MM[k], A[0, k], B[k])\n",
    "             for k in xrange(y_test.shape[0]))\n",
    "    results_ = parallel_(jobs_)\n",
    "\n",
    "    width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                       for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                      for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                        for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    hit_prob_ = hits_.mean(axis=0)\n",
    "    hit_prob_std_ = hits_.std(axis=0)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    order_ = [1, 4, 2, 5, 3, 6]\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, order_[0])\n",
    "    ax.plot(X_test, y_test, color=\"blue\")\n",
    "    ax.plot(X_test, y_hat_, color=\"red\")\n",
    "    ax.set_title(\"Actual/Prediction: %s\"%(func_,))\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, order_[1])\n",
    "    ax.plot(X_test, np.abs(y_hat_ - y_test))\n",
    "    ax.set_title(\"Absolute error\")\n",
    "\n",
    "    for j, name_ in enumerate([\"rrcm\", \"bayes\"]):\n",
    "        for i, i_ in enumerate([2, 3]):\n",
    "            ax = fig.add_subplot(2, 3, order_[i + 3 + j*2 - 1])\n",
    "            ax.plot(X_test, bounds_[:, i_, 1, j] - bounds_[:, i_, 0, j], color=\"red\")\n",
    "            ax.plot(X_test, y_test[:, 0] - bounds_[:, i_, 0, j], color=\"blue\")\n",
    "            ax.axhline(y=0, color=\"red\")\n",
    "            ax.set_title(\"the %s-CI(%0.1f%%$\\pm$%0.1f%%)\\n of %s\"\n",
    "                         %(lvl_cols_[i_], 100*hit_prob_[i_, j], 100*hit_prob_std_[i_,j], name_.upper(),))\n",
    "    fig.tight_layout()\n",
    "#     fig.savefig(os.path.join(PLOT_PATH, \"1k-%d %s.png\"%(step_, func_,)))\n",
    "#     plt.close()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.functions_2d import func2D\n",
    "DGP_ = func2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0xDEADC0DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "parallel_ = Parallel(n_jobs=-1, verbose=1)\n",
    "\n",
    "# X_train = random_state.uniform(size=(100, 2)) * 2 - 1\n",
    "X_train = random_state.uniform(size=(1500, 2)) * 2 - 1\n",
    "\n",
    "mesh_ = np.meshgrid(*2*[np.linspace(-1, 1, num=51)])\n",
    "X_test = np.concatenate([ax_.reshape((-1, 1)) for ax_ in mesh_], axis=1)\n",
    "\n",
    "X = np.concatenate([X_train, X_test], axis=0)\n",
    "train_ = np.s_[:X_train.shape[0]]\n",
    "\n",
    "z_a = norm.ppf(1 - .5 * levels)\n",
    "\n",
    "levels_ = np.linspace(-.75, .75, num=16) * 100\n",
    "\n",
    "i, int_name_ = [(0, \"rrcm\"), (1, \"crr\"), (2, \"bayes\")][0]\n",
    "\n",
    "# nugget = 1e-2 ## 20160504\n",
    "nugget = 1e-6\n",
    "\n",
    "use_loo = True\n",
    "\n",
    "for theta0_ in np.logspace(-2, 2, num=5):\n",
    "    for name_ in [\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"][-1:]:\n",
    "        y = DGP_[name_](X)\n",
    "\n",
    "        y_train = y[train_]\n",
    "        y_test = np.delete(y, train_, axis=0)\n",
    "\n",
    "    #     gp = GaussianProcess(thetaL=1e-4, thetaU=1e4, beta0=0, theta0=0.1,\n",
    "        gp = GaussianProcess(beta0=0, theta0=theta0_, normalize=False,\n",
    "                             nugget=nugget).fit(X_train, y_train)\n",
    "\n",
    "        A, B, y_hat_, MM, loo_ = KRR_AB(X_train, y_train, X_test, forecast=True, loo=use_loo,\n",
    "                                        nugget=gp.nugget, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "        MM *= gp.sigma2\n",
    "\n",
    "        jobs_ = (delayed(_pccia)(k, levels, y_test[k], y_hat_[k], MM[k], A[0, k], B[k])\n",
    "                 for k in xrange(y_test.shape[0]))\n",
    "        results_ = parallel_(jobs_)\n",
    "\n",
    "        width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                           for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "        hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                          for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "        bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                            for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "        hit_prob_ = hits_.mean(axis=0)\n",
    "        hit_prob_std_ = hits_.std(axis=0)\n",
    "\n",
    "        delta_ = (bounds_[:, :, 1] - bounds_[:, :, 0]) / (2 * z_a[np.newaxis, :, np.newaxis])\n",
    "        rel_ = (delta_[..., i] / delta_[..., 2] - 1) * 100\n",
    "        ae_ = np.abs(y_test - y_hat_[:, 0])\n",
    "\n",
    "    ## Actual surface: 3D\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], y_test.reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.75)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"Actual\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s (tht %.1e).png\"\n",
    "                                 %(name_, theta0_,))\n",
    "        print fig_name_\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## Absolute prediction error: 3D\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], ae_.reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.9)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"Absolute error\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s abs_error (tht %.1e).png\"\n",
    "                                 %(name_, theta0_,))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## \\hat{y}: 3D\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], y_hat_.reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.9)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"Predicted\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s predicted (tht %.1e).png\"\n",
    "                                 %(name_, theta0_,))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## \\hat{\\sigma}: 3D\n",
    "        sigma_hat_ = np.sqrt(MM[:, 0] - gp.sigma2 * gp.nugget)\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], sigma_hat_.reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.9)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"$\\\\hat{\\\\sigma}$\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s sigma (tht %.1e).png\"\n",
    "                                 %(name_, theta0_,))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## \\delta\n",
    "        sigma_hat_ = np.sqrt(MM[:, 0] - gp.sigma2 * gp.nugget)\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], delta_[:, -1, 0].reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.9)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"RRCM 5%-CI scaled half-width\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s rrcm25-shw (tht %.1e%s).png\"\n",
    "                                 %(name_, theta0_, \", loo\" if use_loo else \"\",))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## Actual values: top-down\n",
    "        fig = plt.figure(figsize=(12, 15))\n",
    "        ax = fig.add_subplot(321)\n",
    "        cont_ = ax.contourf(mesh_[0], mesh_[1],\n",
    "                            y_test.reshape(mesh_[0].shape), 20,\n",
    "                            cmap=plt.cm.coolwarm, lw=0, alpha=0.9)\n",
    "        ax.set_title(\"Actual value %s\"%(name_,))\n",
    "        plt.colorbar(cont_)\n",
    "\n",
    "    ## Absolute arror: top-down\n",
    "        ax = fig.add_subplot(322)\n",
    "        cont_ = ax.contourf(mesh_[0], mesh_[1],\n",
    "                            ae_.reshape(mesh_[0].shape), 20,\n",
    "                            cmap=plt.cm.coolwarm, lw=0, alpha=0.9)\n",
    "        ax.set_title(\"Absolute prediction error\")\n",
    "        plt.colorbar(cont_)\n",
    "\n",
    "        ## CCI relative precision wrt. bayesian CI.\n",
    "        for j, pct_ in enumerate(lvl_cols_):\n",
    "            ax = fig.add_subplot(3, 2, j + 3)\n",
    "\n",
    "            cont_ = ax.contour(mesh_[0], mesh_[1], rel_[:, j].reshape(mesh_[0].shape),\n",
    "                               levels=levels_, colors=\"k\", linestyles=\"solid\", extend=\"both\")\n",
    "            ax.clabel(cont_, inline=1, fontsize=8, fmt='%.0f')\n",
    "\n",
    "            CS3 = ax.contourf(mesh_[0], mesh_[1], rel_[:, j].reshape(mesh_[0].shape),\n",
    "                        cmap=plt.cm.coolwarm, lw=1, levels=levels_,\n",
    "                        antialiased=False, alpha=1.0, extend='both',)\n",
    "            CS3.cmap.set_over('white')\n",
    "\n",
    "            ax.set_title(\"\"\"rel. %s(%.1f%%) / bayes(%.1f%%) %s-CI%s\"\"\"\n",
    "                         %(int_name_, 100-hit_prob_[j, i]*100,\n",
    "                           100-hit_prob_[j, -1]*100, pct_,\n",
    "                           \"(loo)\" if use_loo else \"\",))\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s efficiency (tht %.1e%s).png\"\n",
    "                                 %(name_, theta0_, \", loo\" if use_loo else \"\",))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0x0ABACABA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma = 10.0\n",
    "dim_ = 2\n",
    "resolution=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dgp_opts_ = {name_: dict(scale=1.0) for name_ in DGP}\n",
    "dgp_opts_[\"gaussian\"].update(dict(metric=\"rbf\", gamma=gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def surface(ax, mesh, yy, name, **kwargs):\n",
    "#     ax.plot_surface(mesh[0], mesh[1], yy.reshape(mesh[0].shape),\n",
    "#                     cstride=1, rstride=1, cmap=plt.cm.coolwarm,\n",
    "#                     lw=0, antialiased=False, **kwargs)\n",
    "#     ax.set_title(\"A sample surface $y\\\\sim \\\\mathtt{%s}$\"%(name,))\n",
    "#     ax.set_ylabel(\"y\")\n",
    "#     return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(X, y, X_test, y_test):\n",
    "## Run the GP regression\n",
    "    gp = GaussianProcess(thetaL=1e-4, thetaU=1e2, beta0=0,\n",
    "                         normalize=False, nugget=1e-6,\n",
    "                         storage_mode='light').fit(X, y)\n",
    "## Compute the necessary matrices\n",
    "    A, B, y_hat_, MM, loo_ = KRR_AB(X, y, X_test, nugget=gp.nugget,\n",
    "                                    sigma2=gp.sigma2, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "#     y_hat_gp, mse_gp = gp.predict(X_test, eval_MSE=True)\n",
    "#     assert np.allclose(MM[:, 0], mse_gp + gp.sigma2 * gp.nugget)\n",
    "#     assert np.allclose(y_hat_[:, 0], y_hat_gp, rtol=1e-3)\n",
    "\n",
    "## Run in parallel\n",
    "    parallel_ = Parallel(n_jobs=-1, verbose=1)\n",
    "    jobs_ = (delayed(_pccia)(k, levels, y_test[k],\n",
    "                             y_hat_[k], MM[k], A[0, k], B[k])\n",
    "             for k in xrange(y_test.shape[0]))\n",
    "    results_ = parallel_(jobs_)\n",
    "# ## Combine the results\n",
    "    width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                       for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                      for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                        for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    return width_, hits_, bounds_, y_hat_[:, 0], MM[:, 0], gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_ = dict()\n",
    "for name_, dgp_ in DGP.iteritems():\n",
    "    print \"%s:\"%(name_,),\n",
    "## Create a dediacted validation sample\n",
    "    mesh_ = np.meshgrid(*dim_*[np.linspace(-1, 1, num=resolution)])\n",
    "    XX = np.concatenate([ax_.reshape((-1,1)) for ax_ in mesh_], axis=1)\n",
    "    yy = dgp_(XX, random_state=random_state, **dgp_opts_[name_])\n",
    "# ## A typical realisation\n",
    "#     fig = plt.figure(figsize=(8, 6))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     surface(ax, mesh_, yy, name_).view_init(60, 30)\n",
    "#     fig.savefig(os.path.join(SAMPLE_PLOT_PATH, \"%s.png\"%(name_)), )\n",
    "#     plt.close()\n",
    "## Now do the train/validation split\n",
    "    XX0, X_validate = train_test_split(XX, test_size=0.25, random_state=random_state)\n",
    "    for N in [100, 400, 1600]:\n",
    "        print \"N = %d,\"%(N,),\n",
    "        X_train = resample(XX0, replace=False, n_samples=N, random_state=random_state)\n",
    "        X_full = np.concatenate([X_train, X_validate], axis=0)\n",
    "## the dgp: add some independent gaussian noise.\n",
    "        for noise_level_ in [1e-6, 1e-1]:\n",
    "            print \"noise = %2.2e\"%(noise_level_)\n",
    "            y_full = dgp_(X_full, random_state=random_state,\n",
    "                          nugget=noise_level_, **dgp_opts_[name_])\n",
    "            if name_ != \"gaussian\":\n",
    "                y_full += random_state.normal(size=y_full.shape) * sqrt(noise_level_)\n",
    "            y_train, y_validate = y_full[:N], y_full[N:]\n",
    "## The experiment\n",
    "            result_ = run_experiment(X_train, y_train, X_validate, y_validate)\n",
    "# ## Save\n",
    "            experiment_[name_, N, noise_level_] = (result_, X_full, y_full, N)\n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_save(experiment_, os.path.join(OUTPUT_PATH, \"experiment_02_\"), gz=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tuple_, result_ in experiment_.iteritems():\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result_\n",
    "    name_, size_, noise_ = tuple_\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "\n",
    "    fig, ax_ = plt.subplots(nrows=1, ncols=3, sharex=True,\n",
    "                            sharey=True, figsize=(16, 9))\n",
    "    for i, type_ in enumerate([\"rrcm\", \"crr\", \"bayes\"]):\n",
    "        ax_[i].boxplot(width_[..., i])\n",
    "        ax_[i].set_title(\"\"\"`%s` `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                         %(type_, name_, size_, noise_,))\n",
    "        ax_[i].set_ylabel(\"width\")\n",
    "        ax_[i].set_xticklabels(lvl_cols_)\n",
    "        ax_[i].grid()\n",
    "    fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"width_box - %s %.1E %d.png\"\n",
    "                             %(name_, noise_, size_, )), )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(result):\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "    ratio_ = np.abs(y_test-y_hat_).reshape((-1,1,1)) / (bounds_[:, :, 1] - bounds_[:, :, 0])\n",
    "    lvl_cols_ = [\"%4.1f%%\"%(100*lv_,) for lv_ in levels]\n",
    "    return pd.concat({\n",
    "        \"median width\": pd.DataFrame(np.median(width_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"mean width\": pd.DataFrame(np.mean(width_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"95% width\": pd.DataFrame(np.percentile(width_, 95, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"max width\": pd.DataFrame(np.max(width_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"coverage\": pd.DataFrame(np.mean(hits_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"avg. abs-width ratio\": pd.DataFrame(np.median(ratio_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"mse/var\": pd.DataFrame(np.full((4, 3), (y_test - y_hat_).var() / y_test.var()), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "    }, axis=0, names=[\"measure\"]).unstack().stack(level=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ = pd.concat({tuple_: process(result_) for tuple_, result_ in experiment_.iteritems()},\n",
    "            axis=0, names = [\"fun\", \"N\", \"noise\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coverage table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_.xs(\"coverage\", level=-2, axis=0).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max width table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_.xs(\"max width\", level=-2, axis=0).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual, predicted and abs-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tuple_, result_ in experiment_.iteritems():\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result_\n",
    "    name_, size_, noise_ = tuple_\n",
    "## Plot the error bars\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_trisurf(X_test[:, 0], X_test[:, 1], np.abs(y_test-y_hat_) / y_test.std(),\n",
    "                    cmap=plt.cm.coolwarm, lw=0) #, norm=MidPointNorm())\n",
    "    ax.set_title(\"\"\"abs/std ratio of `y` for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                 %(name_, size_, noise_,))\n",
    "    ax.view_init(60, 60)\n",
    "    fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"abs_std_ratio - %s %.1E %d.png\"\n",
    "                             %(name_, noise_, size_, )), )\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_trisurf(X_test[:, 0], X_test[:, 1], y_test,\n",
    "                    cmap=plt.cm.coolwarm, lw=0) #, norm=MidPointNorm())\n",
    "    ax.set_title(\"\"\"Actual value of `y` for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                 %(name_, size_, noise_,))\n",
    "    ax.view_init(60, 60)\n",
    "    fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"actual - %s %.1E %d.png\"\n",
    "                             %(name_, noise_, size_,)), )\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_trisurf(X_test[:, 0], X_test[:, 1], y_hat_,\n",
    "                    cmap=plt.cm.coolwarm, lw=0) #, norm=MidPointNorm())\n",
    "    ax.set_title(\"\"\"Predicted value of `y` for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                 %(name_, size_, noise_,))\n",
    "    ax.view_init(60, 60)\n",
    "    fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"predicted - %s %.1E %d.png\"\n",
    "                             %(name_, noise_, size_,)), )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abs-width ratio for the intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tuple_, result_ in experiment_.iteritems():\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result_\n",
    "    name_, size_, noise_ = tuple_\n",
    "## Plot the error bars\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "\n",
    "    for i, type_ in enumerate([\"rrcm\", \"crr\", \"bayes\"]):\n",
    "        for j, sign_ in enumerate(lvl_cols_):\n",
    "            fig = plt.figure(figsize=(16, 9))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            ax.plot_trisurf(X_test[:, 0], X_test[:, 1], np.abs(y_test-y_hat_) / width_[:, j, i],\n",
    "                            cmap=plt.cm.coolwarm, lw=0) #, norm=MidPointNorm())\n",
    "            ax.set_title(\"\"\"abs/width ratio for `%s`-type %s-interval for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                         %(type_, sign_, name_, size_, noise_,))\n",
    "            ax.view_init(60, 60)\n",
    "            fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"abs_width_ratio - %s %.1E %d %s %s.png\"\n",
    "                                     %(name_, noise_, size_, type_, sign_, )), )\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excess plot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tuple_, result_ in experiment_.iteritems():\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result_\n",
    "    name_, size_, noise_ = tuple_\n",
    "## Plot the error bars\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "    for i, type_ in enumerate([\"rrcm\", \"crr\", \"bayes\"]):\n",
    "        for j, sign_ in enumerate(lvl_cols_):\n",
    "            excess_u_ = y_test - bounds_[:, j, 1, i]\n",
    "            excess_d_ = bounds_[:, j, 0, i] - y_test\n",
    "            excess_u_[excess_u_ < 0] = 0\n",
    "            excess_d_[excess_d_ < 0] = 0\n",
    "            excess_ = 2 * (excess_u_ - excess_d_) / width_[:, j, i]\n",
    "\n",
    "            fig = plt.figure(figsize=(16, 9))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            ax.set_title(\"\"\"Excess of `%s`-type %s-interval for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                         %(type_, sign_, name_, size_, noise_,))\n",
    "            ax.plot_trisurf(X_test[:, 0], X_test[:, 1], excess_, cmap=plt.cm.coolwarm,\n",
    "                            lw=0, alpha=.95, norm=MidPointNorm())\n",
    "            ax.view_init(60, 60)\n",
    "\n",
    "            fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"excess - %s %.1E %d %s %s.png\"\n",
    "                                     %(name_, noise_, size_, type_, sign_, )), )\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
