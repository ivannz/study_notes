{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKRR -- plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from utils.mpl_mid_point_norm import MidPointNorm\n",
    "\n",
    "from utils.state import _load\n",
    "from scipy.stats import binom_test\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdirifnot(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \".\"\n",
    "DATA_PATH = os.path.join(BASE_PATH, \"..\", \"thesis_exp\")\n",
    "OUTPUT_PATH = mkdirifnot(os.path.join(BASE_PATH, \"output_pdf-3\"))\n",
    "\n",
    "PROFILE_PATH = mkdirifnot(os.path.join(OUTPUT_PATH, \"profile\"))\n",
    "EXP1D_PATH = mkdirifnot(os.path.join(OUTPUT_PATH, \"exp_1d\"))\n",
    "EXP2D_PATH = mkdirifnot(os.path.join(OUTPUT_PATH, \"exp_2d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dumps(path, n_jobs=-1, verbose=1, include_target=False):\n",
    "    parallel_ = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "    jobs_ = (delayed(_load)(os.path.join(path, fname_))\n",
    "             for fname_ in os.listdir(path)\n",
    "             if fname_.endswith(\".gz\"))\n",
    "    dumps_ = parallel_(jobs_)\n",
    "    experiment = [exp_ for dump_ in dumps_ for exp_ in dump_]\n",
    "    \n",
    "    temp_ = dict()\n",
    "    for exp_ in experiment:\n",
    "        key_ = exp_[0][:-1]\n",
    "        if key_ not in temp_:\n",
    "            temp_[key_] = list()\n",
    "        temp_[key_].append((exp_[0][-1], exp_[1:]))\n",
    "\n",
    "    temp_ = {key_ : sorted(res_, key=lambda x: x[0])\n",
    "             for key_, res_ in temp_.iteritems()}\n",
    "\n",
    "    results_ = dict()\n",
    "    for key_, result_ in temp_.iteritems():\n",
    "        ratio_ = np.stack([np.sqrt(np.mean((res_[1][0]-res_[1][1])**2, axis=0, keepdims=True)) /\n",
    "                           np.std(res_[1][0], axis=0, keepdims=True) for res_ in result_], axis=0)\n",
    "        sizes_ = np.array([res_[0] for res_ in result_])\n",
    "        coverage_ = np.stack([np.stack([res_[1][3+2*j] for res_ in result_], axis=0)\n",
    "                              for j in xrange(6)], axis=0)\n",
    "        width_ = np.stack([np.stack([res_[1][2+2*j] for res_ in result_], axis=0)\n",
    "                           for j in xrange(6)], axis=0)\n",
    "\n",
    "        if include_target:\n",
    "            target_ = np.stack([res_[1][0] for res_ in result_], axis=0)\n",
    "            target_hat_ = np.stack([res_[1][1] for res_ in result_], axis=0)\n",
    "            results_[key_] = ratio_, sizes_, coverage_, width_, target_, target_hat_\n",
    "        else:\n",
    "            results_[key_] = ratio_, sizes_, coverage_, width_\n",
    "\n",
    "    return results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_profiles(path, n_jobs=-1, verbose=1):\n",
    "    parallel_ = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "    jobs_ = (delayed(_load)(os.path.join(path, fname_))\n",
    "             for fname_ in os.listdir(path)\n",
    "             if fname_.endswith(\".gz\"))\n",
    "    dumps_ = parallel_(jobs_)\n",
    "    experiment = [exp_ for dump_ in dumps_ for exp_ in dump_]\n",
    "    \n",
    "    temp_ = dict()\n",
    "    for exp_ in experiment:\n",
    "        key_ = exp_[0][:-1]\n",
    "        if key_ not in temp_:\n",
    "            temp_[key_] = list()\n",
    "        temp_[key_].append((exp_[0][-1], exp_[1:]))\n",
    "\n",
    "    temp_ = {key_ : sorted(res_, key=lambda x: x[0])\n",
    "             for key_, res_ in temp_.iteritems()}\n",
    "\n",
    "    results_ = dict()\n",
    "    for key_, result_ in temp_.iteritems():\n",
    "        ratio_ = np.stack([np.sqrt(np.mean((res_[1][0]-res_[1][1])**2, axis=0, keepdims=True)) /\n",
    "                           np.std(res_[1][0], axis=0, keepdims=True) for res_ in result_], axis=0)\n",
    "        sizes_ = np.array([res_[0] for res_ in result_])\n",
    "        bounds_ = np.stack([np.stack([res_[1][2+j] for res_ in result_], axis=0)\n",
    "                            for j in xrange(6)], axis=0)\n",
    "        target_ = np.stack([res_[1][0] for res_ in result_], axis=0)\n",
    "        target_hat_ = np.stack([res_[1][1] for res_ in result_], axis=0)\n",
    "        results_[key_] = ratio_, sizes_, bounds_, target_, target_hat_\n",
    "\n",
    "    return results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coverage_plot(ax, sizes, cov, levels):\n",
    "    cov_med_ = np.median(cov, axis=-1)\n",
    "    cov_lo_, cov_hi_ = np.percentile(cov, [25, 75], axis=-1)\n",
    "\n",
    "    ax.set_ylim(0.65, 1.025)\n",
    "    ax.set_xlim(25, 1600)\n",
    "    ax.locator_params(axis=\"x\", nbins=5)\n",
    "    ax.set_yticks(1-levels)\n",
    "    for i in xrange(cov_med_.shape[1]):\n",
    "        ax.plot(sizes, cov_med_[:, i], color=\"bgrm\"[i%4])\n",
    "        ax.plot(sizes, cov_hi_[:, i], color=\"bgrm\"[i%4], alpha=0.5)\n",
    "        ax.plot(sizes, cov_lo_[:, i], color=\"bgrm\"[i%4], alpha=0.5)\n",
    "        ax.axhline(y=1 - levels[i], color='black', alpha=0.25)\n",
    "    return ax\n",
    "\n",
    "def nomorethan(x, bound=0):\n",
    "    x_ = np.array(x, dtype=float)\n",
    "    x_[x_>bound] = np.nan\n",
    "    return x_\n",
    "\n",
    "def width_plot(ax, sizes, width):\n",
    "    avg_width_ = width.mean(axis=-1)\n",
    "    aw_med_ = np.median(avg_width_, axis=-2)\n",
    "    aw_q95_ = np.percentile(avg_width_, [95,], axis=-2)[0]\n",
    "    aw_min_ = np.percentile(avg_width_, [ 5,], axis=-2)[0]\n",
    "    aw_max_ = np.max(avg_width_, axis=-2)\n",
    "\n",
    "    ax.set_xlim(25, 1600)\n",
    "    ax.locator_params(axis=\"x\", nbins=5)\n",
    "    for i in xrange(aw_med_.shape[1]):\n",
    "        ax.plot(sizes, nomorethan(aw_med_[:, i], 2), color=\"bgrm\"[i%4])\n",
    "#         ax.plot(sizes, nomorethan(aw_q95_[:, i], 2), color=\"bgrm\"[i%4], alpha=0.5, marker='x')\n",
    "        ax.plot(sizes, nomorethan(aw_max_[:, i], 2), color=\"bgrm\"[i%4], alpha=0.5, marker='v')\n",
    "        ax.plot(sizes, nomorethan(aw_min_[:, i], 2), color=\"bgrm\"[i%4], alpha=0.5, marker='^')\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "\n",
    "titles_ = pd.Index([\"GPR-p\", \"GPR-f\", \"RRCM\", \"CRR\", \"RRCM-loo\", \"CRR-loo\"], name=\"type\")\n",
    "ncms_ = pd.Index([\"GPR\", \"GPR\", \"RRCM\", \"CRR\", \"RRCM\", \"CRR\"], name=\"type\")\n",
    "levels_ = pd.Index([\"%0.2f\"%(lvl,) for lvl in levels], name=\"alpha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "\n",
    "exp_gauss_1d = load_dumps(os.path.join(DATA_PATH, 'exp_gauss_1d_25'), verbose=1, n_jobs=-1)\n",
    "exp_nongauss_1d = load_dumps(os.path.join(DATA_PATH, 'exp_nongauss_1d_25'), verbose=1, n_jobs=-1)\n",
    "\n",
    "exp_gauss_1d.update(exp_nongauss_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make coverage tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "for key_ in sorted(exp_gauss_1d.keys(), key=lambda x: (x[0], x[1], x[3], x[2])):\n",
    "    name_, noise_, theta0_, nugget_ = key_\n",
    "    ratio_, sizes_, coverage_, width_ = exp_gauss_1d[key_]\n",
    "\n",
    "    output_path_ = mkdirifnot(os.path.join(EXP1D_PATH, name_))\n",
    "    output_path_ = mkdirifnot(os.path.join(output_path_, \"%g_%g\"%(noise_, nugget_,)))\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"$'%s'$\")%(theta0_,)\n",
    "    title_template_ = \"%%s ($\\\\theta=%s, \\\\lambda=%g, \\\\gamma=%g$)\"%(theta_, nugget_, noise_)\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"%s\")%(theta0_,)\n",
    "    filename_template_ = \"%%s%s %g %g %s %%s\"%(name_, noise_, nugget_, theta_)\n",
    "\n",
    "    ## width dynamics\n",
    "    output_path_current_ = mkdirifnot(os.path.join(output_path_, \"width\"))\n",
    "    for j in xrange(6):\n",
    "        output_path_local_ = mkdirifnot(os.path.join(output_path_current_, titles_[j]))\n",
    "        fig = plt.figure(figsize=(4, 3))\n",
    "        ax = fig.add_subplot(111)\n",
    "#         ax.set_yscale(\"log\")\n",
    "        width_plot(ax, sizes_, width_[j])\n",
    "        ax.set_title(title_template_%(titles_[j],))\n",
    "\n",
    "        filename_ = (filename_template_%(\"width \", titles_[j],)).replace(\" \", \"_\").replace(\".\", \",\")\n",
    "        fig_file_name_ = os.path.join(output_path_local_, filename_ + \".pdf\")\n",
    "        fig.savefig(fig_file_name_, dpi=120)\n",
    "        plt.close()\n",
    "#         print fig_file_name_\n",
    "\n",
    "    ## Coverage asymptotics\n",
    "    output_path_current_ = mkdirifnot(os.path.join(output_path_, \"coverage\"))\n",
    "    for j in xrange(6):\n",
    "        output_path_local_ = mkdirifnot(os.path.join(output_path_current_, titles_[j]))\n",
    "        fig = plt.figure(figsize=(4, 3))\n",
    "        ax = fig.add_subplot(111)\n",
    "        coverage_plot(ax, sizes_, coverage_[j], levels)\n",
    "        ax.set_title(title_template_%(titles_[j],))\n",
    "\n",
    "        filename_ = (filename_template_%(\"coverage \", titles_[j],)).replace(\" \", \"_\").replace(\".\", \",\")\n",
    "        fig_file_name_ = os.path.join(output_path_local_, filename_ + \".pdf\")\n",
    "        fig.savefig(fig_file_name_, dpi=120)\n",
    "        plt.close()\n",
    "#         print fig_file_name_\n",
    "\n",
    "    ## rmse/var dynamics\n",
    "    output_path_current_ = output_path_\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ratio_ = nomorethan(ratio_.mean(axis=-1), 1)\n",
    "#     ax.set_ylim(bottom = -0.001)\n",
    "    ax.plot(sizes_, ratio_)\n",
    "    ax.set_title(title_template_%('RMSE/std',))\n",
    "\n",
    "    filename_ = (filename_template_%(\"\", \"ratio\",)).replace(\" \", \"_\").replace(\".\", \",\")\n",
    "    fig_file_name_ = os.path.join(output_path_, filename_ + \".pdf\")\n",
    "    fig.savefig(fig_file_name_, dpi=120)\n",
    "    plt.close()\n",
    "#     print fig_file_name_\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX_test = np.linspace(0, 1, num=501).reshape((-1, 1))\n",
    "\n",
    "prof_gauss = load_profiles(os.path.join(DATA_PATH, 'prof_gauss'), verbose=1, n_jobs=1)\n",
    "prof_nongauss = load_profiles(os.path.join(DATA_PATH, 'prof_nongauss'), verbose=1, n_jobs=1)\n",
    "\n",
    "prof_gauss.update(prof_nongauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key_ in sorted(prof_gauss.keys(), key=lambda x: (x[0], x[1], x[3], x[2])):\n",
    "    name_, noise_, theta0_, nugget_ = key_\n",
    "    ratio_, sizes_, bounds_, y_test_, y_hat_ = prof_gauss[key_]\n",
    "    ## Skip\n",
    "#     if name_ != \"heaviside\": continue\n",
    "#     if theta0_ == \"auto\": continue\n",
    "\n",
    "    output_path_ = mkdirifnot(os.path.join(PROFILE_PATH, name_))\n",
    "    output_path_ = mkdirifnot(os.path.join(output_path_, \"%g_%g\"%(noise_, nugget_,)))\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"$'%s'$\")%(theta0_,)\n",
    "    title_template_ = \"%%s: %%s ($\\\\theta=%s, \\\\lambda=%g, \\\\gamma=%g$)\"%(theta_, nugget_, noise_)\n",
    "\n",
    "    theta_= (\"%g\" if isinstance(theta0_, float) else \"%s\")%(theta0_,)\n",
    "    filename_template_ = \"%%s%s %g %g %s %%s\"%(name_, noise_, nugget_, theta_)\n",
    "\n",
    "    ## Profile\n",
    "    for s_ in xrange(len(sizes_)):\n",
    "#         if s_ > 1: continue\n",
    "        output_path_current_ = mkdirifnot(os.path.join(output_path_, \"%d\"%(sizes_[s_],)))\n",
    "        for i_ in xrange(4):\n",
    "            # max_, min_ = np.percentile(bounds_[:, s_, :, i_], [92.5, 7.5])*2\n",
    "            max_, min_ = y_test_[s_].max()*1.5, y_test_[s_].min()*1.5\n",
    "            if name_==\"heaviside\": min_, max_ = -0.95, 1.95\n",
    "            for ncm_ in pd.unique(ncms_):\n",
    "                fig = plt.figure(figsize=(5, 4))\n",
    "                ax = fig.add_subplot(111)\n",
    "                if np.isfinite(min_) and np.isfinite(max_):\n",
    "                    ax.set_ylim(min_, max_)\n",
    "                ax.plot(XX_test, y_test_[s_], c=\"#c0c0c0\", lw=2, alpha=.5, label=\"$y_x$\")\n",
    "                ax.plot(XX_test, y_hat_[s_], c='k', label=\"$\\\\hat{y}_x$\")\n",
    "                for j, b in enumerate(np.flatnonzero(ncms_==ncm_)):\n",
    "                    ax.plot(XX_test, bounds_[b, s_, :, i_, 0], color=\"rb\"[j], label=titles_[b])\n",
    "                    ax.plot(XX_test, bounds_[b, s_, :, i_, 1], color=\"rb\"[j])\n",
    "                ax.set_title(title_template_%(\"%.1f%%-%s\"%(levels[i_]*100, ncm_,), name_,))\n",
    "                ax.legend(loc=\"best\", ncol=2)\n",
    "\n",
    "                filename_ = (filename_template_%(\"profile \", \"%dp-%s %d\"%(levels[i_]*100, ncm_, sizes_[s_],),))\n",
    "                fig_file_name_ = os.path.join(output_path_current_,\n",
    "                                              filename_.replace(\" \", \"_\").replace(\".\", \",\") + \".pdf\")\n",
    "                fig.savefig(fig_file_name_, dpi=120)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nd = 2\n",
    "mesh_ = np.meshgrid(*nd*[np.linspace(0, 1, num=51)])\n",
    "XX_test = np.concatenate([ax_.reshape((-1, 1)) for ax_ in mesh_], axis=1)\n",
    "exp_gauss_2d = load_dumps(os.path.join(DATA_PATH, 'exp_gauss_2d_25'),\n",
    "                          verbose=1, n_jobs=1, include_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_nongauss_2d = load_dumps(os.path.join(DATA_PATH, 'exp_nongauss_2d_25'),\n",
    "                             verbose=1, n_jobs=1, include_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_2d = dict()\n",
    "exp_2d.update(exp_nongauss_2d)\n",
    "exp_2d.update(exp_gauss_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table #1: gaussian 2d case RMSE/STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ = pd.concat([pd.DataFrame(exp_2d[key_][0].mean(axis=-1).T,\n",
    "                              index=pd.Index([key_], names=[\"name\", \"noise\", \"theta\", \"nugget\"]),\n",
    "                              columns=pd.Index(exp_2d[key_][1], name=\"size\"))\n",
    "                 for key_ in sorted(exp_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]],\n",
    "                axis=0).unstack(level=0).swaplevel(0,1, axis=1).sort_index(axis=1)\\\n",
    "        .swaplevel(1,2, axis=0).sort_index(axis=0)\n",
    "\n",
    "print df_.unstack().T.xs(\"gaussian\", axis=0).to_latex(float_format=lambda f: \"%0.3f\"%(f,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table #2: GPR confidence sets -- correct $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ = pd.concat({key_: pd.Panel(1-np.mean(exp_2d[key_][2], axis=-1), items=titles_, minor_axis=levels_,\n",
    "                                major_axis=pd.Index(exp_2d[key_][1], name=\"size\")).to_frame()\n",
    "                 for key_ in sorted(exp_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]},\n",
    "                axis=0, names=[\"name\", \"noise\", \"theta\", \"nugget\"])\\\n",
    "   .xs(\"gaussian\", axis=0)\\\n",
    "   .drop(\"GPR-p\", axis=1).unstack(level=-1)\n",
    "\n",
    "print \\\n",
    "df_.xs(\"GPR-f\", axis=1, level=0).drop(10.0, axis=0, level=1).drop(1000.0, axis=0, level=1)\\\n",
    "    .unstack(level=-1).unstack(level=1).T\\\n",
    "    .swaplevel(0,2,axis=0).swaplevel(1,0,axis=0).sort_index(axis=0)\\\n",
    "           .to_latex(float_format=lambda f: \"%3.1f\"%(100*f,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table #3: conformal confidence sets -- incorrect $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ = pd.concat({key_: pd.Panel(1-np.mean(exp_2d[key_][2], axis=-1), items=titles_, minor_axis=levels_,\n",
    "                                major_axis=pd.Index(exp_2d[key_][1], name=\"size\")).to_frame()\n",
    "                 for key_ in sorted(exp_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]},\n",
    "                axis=0, names=[\"name\", \"noise\", \"theta\", \"nugget\"])\\\n",
    "   .xs(\"gaussian\", axis=0)\\\n",
    "   .drop(\"GPR-p\", axis=1).unstack(level=-1)\n",
    "\n",
    "print \\\n",
    "df_.xs(\"GPR-f\", axis=1, level=0).drop(100.0, axis=0, level=1).drop(\"auto\", axis=0, level=1)\\\n",
    "    .unstack(level=-1).unstack(level=1).T\\\n",
    "    .swaplevel(0,2,axis=0).swaplevel(1,0,axis=0).sort_index(axis=0)\\\n",
    "           .to_latex(float_format=lambda f: \"%3.1f\"%(100*f,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table #4: conformal confidence sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ = pd.concat({key_: pd.Panel(1-np.mean(exp_2d[key_][2], axis=-1) - levels, items=titles_, minor_axis=levels_,\n",
    "                                major_axis=pd.Index(exp_2d[key_][1], name=\"size\")).to_frame()\n",
    "                 for key_ in sorted(exp_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]},\n",
    "                axis=0, names=[\"name\", \"noise\", \"theta\", \"nugget\"])\\\n",
    "   .xs(\"gaussian\", axis=0)\\\n",
    "   .drop(\"GPR-p\", axis=1).unstack(level=-1)\n",
    "\n",
    "print \\\n",
    "np.abs(df_).max(axis=1, level=0).drop(\"GPR-f\", axis=1)\\\n",
    ".unstack(level=-1).unstack(level=1).T\\\n",
    ".unstack(level=1).swaplevel(0, -1, axis=1).swaplevel(2, 1, axis=1).sort_index(axis=1)\\\n",
    ".to_latex(float_format=lambda f: \"%2.1f\"%(100*f,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table #5: non-gaussian $2$-d RMSE/std ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ = pd.concat([pd.DataFrame(exp_2d[key_][0].mean(axis=-1).T,\n",
    "                              index=pd.Index([key_], names=[\"name\", \"noise\", \"theta\", \"nugget\"]),\n",
    "                              columns=pd.Index(exp_2d[key_][1], name=\"size\"))\n",
    "                 for key_ in sorted(exp_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]],\n",
    "                axis=0).unstack(level=0).swaplevel(0,1, axis=1).sort_index(axis=1)\\\n",
    "        .swaplevel(1,2, axis=0).sort_index(axis=0)\n",
    "\n",
    "print \\\n",
    "df_.unstack().T.drop(\"gaussian\", axis=0)\\\n",
    ".unstack(0).swaplevel(0,2, axis=1).swaplevel(1,2, axis=1).sort_index(axis=1)\\\n",
    ".to_latex(float_format=lambda f: \"%0.2f\"%(f,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table #6: non-gaussian GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ = pd.concat({key_: pd.Panel(1-np.mean(exp_2d[key_][2], axis=-1)-levels, items=titles_, minor_axis=levels_,\n",
    "                                major_axis=pd.Index(exp_2d[key_][1], name=\"size\")).to_frame()\n",
    "                 for key_ in sorted(exp_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]},\n",
    "                axis=0, names=[\"name\", \"noise\", \"theta\", \"nugget\"])\\\n",
    "   .drop(\"gaussian\", axis=0)\\\n",
    "   .drop(\"GPR-p\", axis=1).drop(\"GPR-f\", axis=1).unstack(level=-1)\n",
    "\n",
    "# print \\\n",
    "# np.abs(df_).max(axis=1, level=0)\n",
    "df_.xs(\"0.05\", axis=1, level=1).unstack(level=1).unstack(level=2).T.unstack(level=0).T.\\\n",
    "swaplevel(1,-1, axis=0).sort_index(axis=0).unstack(0).\\\n",
    "swaplevel(2, 1, axis=1).swaplevel(1, 0, axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_.xs(\"f2\", axis=0, level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ = pd.concat({key_: pd.Panel(1-np.mean(exp_2d[key_][2], axis=-1) - levels, items=titles_, minor_axis=levels_,\n",
    "                                major_axis=pd.Index(exp_2d[key_][1], name=\"size\")).to_frame()\n",
    "                 for key_ in sorted(exp_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]},\n",
    "                axis=0, names=[\"name\", \"noise\", \"theta\", \"nugget\"])\\\n",
    "   .drop(\"gaussian\", axis=0).drop(\"GPR-p\", axis=1).unstack(level=-1)\n",
    "\n",
    "df_.xs(\"f2\", axis=0, level=0).xs(\"GPR-f\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# EXP2D_PATH\n",
    "for key_ in sorted(exp_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]:\n",
    "    name_, noise_, theta0_, nugget_ = key_\n",
    "    ratio_, sizes_, coverage_, width_, y_test, y_hat = exp_2d[key_]\n",
    "\n",
    "    df_coverage_ = pd.Panel(np.mean(coverage_[:, 1:], axis=-1), items=titles_, minor_axis=levels_,\n",
    "                            major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "\n",
    "    avg_width_ = np.mean(width_, axis=-1)[:, 1:]\n",
    "    aw_med_ = np.median(avg_width_, axis=-2)\n",
    "    aw_q95_ = np.percentile(avg_width_, [95,], axis=-2)[0]\n",
    "    aw_min_ = np.percentile(avg_width_, [ 5,], axis=-2)[0]\n",
    "    aw_max_ = np.max(avg_width_, axis=-2)\n",
    "    pn_med_ = pd.Panel(aw_med_, items=titles_, minor_axis=levels_, major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "    pn_q95_ = pd.Panel(aw_q95_, items=titles_, minor_axis=levels_, major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "\n",
    "    pv_ = np.stack([ttest_1samp(coverage_[:, 1:, j], (1 - levels[j]), axis=-1)[1] for j in xrange(4)], axis=-1)\n",
    "    pn_pv_ = pd.Panel(pv_, items=titles_, minor_axis=levels_, major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "\n",
    "    df_output_ = pd.concat({\"width. med\": pn_med_.to_frame(),\n",
    "                            \"width 95%\": pn_q95_.to_frame(),\n",
    "                            \"coverage\": df_coverage_.to_frame(),\n",
    "#                             \"t-test\": pn_pv_.to_frame(),\n",
    "                           },\n",
    "                           axis=0, names=[\"statistic\"])\\\n",
    "                   .swaplevel(0, 1, axis=0).sort_index(axis=0)\\\n",
    "                   .drop(\"GPR-p\", axis=1)\n",
    "    print key_\n",
    "#     display(HTML(df_output_.to_html(float_format=lambda f: \"%0.3f\"%(f,))))\n",
    "#     print df_output_.to_latex(float_format=lambda f: \"%0.3f\"%(f,))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_width_ = np.mean(width_, axis=-1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_width_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## The approximated surface\n",
    "plot_ = np.abs(y_test_-y_hat_)-.5*avg_width_[2, :, -1]\n",
    "plot_[plot_<0] = 0\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], (plot_).reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Show the true surface\n",
    "y_test_ = y_hat[0].mean(axis=-1)\n",
    "y_hat_ = y_hat[1].mean(axis=-1)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], y_test_.reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)\n",
    "plt.show()\n",
    "\n",
    "## The approximated surface\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], np.abs(y_test_-y_hat_).reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.functions_2d import f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yy = f2(XX)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], y_test_.reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# EXP2D_PATH\n",
    "for key_ in sorted(exp_gauss_2d.keys(), key=lambda x: (x[0], x[1], x[3], x[2]))[::-1]:\n",
    "    name_, noise_, theta0_, nugget_ = key_\n",
    "    ratio_, sizes_, coverage_, width_, y_test, y_hat = exp_gauss_2d[key_]\n",
    "\n",
    "    df_coverage_ = pd.Panel(np.mean(coverage_[:, 1:], axis=-1), items=titles_, minor_axis=levels_,\n",
    "                            major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "\n",
    "    avg_width_ = np.mean(width_, axis=-1)[:, 1:]\n",
    "    aw_med_ = np.median(avg_width_, axis=-2)\n",
    "    aw_q95_ = np.percentile(avg_width_, [95,], axis=-2)[0]\n",
    "    aw_min_ = np.percentile(avg_width_, [ 5,], axis=-2)[0]\n",
    "    aw_max_ = np.max(avg_width_, axis=-2)\n",
    "    pn_med_ = pd.Panel(aw_med_, items=titles_, minor_axis=levels_, major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "    pn_q95_ = pd.Panel(aw_q95_, items=titles_, minor_axis=levels_, major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "\n",
    "    pv_ = np.stack([ttest_1samp(coverage_[:, 1:, j], (1 - levels[j]), axis=-1)[1] for j in xrange(4)], axis=-1)\n",
    "    pn_pv_ = pd.Panel(pv_, items=titles_, minor_axis=levels_, major_axis=pd.Index(sizes_[1:], name=\"size\"))\n",
    "\n",
    "    df_output_ = pd.concat({\"width. med\": pn_med_.to_frame(),\n",
    "                            \"width 95%\": pn_q95_.to_frame(),\n",
    "                            \"coverage\": df_coverage_.to_frame(),\n",
    "                            \"t-test\": pn_pv_.to_frame()},\n",
    "                           axis=0, names=[\"statistic\"])\\\n",
    "                   .swaplevel(0, 1, axis=0).sort_index(axis=0)\n",
    "    print key_\n",
    "#     display(HTML(df_output_.to_html(float_format=lambda f: \"%0.3f\"%(f,))))\n",
    "#     print df_output_.to_latex(float_format=lambda f: \"%0.3f\"%(f,))\n",
    "    \n",
    "    ## Show the true surface\n",
    "    y_test_ = y_test[1].mean(axis=-1)\n",
    "    y_hat_ = y_hat[1].mean(axis=-1)\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(mesh_[0], mesh_[1], y_test_.reshape(mesh_[0].shape),\n",
    "                    cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                    antialiased=False, alpha=0.9)\n",
    "    ax.view_init(60, -60)\n",
    "    plt.show()\n",
    "\n",
    "    ## The approximated surface\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(mesh_[0], mesh_[1], y_hat_.reshape(mesh_[0].shape),\n",
    "                    cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                    antialiased=False, alpha=0.9)\n",
    "    ax.view_init(60, -60)\n",
    "    plt.show()\n",
    "    \n",
    "#     ## The GPR-p\n",
    "#     fig = plt.figure(figsize=(6, 3))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     ax.plot_surface(mesh_[0], mesh_[1], avg_width_[0, 0, :, 2].reshape(mesh_[0].shape),\n",
    "#                     cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "#                     antialiased=False, alpha=0.9)\n",
    "#     ax.view_init(60, -60)\n",
    "#     ax.set_title(titles_[0])\n",
    "#     plt.show()\n",
    "    \n",
    "#     ## The RRCM / GPR-p : j=0..3, i=2..5\n",
    "#     i, j = 3, 2\n",
    "#     awr_ = avg_width_[i, 0, :, j] / avg_width_[0, 0, :, j] - 1\n",
    "#     fig = plt.figure(figsize=(6, 3))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     ax.plot_surface(mesh_[0], mesh_[1], awr_.reshape(mesh_[0].shape),\n",
    "#                     cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "#                     antialiased=False, alpha=0.9)\n",
    "#     ax.view_init(60, -60)\n",
    "#     ax.set_title(titles_[2])\n",
    "#     plt.show()\n",
    "    \n",
    "    print ratio_.mean(axis=-1)[1, 0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.log(awr_), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pn_pv_.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coverage_ = dict()\n",
    "for key_, item_ in exp_gauss_1d.iteritems():\n",
    "    sizes_ = pd.Index(item_[1], name=\"size\")\n",
    "    noise_, theta0_, nugget_ = key_[1:]\n",
    "    df_cov_ = pd.Panel(item_[2].mean(axis=-1), items=titles_, major_axis=sizes_, minor_axis=levels_).to_frame()\n",
    "    pv_ = np.stack([ttest_1samp(item_[2][:,:,j], (1-levels[j]), axis=-1)[1] for j in xrange(4)], axis=-1)\n",
    "    df_cov_pv_ = pd.Panel(pv_, items=titles_, major_axis=sizes_, minor_axis=levels_).to_frame()\n",
    "    coverage_[key_] = df_cov_, df_cov_pv_, item_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.stack([ttest_1samp(item_[2][:,:,j], (1-levels[j]), axis=-1)[1] for j in xrange(4)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.abs(item_[2].mean(axis=-1)-(1-levels)[np.newaxis, np.newaxis]) / item_[2].std(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hits_ = np.round(item_[2].mean(axis=-1)*2601)\n",
    "pv_ = np.stack([np.vectorize(lambda x: binom_test(x, n=2601, p=1 - levels[j]))(hits_[..., j]) for j in range(4)], axis=-1)\n",
    "pv_[pv_ < 0.001] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_[2][..., j, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_.T.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], m_w_[1, 1, :, 0].reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                antialiased=False, alpha=0.9)\n",
    "ax.view_init(60, -60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
