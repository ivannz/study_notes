{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformalized Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import _save, _load\n",
    "\n",
    "from scipy.linalg import cholesky, solve_triangular\n",
    "from sklearn.metrics.pairwise import pairwise_kernels as kernel\n",
    "from sklearn.utils import check_random_state, resample\n",
    "from sklearn.cross_validation import train_test_split, ShuffleSplit\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "\n",
    "from utils.mpl_mid_point_norm import MidPointNorm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mkdirifnot(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    return path\n",
    "\n",
    "BASE_PATH = mkdirifnot(os.path.join(\".\", \"new-%s\"%(time.strftime(\"%Y%m%d_%H%M%S\"),)))\n",
    "\n",
    "PLOT_PATH = mkdirifnot(os.path.join(BASE_PATH, \"plots\"))\n",
    "SAMPLE_PLOT_PATH = mkdirifnot(os.path.join(PLOT_PATH, \"sample\"))\n",
    "VISUAL_PLOT_PATH = mkdirifnot(os.path.join(PLOT_PATH, \"visual\"))\n",
    "OUTPUT_PLOT_PATH = mkdirifnot(os.path.join(PLOT_PATH, \"output\"))\n",
    "OUTPUT_PATH = mkdirifnot(os.path.join(BASE_PATH, \"dumps\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute RBF kernel:\n",
    "$$ K(x, x') = \\mathop{\\text{exp}}\\bigl\\{-\\gamma\\|x-x'\\|^2\\bigr\\} \\,, $$\n",
    "for arbitrary datasets $X\\in\\mathcal{X}^{n\\times 1}$ and $Z\\in\\mathcal{X}^{m\\times 1}$,\n",
    "$\\mathcal{X} \\subseteq \\mathbb{R}^{d\\times 1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain a matrix\n",
    "$$ Q\n",
    "    = \\begin{pmatrix}\n",
    "        aI_{n+m}\n",
    "        + \\begin{pmatrix}\n",
    "            K_XX & K_{XX^*}\\\\\n",
    "            K_{X^*X} & K_{X^*X^*}\n",
    "          \\end{pmatrix}\n",
    "       \\end{pmatrix}^{-1}\n",
    "    \\,, $$\n",
    "and return its block structure accroding to:\n",
    "$$ Q\n",
    "    = \\begin{pmatrix}\n",
    "        Q_X + Q_XK_{XX^*} M^{-1} K_{X^*X} Q_X & - Q_X K_{XX^*} M^{-1} \\\\\n",
    "        - M^{-1} K_{X^*X} Q_X & M^{-1}\n",
    "    \\end{pmatrix}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since only $A$ and $B$ vector are required for construction of Conformal Confidence\n",
    "Region for Regression construction, we prepare a special routine to compute them in bulk:\n",
    "$$ B'e_i\n",
    "    = \\begin{pmatrix}\n",
    "        - Q_X K_{Xz_i} \\\\\n",
    "        1\n",
    "    \\end{pmatrix} m_i^{-1} a \\,, $$\n",
    "and\n",
    "$$ A'e_i\n",
    "    = \\begin{pmatrix}\n",
    "        Q_X y + Q_X K_{Xz_i} m_i^{-1} K_{z_iX} Q_X y \\\\\n",
    "        - m_i^{-1} K_{z_iX} Q_X y\n",
    "    \\end{pmatrix} a\n",
    "    = \\begin{pmatrix} Q_X y \\\\ 0 \\end{pmatrix} a\n",
    "    - \\begin{pmatrix}\n",
    "        - Q_X K_{Xz_i} \\\\\n",
    "        1\n",
    "    \\end{pmatrix} m_i^{-1} K_{z_iX} Q_X y a\n",
    "    = \\begin{pmatrix} a Q_X y \\\\ 0 \\end{pmatrix}\n",
    "    - B'e_i K_{z_iX} Q_X y \\,, $$\n",
    "with\n",
    "$$ m_i = a + K(z_i, z_i) - K_{z_iX} Q_X K_{Xz_i} \\,. $$\n",
    "\n",
    "Note that $a Q_x = I_n - K_x Q_x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOO residuals are computed using the following result: for all $i=1,\\ldots, n$ it is\n",
    "true that $\\hat{r}_i = e_i' a Q_X y$, which is given by \n",
    "$$ \\hat{r}_i\n",
    "    = a m_i^{-1} \\bigl(y_i - k_{-i}(x_i)Q_{-i}y_{-i} \\bigr)\n",
    "     = a m_i^{-1} \\hat{r}_{i\\vert -i}\n",
    "    \\,, $$\n",
    "using the block inversion of a row-columns permuted matrix $Q_X$. In a compacter matrix\n",
    "form this is given by\n",
    "$$ \\hat{r} = a \\mathop{\\text{diag}}(Q_X) \\hat{r}_{\\text{loo}} \\,, $$\n",
    "which, when all $m_i$ are non-zero, is equivalent to:\n",
    "$$ \\hat{r}_{\\text{loo}}\n",
    "    = a^{-1} \\mathop{\\text{diag}}(Q_X)^{-1} \\hat{r}\n",
    "    = a^{-1} \\mathop{\\text{diag}}(Q_X)^{-1} a Q_X y\n",
    "    = \\mathop{\\text{diag}}(Q_X)^{-1} Q_X y\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.KRR import KRR_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A separate fast LOO computation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.KRR import KRR_loo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confidence region builder for measure\n",
    "$$ \\alpha_i^y = - \\hat{r}^y_i = - (a_i + b_i y) \\,. $$\n",
    "The p-value is computed as\n",
    "$$ p^y = n^{-1} \\bigl\\lvert\\{i=1,\\ldots, n\\,:\\, y\\in S_i \\}\\bigr\\rvert \\,, $$\n",
    "where\n",
    "$$ S_i = \\{y\\in \\mathbb{R}\\,:\\, \\alpha_i^y \\leq \\alpha_n^y \\} \\,. $$\n",
    "\n",
    "\n",
    "A confidence region builder for measures\n",
    "$$ \\alpha_i^y = \\hat{r}^y_i \\text{ and } \\alpha_i^y = -\\hat{r}^y_i \\,, $$\n",
    "used in Vovk, Burnaev (2014) for Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.conformal import CCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a confidence measure builder for measure\n",
    "$$ \\alpha^y_i = - \\lvert \\hat{r}^y_i\\rvert\\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confidence region builder for Vovk's original Ridge Regression Confidence Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.conformal import RRCM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gaussian process generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.functions import get_functions\n",
    "DGP = get_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0x12345678)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate mesh of $X$ samples for the Gaussian Process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_ = 2\n",
    "mesh_ = np.meshgrid(*dim_*[np.linspace(-1, 1, num=51)])\n",
    "XX = np.concatenate([ax_.reshape((-1,1)) for ax_ in mesh_], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the width of the RBF kernel and the regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma = 50.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels = np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "lvl_cols_ = [\"%4.1f%%\"%(100*lv_,) for lv_ in levels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate A GP with the specified kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_ = \"gaussian\"\n",
    "yy = DGP[name_](XX, random_state=random_state, nugget=1e-9, gamma=gamma)\n",
    "if yy.ndim == 1:\n",
    "    yy = yy.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a nice 3D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], yy.reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0, antialiased=False)\n",
    "ax.view_init(60, 30)\n",
    "ax.set_title(\"A sample trajectory of a 2D Gaussian process\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(XX, yy, test_size=0.25, random_state=random_state)\n",
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a Gaussian process regression to the train dataset $(X, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp = GaussianProcess(thetaL=1e-4, thetaU=1e2, beta0=0,\n",
    "                     normalize=False, nugget=1e-6).fit(X_train, y_train)\n",
    "print gp.theta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a prediction on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred, sigma2_pred = gp.predict(XX, eval_MSE=True)\n",
    "if sigma2_pred.ndim == 1:\n",
    "    sigma2_pred = sigma2_pred.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], y_pred.reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0, antialiased=False)\n",
    "ax.view_init(60, 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], np.abs(yy - y_pred).reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0, antialiased=False)\n",
    "ax.view_init(60, 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction variance:\n",
    "$$ \\mathtt{var}(\\hat{y}^*_{|(X, y), x^*}) = K(x^*, x^*) - k_X(x^*)'Q_X k_X(x^*) \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], np.sqrt(sigma2_pred).reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0, antialiased=False)\n",
    "ax.view_init(60, 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the estimate of the forecast error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio_ = np.abs(yy-y_pred) / (np.sqrt(sigma2_pred + gp.sigma2) * st.norm.ppf(0.95))\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(mesh_[0], mesh_[1], ratio_.reshape(mesh_[0].shape),\n",
    "                cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0, antialiased=False)\n",
    "ax.view_init(60, 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key parameters are: $\\sigma^2$, $\\gamma$ and $\\mathtt{nugget}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function to analyse the conformal procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _pccia(key, levels, y, y_hat, m, A, B):\n",
    "    z_levels = (sqrt(m) * norm.ppf(1 - .5 * levels))\n",
    "    bayes_ = [np.array([[a, b]]) for a, b in zip(y_hat - z_levels, y_hat + z_levels)]\n",
    "    rrcm_ = RRCM(A, B, levels=levels)\n",
    "    ccr_ = CCR(A, B, levels=levels)\n",
    "    def _helper(y, regions):\n",
    "        return np.asarray([np.any(((int_[:, 0] <= y) & (y <= int_[:, 1]))) for int_ in regions]), \\\n",
    "               np.asarray([np.sum(int_[:, 1] - int_[:, 0]) for int_ in regions]), \\\n",
    "               np.asarray([[int_.min(), int_.max()] for int_ in regions])\n",
    "    return key, _helper(y, rrcm_), _helper(y, ccr_), _helper(y, bayes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-compute the necessary vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A, B, y_hat_, MM, loo_ = KRR_AB(X_train, y_train, X_test,\n",
    "                                nugget=gp.nugget, loo=False, metric=\"rbf\",\n",
    "                                gamma=gp.theta_[0])\n",
    "MM *= gp.sigma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GP prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat_gp, mse_gp = gp.predict(X_test, eval_MSE=True)\n",
    "assert np.allclose(y_hat_, y_hat_gp, rtol=1e-3)\n",
    "assert np.allclose(MM[:, 0], mse_gp + gp.sigma2 * gp.nugget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the parallel backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from itertools import chain\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "parallel_ = Parallel(n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a generator for jobs and run them in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs_ = (delayed(_pccia)(k, levels, y_test[k], y_hat_[k], MM[k], A[0, k], B[k])\n",
    "         for k in xrange(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_ = parallel_(jobs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                   for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                  for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                    for key_, rrcm_, ccr_, bayes_ in results_], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hits_.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(width_, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, type_ in enumerate([\"rrcm\", \"crr\", \"bayes\"]):\n",
    "    for j, sign_ in enumerate(lvl_cols_):\n",
    "        excess_u_ = y_test - bounds_[:, j, 1, i, np.newaxis]\n",
    "        excess_d_ = bounds_[:, j, 0, i] - y_test\n",
    "        excess_u_[excess_u_ < 0] = 0\n",
    "        excess_d_[excess_d_ < 0] = 0\n",
    "        excess_ = 2 * (excess_u_ - excess_d_) / width_[:, j, i, np.newaxis]\n",
    "\n",
    "        fig = plt.figure(figsize=(16, 9))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        ax.set_title(\"\"\"Excess of `%s`-type %s-interval for `%s`\"\"\"\n",
    "                     %(type_, sign_, name_,))\n",
    "        ax.plot_trisurf(X_test[:, 0], X_test[:, 1], excess_[..., 0], cmap=plt.cm.coolwarm,\n",
    "                        lw=0, alpha=.95, norm=MidPointNorm())\n",
    "        ax.view_init(60, 60)\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.functions_1d import get_functions\n",
    "func1d_ = get_functions()\n",
    "\n",
    "from scipy.stats import norm\n",
    "from itertools import chain\n",
    "from joblib import Parallel, delayed\n",
    "parallel_ = Parallel(n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# random_state = np.random.RandomState(0x0ABACABA)\n",
    "# random_state = np.random.RandomState(0x0DABACAB)\n",
    "random_state = np.random.RandomState(0x0EABACAB)\n",
    "use_loo = True\n",
    "\n",
    "noise_ = 1e-6\n",
    "z_a = norm.ppf(1 - .5 * levels)\n",
    "for size_ in [400,]:\n",
    "## train\n",
    "    X_train = random_state.uniform(size=(size_, 1))\n",
    "## test\n",
    "    X_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "    X = np.concatenate([X_train, X_test], axis=0)\n",
    "    train_ = np.s_[:X_train.shape[0]]\n",
    "    for nugget in np.logspace(-4, 0, num=3):\n",
    "        for func_ in func1d_.iterkeys():\n",
    "            print size_, nugget, func_,\n",
    "            y = func1d_[func_](X)\n",
    "            y += random_state.normal(size=y.shape) * noise_\n",
    "\n",
    "            y_train = y[train_]\n",
    "            y_test = np.delete(y, train_, axis=0)\n",
    "\n",
    "            gp = GaussianProcess(thetaL=1e-4, thetaU=1e4, beta0=0,\n",
    "                                 normalize=False, nugget=nugget).fit(X_train, y_train)\n",
    "\n",
    "            A, B, y_hat_, MM, loo_ = KRR_AB(X_train, y_train, X_test, forecast=True, loo=use_loo,\n",
    "                                            nugget=gp.nugget, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "            MM *= gp.sigma2\n",
    "\n",
    "            jobs_ = (delayed(_pccia)(k, levels, y_test[k], y_hat_[k], MM[k], A[0, k], B[k])\n",
    "                     for k in xrange(y_test.shape[0]))\n",
    "            results_ = parallel_(jobs_)\n",
    "\n",
    "            width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                               for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                              for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                                for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            hit_prob_ = hits_.mean(axis=0)\n",
    "            hit_prob_std_ = hits_.std(axis=0)\n",
    "\n",
    "            for j, name_ in enumerate([\"rrcm\", \"crr\"]):\n",
    "                fig = plt.figure(figsize=(12, 6))\n",
    "                order_ = [1, 4, 2, 5, 3, 6]\n",
    "\n",
    "                ax = fig.add_subplot(2, 3, order_[0])\n",
    "                ax.plot(X_test, y_test, color=\"blue\")\n",
    "                ax.plot(X_test, y_hat_, color=\"red\")\n",
    "                ax.set_title(\"Actual/Prediction: %s\"%(func_,))\n",
    "\n",
    "                ax = fig.add_subplot(2, 3, order_[1])\n",
    "                ax.plot(X_test, np.abs(y_hat_ - y_test))\n",
    "                ax.set_title(\"Absolute error\")\n",
    "\n",
    "                for i in xrange(4):\n",
    "                    ax = fig.add_subplot(2, 3, order_[i + 2])\n",
    "\n",
    "                    ax.plot(X_test, np.abs(y_hat_ - y_test), alpha=0.25, label=\"$|y-\\\\hat{y}|$\")\n",
    "                    ax.plot(X_test, np.sqrt(MM), label=\"bayes\")\n",
    "            #         ax.plot(X_test, (bounds_[:, i, 1, 2] - bounds_[:, i, 0, 2]) / (2 * z_a[i]), label=\"bayes\")\n",
    "                    ax.plot(X_test, (bounds_[:, i, 1, j] - bounds_[:, i, 0, j]) / (2 * z_a[i]), label=name_)\n",
    "                    ax.set_title(\"Absolute error/accuracy %s %s-CI\"%(name_, lvl_cols_[i],))\n",
    "                    ax.legend(loc=\"best\")\n",
    "\n",
    "                fig.tight_layout()\n",
    "                fig_name_ = os.path.join(PLOT_PATH, \"%s 1k-%d %.1e %.1e %s%s.png\"\n",
    "                                         %(func_, X_train.shape[0], nugget, noise_, name_,\n",
    "                                           \" loo\" if use_loo else \"\"))\n",
    "                print fig_name_\n",
    "\n",
    "                fig.savefig(fig_name_)\n",
    "                plt.close()\n",
    "#                 plt.show()\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce the 1D test plots for a $10k$ grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0x0BADC0DE)\n",
    "\n",
    "z_a = norm.ppf(1 - .5 * levels)\n",
    "for size_ in [10, 20,]:\n",
    "## train\n",
    "    X_train = random_state.uniform(size=(size_, 1))\n",
    "## test\n",
    "    X_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "    X = np.concatenate([X_train, X_test], axis=0)\n",
    "    train_ = np.s_[:X_train.shape[0]]\n",
    "    for nugget in np.logspace(-4, 0, num=3):\n",
    "        for func_ in func1d_.iterkeys():\n",
    "            print size_, nugget, func_,\n",
    "            y = func1d_[func_](X)\n",
    "\n",
    "            y_train = y[train_]\n",
    "            y_test = np.delete(y, train_, axis=0)\n",
    "\n",
    "            gp = GaussianProcess(thetaL=1e-4, thetaU=1e4, beta0=0,\n",
    "                                 normalize=False, nugget=nugget).fit(X_train, y_train)\n",
    "\n",
    "            A, B, y_hat_, MM, loo_ = KRR_AB(X_train, y_train, X_test, forecast=True,\n",
    "                                            nugget=gp.nugget, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "            MM *= gp.sigma2\n",
    "\n",
    "            jobs_ = (delayed(_pccia)(k, levels, y_test[k], y_hat_[k], MM[k], A[0, k], B[k])\n",
    "                     for k in xrange(y_test.shape[0]))\n",
    "            results_ = parallel_(jobs_)\n",
    "\n",
    "            width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                               for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                              for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                                for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "            hit_prob_ = hits_.mean(axis=0)\n",
    "            hit_prob_std_ = hits_.std(axis=0)\n",
    "\n",
    "            for j, name_ in enumerate([\"rrcm\", \"crr\"]):\n",
    "                fig = plt.figure(figsize=(12, 6))\n",
    "                order_ = [1, 4, 2, 5, 3, 6]\n",
    "\n",
    "                ax = fig.add_subplot(2, 3, order_[0])\n",
    "                ax.plot(X_test, y_test, color=\"blue\")\n",
    "                ax.plot(X_test, y_hat_, color=\"red\")\n",
    "                ax.set_title(\"Actual/Prediction: %s\"%(func_,))\n",
    "\n",
    "                ax = fig.add_subplot(2, 3, order_[1])\n",
    "                ax.plot(X_test, np.abs(y_hat_ - y_test))\n",
    "                ax.set_title(\"Absolute error\")\n",
    "\n",
    "                for i in xrange(4):\n",
    "                    ax = fig.add_subplot(2, 3, order_[i + 2])\n",
    "\n",
    "                    ax.plot(X_test, np.abs(y_hat_ - y_test), alpha=0.25, label=\"$|y-\\\\hat{y}|$\")\n",
    "                    ax.plot(X_test, np.sqrt(MM), label=\"bayes\")\n",
    "            #         ax.plot(X_test, (bounds_[:, i, 1, 2] - bounds_[:, i, 0, 2]) / (2 * z_a[i]), label=\"bayes\")\n",
    "                    ax.plot(X_test, (bounds_[:, i, 1, j] - bounds_[:, i, 0, j]) / (2 * z_a[i]), label=name_)\n",
    "                    ax.set_title(\"Absolute error/accuracy %s %s-CI\"%(name_, lvl_cols_[i],))\n",
    "                    ax.legend(loc=\"best\")\n",
    "\n",
    "                fig.tight_layout()\n",
    "                fig_name_ = os.path.join(PLOT_PATH, \"%s 1k-%d %.1e %s.png\"%(func_, X_train.shape[0],\n",
    "                                                                            nugget, name_,))\n",
    "                print fig_name_\n",
    "\n",
    "                fig.savefig(fig_name_)\n",
    "                plt.close()\n",
    "            #     plt.show()\n",
    "            #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from itertools import chain\n",
    "from joblib import Parallel, delayed\n",
    "parallel_ = Parallel(n_jobs=-1, verbose=1)\n",
    "\n",
    "step_ = 7\n",
    "for func_ in [\"heaviside\",]:#func1d_.iterkeys():\n",
    "    print func_,\n",
    "    X = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "    y = func1d_[func_](X)\n",
    "\n",
    "    train_ = np.s_[::5]\n",
    "    X_train, y_train = X[train_], y[train_]\n",
    "    X_test, y_test = X, y# np.delete(X, train_, axis=0), np.delete(y, train_, axis=0)\n",
    "    \n",
    "    gp = GaussianProcess(thetaL=1e-4, thetaU=1e4, beta0=0,\n",
    "                         normalize=False, nugget=1e-6).fit(X_train, y_train)\n",
    "    \n",
    "    A, B, y_hat_, MM, loo_ = KRR_AB(X_train, y_train, X_test, forecast=True,\n",
    "                                    nugget=gp.nugget, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "    MM *= gp.sigma2\n",
    "\n",
    "    jobs_ = (delayed(_pccia)(k, levels, y_test[k], y_hat_[k], MM[k], A[0, k], B[k])\n",
    "             for k in xrange(y_test.shape[0]))\n",
    "    results_ = parallel_(jobs_)\n",
    "\n",
    "    width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                       for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                      for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                        for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    hit_prob_ = hits_.mean(axis=0)\n",
    "    hit_prob_std_ = hits_.std(axis=0)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    order_ = [1, 4, 2, 5, 3, 6]\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, order_[0])\n",
    "    ax.plot(X_test, y_test, color=\"blue\")\n",
    "    ax.plot(X_test, y_hat_, color=\"red\")\n",
    "    ax.set_title(\"Actual/Prediction: %s\"%(func_,))\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, order_[1])\n",
    "    ax.plot(X_test, np.abs(y_hat_ - y_test))\n",
    "    ax.set_title(\"Absolute error\")\n",
    "\n",
    "    for j, name_ in enumerate([\"rrcm\", \"bayes\"]):\n",
    "        for i, i_ in enumerate([2, 3]):\n",
    "            ax = fig.add_subplot(2, 3, order_[i + 3 + j*2 - 1])\n",
    "            ax.plot(X_test, bounds_[:, i_, 1, j] - bounds_[:, i_, 0, j], color=\"red\")\n",
    "            ax.plot(X_test, y_test[:, 0] - bounds_[:, i_, 0, j], color=\"blue\")\n",
    "            ax.axhline(y=0, color=\"red\")\n",
    "            ax.set_title(\"the %s-CI(%0.1f%%$\\pm$%0.1f%%)\\n of %s\"\n",
    "                         %(lvl_cols_[i_], 100*hit_prob_[i_, j], 100*hit_prob_std_[i_,j], name_.upper(),))\n",
    "    fig.tight_layout()\n",
    "#     fig.savefig(os.path.join(PLOT_PATH, \"1k-%d %s.png\"%(step_, func_,)))\n",
    "#     plt.close()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.functions_2d import func2D\n",
    "DGP_ = func2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0xDEADC0DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "parallel_ = Parallel(n_jobs=-1, verbose=1)\n",
    "\n",
    "# X_train = random_state.uniform(size=(100, 2)) * 2 - 1\n",
    "X_train = random_state.uniform(size=(1500, 2)) * 2 - 1\n",
    "\n",
    "mesh_ = np.meshgrid(*2*[np.linspace(-1, 1, num=51)])\n",
    "X_test = np.concatenate([ax_.reshape((-1, 1)) for ax_ in mesh_], axis=1)\n",
    "\n",
    "X = np.concatenate([X_train, X_test], axis=0)\n",
    "train_ = np.s_[:X_train.shape[0]]\n",
    "\n",
    "z_a = norm.ppf(1 - .5 * levels)\n",
    "\n",
    "levels_ = np.linspace(-.75, .75, num=16) * 100\n",
    "\n",
    "i, int_name_ = [(0, \"rrcm\"), (1, \"crr\"), (2, \"bayes\")][0]\n",
    "\n",
    "# nugget = 1e-2 ## 20160504\n",
    "nugget = 1e-6\n",
    "\n",
    "use_loo = True\n",
    "\n",
    "for theta0_ in np.logspace(-2, 2, num=5):\n",
    "    for name_ in [\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"][-1:]:\n",
    "        y = DGP_[name_](X)\n",
    "\n",
    "        y_train = y[train_]\n",
    "        y_test = np.delete(y, train_, axis=0)\n",
    "\n",
    "    #     gp = GaussianProcess(thetaL=1e-4, thetaU=1e4, beta0=0, theta0=0.1,\n",
    "        gp = GaussianProcess(beta0=0, theta0=theta0_, normalize=False,\n",
    "                             nugget=nugget).fit(X_train, y_train)\n",
    "\n",
    "        A, B, y_hat_, MM, loo_ = KRR_AB(X_train, y_train, X_test, forecast=True, loo=use_loo,\n",
    "                                        nugget=gp.nugget, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "        MM *= gp.sigma2\n",
    "\n",
    "        jobs_ = (delayed(_pccia)(k, levels, y_test[k], y_hat_[k], MM[k], A[0, k], B[k])\n",
    "                 for k in xrange(y_test.shape[0]))\n",
    "        results_ = parallel_(jobs_)\n",
    "\n",
    "        width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                           for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "        hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                          for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "        bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                            for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "        hit_prob_ = hits_.mean(axis=0)\n",
    "        hit_prob_std_ = hits_.std(axis=0)\n",
    "\n",
    "        delta_ = (bounds_[:, :, 1] - bounds_[:, :, 0]) / (2 * z_a[np.newaxis, :, np.newaxis])\n",
    "        rel_ = (delta_[..., i] / delta_[..., 2] - 1) * 100\n",
    "        ae_ = np.abs(y_test - y_hat_[:, 0])\n",
    "\n",
    "    ## Actual surface: 3D\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], y_test.reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.75)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"Actual\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s (tht %.1e).png\"\n",
    "                                 %(name_, theta0_,))\n",
    "        print fig_name_\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## Absolute prediction error: 3D\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], ae_.reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.9)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"Absolute error\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s abs_error (tht %.1e).png\"\n",
    "                                 %(name_, theta0_,))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## \\hat{y}: 3D\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], y_hat_.reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.9)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"Predicted\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s predicted (tht %.1e).png\"\n",
    "                                 %(name_, theta0_,))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## \\hat{\\sigma}: 3D\n",
    "        sigma_hat_ = np.sqrt(MM[:, 0] - gp.sigma2 * gp.nugget)\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], sigma_hat_.reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.9)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"$\\\\hat{\\\\sigma}$\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s sigma (tht %.1e).png\"\n",
    "                                 %(name_, theta0_,))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## \\delta\n",
    "        sigma_hat_ = np.sqrt(MM[:, 0] - gp.sigma2 * gp.nugget)\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(mesh_[0], mesh_[1], delta_[:, -1, 0].reshape(mesh_[0].shape),\n",
    "                        cstride=1, rstride=1, cmap=plt.cm.coolwarm, lw=0,\n",
    "                        antialiased=False, alpha=0.9)\n",
    "        ax.view_init(60, 30)\n",
    "        ax.set_title(\"RRCM 5%-CI scaled half-width\")\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s rrcm25-shw (tht %.1e%s).png\"\n",
    "                                 %(name_, theta0_, \", loo\" if use_loo else \"\",))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    ## Actual values: top-down\n",
    "        fig = plt.figure(figsize=(12, 15))\n",
    "        ax = fig.add_subplot(321)\n",
    "        cont_ = ax.contourf(mesh_[0], mesh_[1],\n",
    "                            y_test.reshape(mesh_[0].shape), 20,\n",
    "                            cmap=plt.cm.coolwarm, lw=0, alpha=0.9)\n",
    "        ax.set_title(\"Actual value %s\"%(name_,))\n",
    "        plt.colorbar(cont_)\n",
    "\n",
    "    ## Absolute arror: top-down\n",
    "        ax = fig.add_subplot(322)\n",
    "        cont_ = ax.contourf(mesh_[0], mesh_[1],\n",
    "                            ae_.reshape(mesh_[0].shape), 20,\n",
    "                            cmap=plt.cm.coolwarm, lw=0, alpha=0.9)\n",
    "        ax.set_title(\"Absolute prediction error\")\n",
    "        plt.colorbar(cont_)\n",
    "\n",
    "        ## CCI relative precision wrt. bayesian CI.\n",
    "        for j, pct_ in enumerate(lvl_cols_):\n",
    "            ax = fig.add_subplot(3, 2, j + 3)\n",
    "\n",
    "            cont_ = ax.contour(mesh_[0], mesh_[1], rel_[:, j].reshape(mesh_[0].shape),\n",
    "                               levels=levels_, colors=\"k\", linestyles=\"solid\", extend=\"both\")\n",
    "            ax.clabel(cont_, inline=1, fontsize=8, fmt='%.0f')\n",
    "\n",
    "            CS3 = ax.contourf(mesh_[0], mesh_[1], rel_[:, j].reshape(mesh_[0].shape),\n",
    "                        cmap=plt.cm.coolwarm, lw=1, levels=levels_,\n",
    "                        antialiased=False, alpha=1.0, extend='both',)\n",
    "            CS3.cmap.set_over('white')\n",
    "\n",
    "            ax.set_title(\"\"\"rel. %s(%.1f%%) / bayes(%.1f%%) %s-CI%s\"\"\"\n",
    "                         %(int_name_, 100-hit_prob_[j, i]*100,\n",
    "                           100-hit_prob_[j, -1]*100, pct_,\n",
    "                           \"(loo)\" if use_loo else \"\",))\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig_name_ = os.path.join(OUTPUT_PLOT_PATH, \"%s efficiency (tht %.1e%s).png\"\n",
    "                                 %(name_, theta0_, \", loo\" if use_loo else \"\",))\n",
    "        print fig_name_,\n",
    "        fig.savefig(fig_name_)\n",
    "#         plt.show()\n",
    "        plt.close()\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0x0ABACABA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma = 10.0\n",
    "dim_ = 2\n",
    "resolution=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dgp_opts_ = {name_: dict(scale=1.0) for name_ in DGP}\n",
    "dgp_opts_[\"gaussian\"].update(dict(metric=\"rbf\", gamma=gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def surface(ax, mesh, yy, name, **kwargs):\n",
    "#     ax.plot_surface(mesh[0], mesh[1], yy.reshape(mesh[0].shape),\n",
    "#                     cstride=1, rstride=1, cmap=plt.cm.coolwarm,\n",
    "#                     lw=0, antialiased=False, **kwargs)\n",
    "#     ax.set_title(\"A sample surface $y\\\\sim \\\\mathtt{%s}$\"%(name,))\n",
    "#     ax.set_ylabel(\"y\")\n",
    "#     return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(X, y, X_test, y_test):\n",
    "## Run the GP regression\n",
    "    gp = GaussianProcess(thetaL=1e-4, thetaU=1e2, beta0=0,\n",
    "                         normalize=False, nugget=1e-6,\n",
    "                         storage_mode='light').fit(X, y)\n",
    "## Compute the necessary matrices\n",
    "    A, B, y_hat_, MM, loo_ = KRR_AB(X, y, X_test, nugget=gp.nugget,\n",
    "                                    sigma2=gp.sigma2, metric=\"rbf\", gamma=gp.theta_[0])\n",
    "#     y_hat_gp, mse_gp = gp.predict(X_test, eval_MSE=True)\n",
    "#     assert np.allclose(MM[:, 0], mse_gp + gp.sigma2 * gp.nugget)\n",
    "#     assert np.allclose(y_hat_[:, 0], y_hat_gp, rtol=1e-3)\n",
    "\n",
    "## Run in parallel\n",
    "    parallel_ = Parallel(n_jobs=-1, verbose=1)\n",
    "    jobs_ = (delayed(_pccia)(k, levels, y_test[k],\n",
    "                             y_hat_[k], MM[k], A[0, k], B[k])\n",
    "             for k in xrange(y_test.shape[0]))\n",
    "    results_ = parallel_(jobs_)\n",
    "# ## Combine the results\n",
    "    width_ = np.stack([np.stack((rrcm_[1], ccr_[1], bayes_[1]), axis=1)\n",
    "                       for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    hits_ = np.stack([np.stack((rrcm_[0], ccr_[0], bayes_[0]), axis=1)\n",
    "                      for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    bounds_ = np.stack([np.stack((rrcm_[2], ccr_[2], bayes_[2]), axis=2)\n",
    "                        for key_, rrcm_, ccr_, bayes_ in results_], axis=0)\n",
    "    return width_, hits_, bounds_, y_hat_[:, 0], MM[:, 0], gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_ = dict()\n",
    "for name_, dgp_ in DGP.iteritems():\n",
    "    print \"%s:\"%(name_,),\n",
    "## Create a dediacted validation sample\n",
    "    mesh_ = np.meshgrid(*dim_*[np.linspace(-1, 1, num=resolution)])\n",
    "    XX = np.concatenate([ax_.reshape((-1,1)) for ax_ in mesh_], axis=1)\n",
    "    yy = dgp_(XX, random_state=random_state, **dgp_opts_[name_])\n",
    "# ## A typical realisation\n",
    "#     fig = plt.figure(figsize=(8, 6))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     surface(ax, mesh_, yy, name_).view_init(60, 30)\n",
    "#     fig.savefig(os.path.join(SAMPLE_PLOT_PATH, \"%s.png\"%(name_)), )\n",
    "#     plt.close()\n",
    "## Now do the train/validation split\n",
    "    XX0, X_validate = train_test_split(XX, test_size=0.25, random_state=random_state)\n",
    "    for N in [100, 400, 1600]:\n",
    "        print \"N = %d,\"%(N,),\n",
    "        X_train = resample(XX0, replace=False, n_samples=N, random_state=random_state)\n",
    "        X_full = np.concatenate([X_train, X_validate], axis=0)\n",
    "## the dgp: add some independent gaussian noise.\n",
    "        for noise_level_ in [1e-6, 1e-1]:\n",
    "            print \"noise = %2.2e\"%(noise_level_)\n",
    "            y_full = dgp_(X_full, random_state=random_state,\n",
    "                          nugget=noise_level_, **dgp_opts_[name_])\n",
    "            if name_ != \"gaussian\":\n",
    "                y_full += random_state.normal(size=y_full.shape) * sqrt(noise_level_)\n",
    "            y_train, y_validate = y_full[:N], y_full[N:]\n",
    "## The experiment\n",
    "            result_ = run_experiment(X_train, y_train, X_validate, y_validate)\n",
    "# ## Save\n",
    "            experiment_[name_, N, noise_level_] = (result_, X_full, y_full, N)\n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_save(experiment_, os.path.join(OUTPUT_PATH, \"experiment_02_\"), gz=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tuple_, result_ in experiment_.iteritems():\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result_\n",
    "    name_, size_, noise_ = tuple_\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "\n",
    "    fig, ax_ = plt.subplots(nrows=1, ncols=3, sharex=True,\n",
    "                            sharey=True, figsize=(16, 9))\n",
    "    for i, type_ in enumerate([\"rrcm\", \"crr\", \"bayes\"]):\n",
    "        ax_[i].boxplot(width_[..., i])\n",
    "        ax_[i].set_title(\"\"\"`%s` `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                         %(type_, name_, size_, noise_,))\n",
    "        ax_[i].set_ylabel(\"width\")\n",
    "        ax_[i].set_xticklabels(lvl_cols_)\n",
    "        ax_[i].grid()\n",
    "    fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"width_box - %s %.1E %d.png\"\n",
    "                             %(name_, noise_, size_, )), )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(result):\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "    ratio_ = np.abs(y_test-y_hat_).reshape((-1,1,1)) / (bounds_[:, :, 1] - bounds_[:, :, 0])\n",
    "    lvl_cols_ = [\"%4.1f%%\"%(100*lv_,) for lv_ in levels]\n",
    "    return pd.concat({\n",
    "        \"median width\": pd.DataFrame(np.median(width_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"mean width\": pd.DataFrame(np.mean(width_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"95% width\": pd.DataFrame(np.percentile(width_, 95, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"max width\": pd.DataFrame(np.max(width_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"coverage\": pd.DataFrame(np.mean(hits_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"avg. abs-width ratio\": pd.DataFrame(np.median(ratio_, axis=0), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "        \"mse/var\": pd.DataFrame(np.full((4, 3), (y_test - y_hat_).var() / y_test.var()), index=lvl_cols_, columns=[\"rrcm\", \"crr\", \"bayes\"]),\n",
    "    }, axis=0, names=[\"measure\"]).unstack().stack(level=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ = pd.concat({tuple_: process(result_) for tuple_, result_ in experiment_.iteritems()},\n",
    "            axis=0, names = [\"fun\", \"N\", \"noise\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coverage table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_.xs(\"coverage\", level=-2, axis=0).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max width table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_.xs(\"max width\", level=-2, axis=0).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual, predicted and abs-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tuple_, result_ in experiment_.iteritems():\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result_\n",
    "    name_, size_, noise_ = tuple_\n",
    "## Plot the error bars\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_trisurf(X_test[:, 0], X_test[:, 1], np.abs(y_test-y_hat_) / y_test.std(),\n",
    "                    cmap=plt.cm.coolwarm, lw=0) #, norm=MidPointNorm())\n",
    "    ax.set_title(\"\"\"abs/std ratio of `y` for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                 %(name_, size_, noise_,))\n",
    "    ax.view_init(60, 60)\n",
    "    fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"abs_std_ratio - %s %.1E %d.png\"\n",
    "                             %(name_, noise_, size_, )), )\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_trisurf(X_test[:, 0], X_test[:, 1], y_test,\n",
    "                    cmap=plt.cm.coolwarm, lw=0) #, norm=MidPointNorm())\n",
    "    ax.set_title(\"\"\"Actual value of `y` for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                 %(name_, size_, noise_,))\n",
    "    ax.view_init(60, 60)\n",
    "    fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"actual - %s %.1E %d.png\"\n",
    "                             %(name_, noise_, size_,)), )\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_trisurf(X_test[:, 0], X_test[:, 1], y_hat_,\n",
    "                    cmap=plt.cm.coolwarm, lw=0) #, norm=MidPointNorm())\n",
    "    ax.set_title(\"\"\"Predicted value of `y` for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                 %(name_, size_, noise_,))\n",
    "    ax.view_init(60, 60)\n",
    "    fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"predicted - %s %.1E %d.png\"\n",
    "                             %(name_, noise_, size_,)), )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abs-width ratio for the intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tuple_, result_ in experiment_.iteritems():\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result_\n",
    "    name_, size_, noise_ = tuple_\n",
    "## Plot the error bars\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "\n",
    "    for i, type_ in enumerate([\"rrcm\", \"crr\", \"bayes\"]):\n",
    "        for j, sign_ in enumerate(lvl_cols_):\n",
    "            fig = plt.figure(figsize=(16, 9))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            ax.plot_trisurf(X_test[:, 0], X_test[:, 1], np.abs(y_test-y_hat_) / width_[:, j, i],\n",
    "                            cmap=plt.cm.coolwarm, lw=0) #, norm=MidPointNorm())\n",
    "            ax.set_title(\"\"\"abs/width ratio for `%s`-type %s-interval for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                         %(type_, sign_, name_, size_, noise_,))\n",
    "            ax.view_init(60, 60)\n",
    "            fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"abs_width_ratio - %s %.1E %d %s %s.png\"\n",
    "                                     %(name_, noise_, size_, type_, sign_, )), )\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excess plot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tuple_, result_ in experiment_.iteritems():\n",
    "    (width_, hits_, bounds_, y_hat_, y_hat_sigma_, gp), X_full, y_full, N = result_\n",
    "    name_, size_, noise_ = tuple_\n",
    "## Plot the error bars\n",
    "    X_test, y_test = X_full[N:], y_full[N:]\n",
    "    for i, type_ in enumerate([\"rrcm\", \"crr\", \"bayes\"]):\n",
    "        for j, sign_ in enumerate(lvl_cols_):\n",
    "            excess_u_ = y_test - bounds_[:, j, 1, i]\n",
    "            excess_d_ = bounds_[:, j, 0, i] - y_test\n",
    "            excess_u_[excess_u_ < 0] = 0\n",
    "            excess_d_[excess_d_ < 0] = 0\n",
    "            excess_ = 2 * (excess_u_ - excess_d_) / width_[:, j, i]\n",
    "\n",
    "            fig = plt.figure(figsize=(16, 9))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            ax.set_title(\"\"\"Excess of `%s`-type %s-interval for `%s`(N=%d, noise=%.1E)\"\"\"\n",
    "                         %(type_, sign_, name_, size_, noise_,))\n",
    "            ax.plot_trisurf(X_test[:, 0], X_test[:, 1], excess_, cmap=plt.cm.coolwarm,\n",
    "                            lw=0, alpha=.95, norm=MidPointNorm())\n",
    "            ax.view_init(60, 60)\n",
    "\n",
    "            fig.savefig(os.path.join(OUTPUT_PLOT_PATH, \"excess - %s %.1E %d %s %s.png\"\n",
    "                                     %(name_, noise_, size_, type_, sign_, )), )\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
