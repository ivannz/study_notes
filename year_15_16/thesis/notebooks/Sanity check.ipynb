{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from utils.state import _save\n",
    "from utils.functions_1d import f6, pressure2, heaviside\n",
    "from utils.functions import gaussian\n",
    "\n",
    "from utils.conformal import RRCM, CRR\n",
    "from utils.KRR import KRR_AB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "np.seterr(all=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n_jobs, verbose = -1, 0\n",
    "parallel_ = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "## The levels and the random state\n",
    "seeds_ = [0xB5066DBC, 0x98E8576F, 0x3161F88E, 0x08CCA9D9,]\n",
    "random_state = np.random.RandomState(seeds_[3])\n",
    "\n",
    "levels = np.linspace(0, 0.9, num=51) #np.asanyarray([0.01, 0.05, 0.10, 0.25])[::-1]\n",
    "\n",
    "## helpers\n",
    "def _helper(y, A, B, proc=RRCM, levels=levels, parallel=None, n_jobs=1, verbose=0):\n",
    "    if not isinstance(parallel, Parallel):\n",
    "        parallel = Parallel(n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "    regions = parallel(delayed(proc)(A[k], B[k], levels=levels)\n",
    "                       for k in xrange(y.shape[0]))\n",
    "\n",
    "    hits_ = np.asarray(\n",
    "        [[np.any(((int_[:, 0] <= target) & (target <= int_[:, 1]))).astype(float)\n",
    "          for int_ in region]\n",
    "         for target, region in zip(y, regions)])\n",
    "\n",
    "    width_ = np.asarray(\n",
    "        [[np.sum(int_[:, 1] - int_[:, 0]) for int_ in region] for region in regions])\n",
    "    \n",
    "    bounds_ = np.asarray(\n",
    "        [[[int_[:, 0].min(), int_[:, 1].max()] for int_ in region] for region in regions])\n",
    "\n",
    "    return hits_, width_, bounds_\n",
    "\n",
    "## Define the grid\n",
    "\n",
    "true_nugget = [1e-6, 1e-1,]\n",
    "test_functions = [f6, heaviside, pressure2]\n",
    "\n",
    "grid_ = ParameterGrid(dict(func=test_functions,\n",
    "                           size=[25, 50, 100, 200, 400, 600, 800, 1000, 1200, 1400, 1600,],\n",
    "                           nugget=true_nugget,\n",
    "                           noise=true_nugget,\n",
    "                           theta0=[1e+1, 1e+2, 1e+3, \"auto\"]))\n",
    "## Initialize\n",
    "kernel = 'rbf'\n",
    "gp = GaussianProcess(beta0=0, normalize=False, corr='squared_exponential')\n",
    "\n",
    "# Generate input\n",
    "XX_test = np.linspace(0, 1, num=1001).reshape((-1, 1))\n",
    "# XX_test = np.concatenate([XX_test,  np.logspace(0, 3, num=2001).reshape((-1, 1))], axis=0)\n",
    "test_ = np.s_[:XX_test.shape[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_, nugget_, theta0_ = 1600, 1e-6, float(100.0)\n",
    "func_, noise_ = f6, 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# true_theta = 100.0\n",
    "# func_ = lambda XX: gaussian(XX, scale=1.0, nugget=noise_, metric=kernel,\n",
    "#                             random_state=random_state,\n",
    "#                             gamma=true_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Draw random train sample\n",
    "train_ = random_state.uniform(size=(size_, 1))\n",
    "X = np.sort(train_, axis=0)\n",
    "\n",
    "## Draw f(x)\n",
    "XX = np.concatenate([XX_test, X], axis=0)\n",
    "yy = func_(XX)\n",
    "if yy.ndim == 1:\n",
    "    yy = yy.reshape((-1, 1))\n",
    "if noise_ > 0 and func_ in {f6, heaviside}:\n",
    "    yy += random_state.normal(size=yy.shape) * noise_\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Split the pooled sample\n",
    "y, y_test = np.delete(yy, test_, axis=0), yy[test_]\n",
    "\n",
    "## Fit a GPR\n",
    "gp_ = clone(gp)\n",
    "gp_.nugget = nugget_\n",
    "if isinstance(theta0_, float):\n",
    "    gp_.theta0 = theta0_\n",
    "elif theta0_ == \"auto\":\n",
    "    gp_.thetaL, gp_.thetaU, gp_.theta0 = 1.0, 1e4, float(size_)\n",
    "gp_.fit(X, y)\n",
    "\n",
    "## Compute the A, B matrices\n",
    "A, B, y_hat_, MM, loo_, A_loo, B_loo = \\\n",
    "    KRR_AB(X, y, XX_test, forecast=True,\n",
    "           nugget=gp_.nugget, metric=kernel, gamma=gp_.theta_[0])\n",
    "del loo_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp_.theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import cholesky, solve_triangular\n",
    "from scipy.linalg.lapack import dtrtri\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "## Obtain AB vectors for the regression CCR problem\n",
    "Kxx = np.asfortranarray(pairwise_kernels(X, metric=kernel, gamma=gp_.theta_[0]))\n",
    "Kxx[np.diag_indices_from(Kxx)] += gp_.nugget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "ax =fig.add_subplot(111)\n",
    "ax.imshow(Kxx, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get the in-place lower triangular Cholesky decomposition (in-place works if\n",
    "##  the array is in fortran layout).\n",
    "## K_{xx} + a I_x = C C' ; K_{zx} Q_X y = (C^{-1} K_{xz})' (C^{-1} y)\n",
    "cholesky(Kxx, lower=True, overwrite_a=True)\n",
    "Ci_y = solve_triangular(Kxx, y.copy('F'), lower=True, overwrite_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_ = solve_triangular(Kxx, Ci_y, lower=True, overwrite_b=True)\n",
    "plt.scatter(y, beta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ass_ = np.concatenate(RRCM(A[0, -1], B[-1], levels=levels), axis=0)\n",
    "plt.plot(ass_[:,1]-ass_[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct the CKRR confidence interval: RRCM\n",
    "rrcm_hits_, rrcm_width_, rrcm_bounds_ = \\\n",
    "    _helper(y_test, A[0], B, proc=RRCM,\n",
    "            levels=np.linspace(0, 0.9, num=51), parallel=parallel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(rrcm_width_.T, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct the GPR forecast interval\n",
    "z_a = norm.ppf(1 - .5 * levels)\n",
    "half_width_ = np.sqrt(MM * gp_.sigma2) * z_a[np.newaxis]\n",
    "bf_bounds_ = np.stack([y_hat_ - half_width_, y_hat_ + half_width_], axis=-1)\n",
    "bf_width_ = bf_bounds_[..., 1] - bf_bounds_[..., 0]\n",
    "bf_hits_ = ((bf_bounds_[..., 0] <= y_test)\n",
    "            & (y_test <= bf_bounds_[..., 1])).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(XX_test, (rrcm_bounds_[:, -1, 1] - y_hat_[:,0]) - (y_hat_[:,0] - rrcm_bounds_[:, -1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(XX_test, np.abs(y_test-y_hat_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(XX_test, rrcm_bounds_[:, 30, 1]-rrcm_bounds_[:, 30, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(levels, rrcm_hits_.mean(axis=0)-(1-levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1-levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rrcm_hits_.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(rrcm_hits_.mean(axis=0)-(1-levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_hits_.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(bf_hits_.mean(axis=0)-(1-levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j=1\n",
    "\n",
    "plt.plot(XX_test, rrcm_bounds_[:, j, 0]-y_hat_[:, 0], c=\"r\")\n",
    "plt.plot(XX_test, rrcm_bounds_[:, j, 1]-y_hat_[:, 0], c=\"r\")\n",
    "plt.plot(XX_test, bf_bounds_[:, j, 0]-y_hat_[:, 0], c=\"b\")\n",
    "plt.plot(XX_test, bf_bounds_[:, j, 1]-y_hat_[:, 0], c=\"b\")\n",
    "# plt.plot(XX_test, y_hat_[:, 0]-y_hat_[:, 0], c=\"m\")\n",
    "plt.plot(XX_test, y_test[:, 0]-y_hat_[:, 0], c=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(XX_test, y_test[:, 0], c=\"k\")\n",
    "plt.plot(XX_test, y_hat_[:, 0], c=\"m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal Anomaly Detector via RBF Kernel Embddeing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Below are shown sample results obtained in this project. On left are level sets of the nominal bivariate Gaussian mixture distribution used to illustrate the K-LPE algorithm. In the middle are results of K-LPE with K= 6 and Euclidean distance metric for $m = 150$ test points drawn from an equal mixture of 2D uniform and the (nominal) bivariate distributions. Scores for the test points are based on 200 nominal training samples. Scores falling below a threshold level 0.05 are declared as anomalies. The dotted contour corresponds to the exact bivariate Gaussian density level set at level alpha= 0.05. On right is the empirical distribution of the test point scores associated with the bivariate Gaussian that appears  to be uniform while scores for the test points drawn from 2D uniform distribution cluster around zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from utils.state import _save\n",
    "from utils.functions_1d import f6, pressure2, heaviside\n",
    "from utils.functions import gaussian\n",
    "\n",
    "from utils.conformal import RRCM, CRR\n",
    "from utils.KRR import KRR_AB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.seterr(all=\"ignore\")\n",
    "random_state = np.random.RandomState(0x0B00B1E5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, D, P = 1000, 2, 1\n",
    "X = np.concatenate([random_state.normal(size=(N//4, D))*1 + np.array([[2, 2]]),\n",
    "                    random_state.normal(size=(N//4, D))*2 + np.array([[-1, -2]]),\n",
    "                    random_state.normal(size=(N//4, D))*.5 + np.array([[-2, 1]]),\n",
    "                    random_state.normal(size=(N//4, D))*.75 + np.array([[2, -2]])], axis=0)\n",
    "# X *= -np.log(random_state.uniform(size=(N, D)))*2.5\n",
    "\n",
    "# W = random_state.normal(size=(D, P))\n",
    "# F = random_state.normal(size=(N, P))\n",
    "# X += np.dot(F, W.T)\n",
    "\n",
    "X = X.reshape((-1, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.5,  random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import cholesky, solve_triangular\n",
    "from scipy.linalg.lapack import dtrtri\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "## Create the kernel matrix\n",
    "Kxx = pairwise_kernels(X_train, metric=\"rbf\", gamma=theta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Kxz = pairwise_kernels(X_train, X_test, metric=\"rbf\", gamma=theta_)\n",
    "delta_ = 1 + Kxz.sum(axis=0, keepdims=True) - Kxx.sum(axis=1, keepdims=True) - Kxz\n",
    "pvalue_ = (np.sum(delta_ >= 0, axis=0) + 1) / (Kxx.shape[0] + 1.0)\n",
    "# delta_ = (Kxx.sum(axis=1, keepdims=True) + Kxz) - (1 + Kxz.sum(axis=0, keepdims=True))\n",
    "# pvalue_ = np.mean(delta_ >= 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(pvalue_ <= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=\"black\", alpha=0.5, lw=0,)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], s=50*(1-pvalue_), lw=0)\n",
    "plt.scatter(X_test[pvalue_ < 0.05, 0], X_test[pvalue_ < 0.05, 1], s=100, c=\"m\", lw=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(Kxx, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CKDE vs. ocSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.25,  random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_, kernel, alpha = 1.0, \"rbf\", 0.250\n",
    "kwargs = dict(gamma=theta_)\n",
    "\n",
    "Kxx = pairwise_kernels(X_train, metric=kernel, **kwargs)\n",
    "Kxz = pairwise_kernels(X_train, X_test, metric=kernel, **kwargs)\n",
    "delta_ = 1 + Kxz.sum(axis=0, keepdims=True) - Kxx.sum(axis=1, keepdims=True) - Kxz\n",
    "pvalue_ = (np.sum(delta_ >= 0, axis=0) + 1) / (Kxx.shape[0] + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.OneClassSVM(nu=alpha, kernel=kernel, gamma=theta_).fit(X_train)\n",
    "ocsvm = clf.predict(X_test) # decision_function(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(ocsvm>0), np.mean(pvalue_<alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.scatter(X_test[:,0], X_test[:,1], c=pvalue_>alpha, cmap=plt.cm.coolwarm_r, lw=0)\n",
    "ax.set_title(\"$\\\\alpha=%g$ Conformal KDE (%s, $\\\\theta=%g$)\"%(alpha, kernel, theta_,))\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.scatter(X_test[:,0], X_test[:,1], c=ocsvm, cmap=plt.cm.coolwarm_r, lw=0)\n",
    "ax.set_title(\"ocSVM (%s, $\\\\theta=%g, \\\\nu=%g$)\"%(kernel, theta_, alpha,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contour plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_ = np.meshgrid(*(2*[np.linspace(-10, 10, num=151)]))\n",
    "X_test_ = np.stack(mesh_, axis=-1).reshape((-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# theta_, kernel, alpha = 1.0, \"rbf\", 0.250\n",
    "# kwargs = dict(gamma=theta_)\n",
    "\n",
    "Kxx = pairwise_kernels(X_train, metric=kernel, **kwargs)\n",
    "Kxz = pairwise_kernels(X_train, X_test_, metric=kernel, **kwargs)\n",
    "delta_ = 1 + Kxz.sum(axis=0, keepdims=True) - Kxx.sum(axis=1, keepdims=True) - Kxz\n",
    "pvalue_ = (np.sum(delta_ >= 0, axis=0) + 1) / (Kxx.shape[0] + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# clf = svm.OneClassSVM(nu=alpha, kernel=kernel, gamma=theta_).fit(X_train)\n",
    "ocsvm = clf.decision_function(X_test_).reshape(mesh_[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eta_ocsvm = np.zeros((X_train.shape[0], 1), dtype=float)\n",
    "eta_ocsvm[clf.support_, 0] = clf.dual_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmcm = np.apply_along_axis(lambda z, Z: np.mean(Z>=z[np.newaxis], axis=0),\n",
    "                            1, eta_ocsvm, eta_ocsvm)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], lw=0,\n",
    "            c=np.array([\"b\",\"r\"])[(svmcm[:,0]<alpha).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.contourf(mesh_[0], mesh_[1], ocsvm.reshape(mesh_[0].shape),\n",
    "            levels=np.linspace(ocsvm.min(), ocsvm.max(), num=51), cmap=plt.cm.coolwarm)\n",
    "# ax.scatter(X_test_[:, 0], X_test_[:, 1], c=\"m\", s=20*(ocsvm < 0), lw=0)\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=\"k\", s=5, lw=0)\n",
    "ax.set_title(\"ocSVM\")\n",
    "ax = fig.add_subplot(122)\n",
    "ax.contourf(mesh_[0], mesh_[1], pvalue_.reshape(mesh_[0].shape),\n",
    "            levels=np.linspace(0, 1, num=51), cmap=plt.cm.coolwarm)\n",
    "# ax.scatter(X_test_[:, 0], X_test_[:, 1], c=\"m\", s=20*(pvalue_ < alpha), lw=0)\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=\"k\", s=5, lw=0)\n",
    "ax.set_title(\"CKDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Kenrel embeddings of timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
